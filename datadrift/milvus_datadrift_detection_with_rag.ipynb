{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73074d34-7d47-40a9-8197-07b86e35e561",
   "metadata": {},
   "source": [
    "# RAG - Datadrift\n",
    "\n",
    "The purpose of this notebook is to demonstrate a straightforward method for assessing data drift in a Large Language Model (LLM) that utilizes the Retrieve, Analyze, Generate (RAG) architecture.\n",
    "\n",
    "1. Data Ingestion: Collect and store a representative sample of data that the LLM was trained on or has been exposed to during its operational phase. This data serves as the reference dataset against which we will compare incoming user input.\n",
    "2. User Input: Whenever a user provides input to the LLM, the text is processed and embedded into a numerical representation.\n",
    "3. Embedding Comparison: We compare the embedding of the user's input with the embeddings of the data in our reference dataset. This comparison can be performed using various techniques, such as cosine similarity or other distance metrics.\n",
    "4. Thresholding: Set a threshold for acceptable similarity scores. If the similarity between the user input and the reference data falls below this threshold, it may indicate data drift.\n",
    "\n",
    "In the upcoming notebook, we will utilize pymilvus to establish a direct connection to the Docker environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c3e31f3-fdb1-4c57-a5ef-4b8b5b7a97f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, Collection\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19101f7-8143-4c02-8c01-5362dcfda488",
   "metadata": {},
   "source": [
    "The initial step is to establish a connection to the Milvus database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3674268e-2500-4037-8b64-4e68a208c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be44daad-4d84-493a-9dd8-a9aec29274b3",
   "metadata": {},
   "source": [
    "Now, we can access the collection that contains the query sent by the user.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e836b734-3ec4-499d-beaf-c61f0174bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_collection_name = \"QueryCollection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "eef7ac2e-d85c-4bb8-8c3a-f6190e3e0938",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_collection = Collection(query_collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2b163905-2a3c-4154-a0a8-fe1a2b182ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Collection>:\n",
      "-------------\n",
      "<name>: QueryCollection\n",
      "<description>: \n",
      "<schema>: {'auto_id': True, 'description': '', 'fields': [{'name': 'text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 65535}}, {'name': 'pk', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': True}, {'name': 'vector', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 768}}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(query_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef08d1d0-e4e4-4b76-ae05-1da982a28647",
   "metadata": {},
   "source": [
    "We can now retrieve the vector field associated with this collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2c81658b-5cfd-4690-8be5-0c5c672dfeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_query = query_collection.query(\n",
    "    expr = \"\",\n",
    "    limit=100,\n",
    "    output_fields=[\"vector\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f1bd4272-953d-492a-83cd-e964375608fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_queries = len(res_query)\n",
    "number_of_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d9d70e-53b6-4d37-975a-3ec75d16373c",
   "metadata": {},
   "source": [
    "We are now equipped to compare user queries with the ingested data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f0bc3977-cf43-442f-ba38-6e03ab0bc20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [query['vector'] for query in res_query]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb2307-8dac-4aa6-87b8-686937a27534",
   "metadata": {},
   "source": [
    "## Compare the query to the ingested data\n",
    "\n",
    "In the second part, our objective is to load the data that was ingested from multiple websites and verify if the embeddings correspond to the user's queries. The collection where we stored the content for retrieval augmentation generation is referred to as LangChainCollection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cc9c39fd-592b-41b9-84e6-ef471e8d839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_collection_name = \"LangChainCollection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "07f28398-2db0-4493-b115-1d6fb0d8996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collection = Collection(langchain_collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1f6d8393-be79-494d-9035-570c592817fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Collection>:\n",
      "-------------\n",
      "<name>: LangChainCollection\n",
      "<description>: \n",
      "<schema>: {'auto_id': True, 'description': '', 'fields': [{'name': 'text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 65535}}, {'name': 'pk', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': True}, {'name': 'vector', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 768}}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b01783-c3db-4a3c-b0f8-e0db1e08b82c",
   "metadata": {},
   "source": [
    "We simply want to determine the number of data chunks present in this collection. This number can then be used to calculate the number of chunks that were utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "22164f17-77b0-4d3a-96ee-005c373ee5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_data = data_collection.query(\n",
    "    expr = \"\",\n",
    "    limit=9999,\n",
    "    output_fields=[\"vector\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "83d0534c-e892-4b0c-8e04-8007cadce02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_chunck_of_data = len(res_data)\n",
    "number_of_chunck_of_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d7e030-79dc-4693-9362-aa68efd05bf6",
   "metadata": {},
   "source": [
    "## RAG Datadrift detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290cc9d2-33e6-4ebe-8a8f-6a12d91c991e",
   "metadata": {},
   "source": [
    "Now, we can employ Milvus' similarity search to compare the queries for their similarity to the current query. We utilize the L2 metric, where a smaller value indicates a better match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "6a9559e3-84ed-4203-be1a-9daeccdbe2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    # use `L2` as the metric to calculate the distance\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\n",
    "        # search for vectors with a distance smaller than 1.0\n",
    "        \"radius\": 1.0,\n",
    "        # filter out vectors with a distance smaller than or equal to 0.8\n",
    "        \"range_filter\" : 0.8\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "0a3e7b8c-9529-4fbe-bc8b-d2679ecfaf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = data_collection.search(\n",
    "    data=queries,\n",
    "    anns_field=\"vector\",\n",
    "    limit=number_of_chunck_of_data,\n",
    "    param=param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9405d9cf-1434-4928-bacf-f3eb44234df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[]', '[]', '[]', '[]', \"['id: 447155909408064991, distance: 0.8176913261413574, entity: {}', 'id: 447155909408065433, distance: 0.8176913261413574, entity: {}', 'id: 447155909408065069, distance: 0.833382785320282, entity: {}', 'id: 447155909408065049, distance: 0.840793251991272, entity: {}', 'id: 447155909408065045, distance: 0.8410907983779907, entity: {}', 'id: 447155909408064921, distance: 0.8595541715621948, entity: {}', 'id: 447155909408065363, distance: 0.8595541715621948, entity: {}', 'id: 447155909408064927, distance: 0.8837847113609314, entity: {}', 'id: 447155909408065369, distance: 0.8837847113609314, entity: {}', 'id: 447155909408064723, distance: 0.8845637440681458, entity: {}']\"]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef9371-1977-49c1-bf06-55ad07462b17",
   "metadata": {},
   "source": [
    "## Data  Drift Metrics\n",
    "\n",
    "We can observe interesting insights by examining the following metrics:\n",
    "\n",
    "1. Non-Matching Queries: This metric checks for queries that do not have any matching documents in the database.\n",
    "2. Matching Queries: The number of queries that have documents matching the query.\n",
    "3. Database Utilization Percentage: This metric represents the percentage of documents from the database that were utilized by the RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "228f5191-6cc2-43d5-9403-b0f160b1036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_matched_queries(res):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of queries with no matching document in the database.\n",
    "\n",
    "    Parameters:\n",
    "    res (list): A list containing query results. Each element in the list represents the result of a query,\n",
    "                and an empty list indicates that no matching documents were found for that query.\n",
    "\n",
    "    Returns:\n",
    "    float: The percentage of queries with no matching document, as a value between 0 and 100.\n",
    "\n",
    "    Example:\n",
    "    >>> results = [[1, 2], [], [3, 4], [], [], [5, 6]]\n",
    "    >>> not_matched_percentage = not_matched_queries(results)\n",
    "    >>> print(not_matched_percentage)\n",
    "    50.0\n",
    "    \"\"\"\n",
    "    \n",
    "    return len(list(filter(lambda x: x == [], res))) / len(res) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "55cf1475-1cc1-4178-b0f2-91f6ce692b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_matched_queries(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "2abc8ddb-79c6-42d8-9032-406b52e0e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matched_queries(res):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of queries with matching documents in the database.\n",
    "\n",
    "    Parameters:\n",
    "    res (list): A list containing query results. Each element in the list represents the result of a query,\n",
    "                and an empty list indicates that no matching documents were found for that query.\n",
    "\n",
    "    Returns:\n",
    "    float: The percentage of queries with matching documents, as a value between 0 and 100.\n",
    "\n",
    "    Example:\n",
    "    >>> results = [[1, 2], [], [3, 4], [], [], [5, 6]]\n",
    "    >>> matched_percentage = matched_queries(results)\n",
    "    >>> print(matched_percentage)\n",
    "    50.0\n",
    "    \"\"\"\n",
    "    \n",
    "    return 100 - not_matched_queries(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "e78919d9-9501-4226-b733-2845cc3b8526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_queries(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "78fbc7bc-735b-4e3a-846d-6e47b1ececb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_of_document_used(res, number_of_chunck_of_data):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of unique documents that were used in at least one query.\n",
    "\n",
    "    Parameters:\n",
    "    res (list): A nested list of query results. Each inner list contains objects with an 'id' attribute.\n",
    "                These objects represent documents associated with query results.\n",
    "    number_of_chunck_of_data (int): The total number of data chunks available in the dataset.\n",
    "\n",
    "    Returns:\n",
    "    float: The percentage of unique documents used in queries, as a value between 0 and 100.\n",
    "\n",
    "    Example:\n",
    "    >>> results = [[doc1, doc2], [doc2, doc3], [doc4], [doc5]]\n",
    "    >>> num_chunks = 10\n",
    "    >>> percentage_used = percentage_of_document_used(results, num_chunks)\n",
    "    >>> print(percentage_used)\n",
    "    40.0\n",
    "    \"\"\"\n",
    "    # Extract unique 'id' values from the nested list and calculate the percentage used.\n",
    "    flattened_res = [j.id for i in res for j in i if hasattr(j, 'id')]\n",
    "    unique_ids = np.unique(flattened_res)\n",
    "\n",
    "    return len(unique_ids) / number_of_chunck_of_data * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "4bf2946b-4081-46e3-bd67-83bf023c0ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.418530351437699"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_of_document_used(res, number_of_chunck_of_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
