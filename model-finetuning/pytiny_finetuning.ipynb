{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning Tinyllama on Elon Musk's Tweets using Axolotl\n",
        "\n",
        "This notebook demonstrates the utilization of the [axolotl](https://github.com/OpenAccess-AI-Collective/axolotl) tool to perform fine-tuning on the [Tinyllama](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0) model using the dataset of tweets authored by Elon Musk.\n",
        "\n",
        "Throughout this project, we employ Weight and Biases to monitor the fine-tuning process, ensuring that we can track and analyze the model's performance as it adapts to the specific tweet data.\n",
        "\n",
        "We use the following config file that can be found on github:\n",
        "https://github.com/Skower/mlpops/blob/d676a2755426f0f94ee03a3649ba8c6c6f2d1d4e/model-finetuning/TinyLlamusk.yml\n",
        "\n",
        "```\n",
        "base_model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
        "model_type: LlamaForCausalLM\n",
        "tokenizer_type: LlamaTokenizer\n",
        "is_llama_derived_model: true\n",
        "hub_model_id: Pytiny\n",
        "\n",
        "load_in_8bit: false\n",
        "load_in_4bit: true\n",
        "strict: false\n",
        "\n",
        "datasets:\n",
        "    - path: mlabonne/Evol-Instruct-Python-1k\n",
        "      type: alpaca\n",
        "dataset_prepared_path:\n",
        "val_set_size: 0.02\n",
        "output_dir: ./qlora-out\n",
        "\n",
        "adapter: qlora\n",
        "lora_model_dir:\n",
        "\n",
        "sequence_len: 2048\n",
        "sample_packing: true\n",
        "pad_to_sequence_len: true\n",
        "\n",
        "lora_r: 32\n",
        "lora_alpha: 16\n",
        "lora_dropout: 0.05\n",
        "lora_target_modules:\n",
        "lora_target_linear: true\n",
        "lora_fan_in_fan_out:\n",
        "\n",
        "wandb_project: axolotl-pytiny\n",
        "wandb_entity:\n",
        "wandb_watch:\n",
        "wandb_name:\n",
        "wandb_log_model:\n",
        "\n",
        "gradient_accumulation_steps: 2\n",
        "micro_batch_size: 1\n",
        "num_epochs: 4\n",
        "optimizer: paged_adamw_32bit\n",
        "lr_scheduler: cosine\n",
        "learning_rate: 0.0002\n",
        "\n",
        "train_on_inputs: false\n",
        "group_by_length: false\n",
        "bf16: false\n",
        "fp16: true\n",
        "tf32: false\n",
        "\n",
        "gradient_checkpointing: true\n",
        "early_stopping_patience:\n",
        "resume_from_checkpoint:\n",
        "local_rank:\n",
        "logging_steps: 1\n",
        "xformers_attention:\n",
        "flash_attention: false\n",
        "\n",
        "warmup_steps: 10\n",
        "evals_per_epoch: 2\n",
        "saves_per_epoch: 1\n",
        "debug:\n",
        "deepspeed:\n",
        "weight_decay: 0.0\n",
        "fsdp:\n",
        "fsdp_config:\n",
        "special_tokens:\n",
        "    bos_token: \"<s>\"\n",
        "    eos_token: \"</s>\"\n",
        "    unk_token: \"<unk>\"\n",
        "```"
      ],
      "metadata": {
        "id": "Qe7I_RZtHIgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U -qqq torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYbmX_4WWEZn",
        "outputId": "19af1232-bc18-4144-cfe6-e06034e346df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/OpenAccess-AI-Collective/axolotl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPL0LhgxKkha",
        "outputId": "5a0dcd35-732e-4495-ac4b-541d530b5eae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'axolotl'...\n",
            "remote: Enumerating objects: 9596, done.\u001b[K\n",
            "remote: Counting objects: 100% (2452/2452), done.\u001b[K\n",
            "remote: Compressing objects: 100% (395/395), done.\u001b[K\n",
            "remote: Total 9596 (delta 2262), reused 2104 (delta 2038), pack-reused 7144\u001b[K\n",
            "Receiving objects: 100% (9596/9596), 3.17 MiB | 14.70 MiB/s, done.\n",
            "Resolving deltas: 100% (6263/6263), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd axolotl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJHtg3fwOMyw",
        "outputId": "95cec454-07c7-41ee-f351-84ab76fadba7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/axolotl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install packaging"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgLSxXU3OOvu",
        "outputId": "05de619b-a2eb-4558-d2bb-e46c51aedeec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (23.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -e '.[flash-attn,deepspeed]'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybODdoNiOR5i",
        "outputId": "20526520-cfc8-4968-be77-4f7ff4538853"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/axolotl\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers@ git+https://github.com/huggingface/transformers.git@3cefac1d974db5e2825a0cb2b842883a628be7a0 (from axolotl==0.3.0)\n",
            "  Cloning https://github.com/huggingface/transformers.git (to revision 3cefac1d974db5e2825a0cb2b842883a628be7a0) to /tmp/pip-install-k2rxmz3q/transformers_955bf95d6de549cfac7d9f4625103655\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-install-k2rxmz3q/transformers_955bf95d6de549cfac7d9f4625103655\n",
            "  Running command git rev-parse -q --verify 'sha^3cefac1d974db5e2825a0cb2b842883a628be7a0'\n",
            "  Running command git fetch -q https://github.com/huggingface/transformers.git 3cefac1d974db5e2825a0cb2b842883a628be7a0\n",
            "  Running command git checkout -q 3cefac1d974db5e2825a0cb2b842883a628be7a0\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 3cefac1d974db5e2825a0cb2b842883a628be7a0\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate@ git+https://github.com/huggingface/accelerate.git@0d2280dadc6a93413a5496613b7fdda3a4d2551b (from axolotl==0.3.0)\n",
            "  Cloning https://github.com/huggingface/accelerate.git (to revision 0d2280dadc6a93413a5496613b7fdda3a4d2551b) to /tmp/pip-install-k2rxmz3q/accelerate_19e32920b08b483580d92be61aecb748\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-install-k2rxmz3q/accelerate_19e32920b08b483580d92be61aecb748\n",
            "  Running command git rev-parse -q --verify 'sha^0d2280dadc6a93413a5496613b7fdda3a4d2551b'\n",
            "  Running command git fetch -q https://github.com/huggingface/accelerate.git 0d2280dadc6a93413a5496613b7fdda3a4d2551b\n",
            "  Running command git checkout -q 0d2280dadc6a93413a5496613b7fdda3a4d2551b\n",
            "  Resolved https://github.com/huggingface/accelerate.git to commit 0d2280dadc6a93413a5496613b7fdda3a4d2551b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging==23.2 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.3.0) (23.2)\n",
            "Collecting peft==0.7.0 (from axolotl==0.3.0)\n",
            "  Downloading peft-0.7.0-py3-none-any.whl (168 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers==0.15.0 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.3.0) (0.15.0)\n",
            "Collecting bitsandbytes>=0.41.1 (from axolotl==0.3.0)\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from axolotl==0.3.0)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting fire (from axolotl==0.3.0)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.3.0) (6.0.1)\n",
            "Collecting datasets>=2.15.0 (from axolotl==0.3.0)\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece (from axolotl==0.3.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from axolotl==0.3.0)\n",
            "  Downloading wandb-0.16.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from axolotl==0.3.0)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xformers==0.0.22 (from axolotl==0.3.0)\n",
            "  Downloading xformers-0.0.22-cp310-cp310-manylinux2014_x86_64.whl (211.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/211.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optimum==1.13.2 (from axolotl==0.3.0)\n",
            "  Downloading optimum-1.13.2.tar.gz (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.0/301.0 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hf_transfer (from axolotl==0.3.0)\n",
            "  Downloading hf_transfer-0.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama (from axolotl==0.3.0)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from axolotl==0.3.0) (0.58.1)\n",
            "Collecting numpy>=1.24.4 (from axolotl==0.3.0)\n",
            "  Downloading numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mlflow (from axolotl==0.3.0)\n",
            "  Downloading mlflow-2.9.2-py3-none-any.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bert-score==0.3.13 (from axolotl==0.3.0)\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate==0.4.0 (from axolotl==0.3.0)\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge-score==0.1.2 (from axolotl==0.3.0)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from axolotl==0.3.0) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from axolotl==0.3.0) (1.2.2)\n",
            "Collecting pynvml (from axolotl==0.3.0)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting art (from axolotl==0.3.0)\n",
            "  Downloading art-6.1-py3-none-any.whl (599 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.8/599.8 kB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fschat==0.2.34 (from axolotl==0.3.0)\n",
            "  Downloading fschat-0.2.34-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.1/220.1 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==3.50.2 (from axolotl==0.3.0)\n",
            "  Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from axolotl==0.3.0) (2.15.1)\n",
            "Collecting s3fs (from axolotl==0.3.0)\n",
            "  Downloading s3fs-2023.12.2-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.10/dist-packages (from axolotl==0.3.0) (2023.6.0)\n",
            "Collecting trl>=0.7.9 (from axolotl==0.3.0)\n",
            "  Downloading trl-0.7.10-py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flash-attn==2.3.3 (from axolotl==0.3.0)\n",
            "  Downloading flash_attn-2.3.3.tar.gz (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deepspeed (from axolotl==0.3.0)\n",
            "  Downloading deepspeed-0.13.0.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.3.0) (2.1.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.3.0) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.3.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.3.0) (4.66.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score==0.3.13->axolotl==0.3.0) (3.7.1)\n",
            "Collecting dill (from evaluate==0.4.0->axolotl==0.3.0)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->axolotl==0.3.0) (3.4.1)\n",
            "Collecting multiprocess (from evaluate==0.4.0->axolotl==0.3.0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->axolotl==0.3.0) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.0->axolotl==0.3.0) (0.20.2)\n",
            "Collecting responses<0.19 (from evaluate==0.4.0->axolotl==0.3.0)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting ninja (from flash-attn==2.3.3->axolotl==0.3.0)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.34->axolotl==0.3.0) (3.9.1)\n",
            "Collecting fastapi (from fschat==0.2.34->axolotl==0.3.0)\n",
            "  Downloading fastapi-0.109.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from fschat==0.2.34->axolotl==0.3.0)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown2[all] (from fschat==0.2.34->axolotl==0.3.0)\n",
            "  Downloading markdown2-2.4.12-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nh3 (from fschat==0.2.34->axolotl==0.3.0)\n",
            "  Downloading nh3-0.2.15-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.34->axolotl==0.3.0) (3.0.43)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.34->axolotl==0.3.0) (1.10.13)\n",
            "Requirement already satisfied: rich>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.34->axolotl==0.3.0) (13.7.0)\n",
            "Collecting shortuuid (from fschat==0.2.34->axolotl==0.3.0)\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting tiktoken (from fschat==0.2.34->axolotl==0.3.0)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn (from fschat==0.2.34->axolotl==0.3.0)\n",
            "  Downloading uvicorn-0.26.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio==3.50.2->axolotl==0.3.0)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl==0.3.0) (4.2.2)\n",
            "Collecting ffmpy (from gradio==3.50.2->axolotl==0.3.0)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.6.1 (from gradio==3.50.2->axolotl==0.3.0)\n",
            "  Downloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl==0.3.0) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl==0.3.0) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl==0.3.0) (2.1.3)\n",
            "Collecting orjson~=3.0 (from gradio==3.50.2->axolotl==0.3.0)\n",
            "  Downloading orjson-3.9.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl==0.3.0) (9.4.0)\n",
            "Collecting pydub (from gradio==3.50.2->axolotl==0.3.0)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==3.50.2->axolotl==0.3.0)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio==3.50.2->axolotl==0.3.0)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl==0.3.0) (4.5.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio==3.50.2->axolotl==0.3.0)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from optimum==1.13.2->axolotl==0.3.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum==1.13.2->axolotl==0.3.0) (1.12)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->axolotl==0.3.0) (5.9.5)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->axolotl==0.3.0) (0.4.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->axolotl==0.3.0) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->axolotl==0.3.0) (3.8.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score==0.1.2->axolotl==0.3.0) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->axolotl==0.3.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->axolotl==0.3.0) (3.2.0)\n",
            "Collecting torch>=1.0.0 (from bert-score==0.3.13->axolotl==0.3.0)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0) (3.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0) (3.2.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch>=1.0.0->bert-score==0.3.13->axolotl==0.3.0)\n",
            "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.15.0->axolotl==0.3.0) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.15.0->axolotl==0.3.0) (0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers@ git+https://github.com/huggingface/transformers.git@3cefac1d974db5e2825a0cb2b842883a628be7a0->axolotl==0.3.0) (2023.6.3)\n",
            "Collecting tyro>=0.5.11 (from trl>=0.7.9->axolotl==0.3.0)\n",
            "  Downloading tyro-0.6.6-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hjson (from deepspeed->axolotl==0.3.0)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed->axolotl==0.3.0) (9.0.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->axolotl==0.3.0) (2.4.0)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs->axolotl==0.3.0) (4.4.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs->axolotl==0.3.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (from gcsfs->axolotl==0.3.0) (1.2.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from gcsfs->axolotl==0.3.0) (2.8.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->axolotl==0.3.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow->axolotl==0.3.0) (2.2.1)\n",
            "Collecting databricks-cli<1,>=0.8.7 (from mlflow->axolotl==0.3.0)\n",
            "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow->axolotl==0.3.0) (0.4)\n",
            "Collecting gitpython<4,>=2.1.0 (from mlflow->axolotl==0.3.0)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->axolotl==0.3.0) (3.20.3)\n",
            "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow->axolotl==0.3.0) (2023.3.post1)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->axolotl==0.3.0) (7.0.1)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->axolotl==0.3.0) (0.4.4)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow->axolotl==0.3.0)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker<7,>=4.0.0 (from mlflow->axolotl==0.3.0)\n",
            "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow->axolotl==0.3.0) (2.2.5)\n",
            "Collecting querystring-parser<2 (from mlflow->axolotl==0.3.0)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->axolotl==0.3.0) (2.0.24)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow->axolotl==0.3.0) (3.5.2)\n",
            "Collecting gunicorn<22 (from mlflow->axolotl==0.3.0)\n",
            "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->axolotl==0.3.0) (0.41.1)\n",
            "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs->axolotl==0.3.0)\n",
            "  Downloading aiobotocore-2.11.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of s3fs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting s3fs (from axolotl==0.3.0)\n",
            "  Downloading s3fs-2023.12.1-py3-none-any.whl (28 kB)\n",
            "  Downloading s3fs-2023.10.0-py3-none-any.whl (28 kB)\n",
            "Collecting aiobotocore~=2.7.0 (from s3fs->axolotl==0.3.0)\n",
            "  Downloading aiobotocore-2.7.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3fs (from axolotl==0.3.0)\n",
            "  Downloading s3fs-2023.9.2-py3-none-any.whl (28 kB)\n",
            "Collecting aiobotocore~=2.5.4 (from s3fs->axolotl==0.3.0)\n",
            "  Downloading aiobotocore-2.5.4-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting s3fs (from axolotl==0.3.0)\n",
            "  Downloading s3fs-2023.9.1-py3-none-any.whl (28 kB)\n",
            "  Downloading s3fs-2023.9.0-py3-none-any.whl (28 kB)\n",
            "  Downloading s3fs-2023.6.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl==0.3.0) (1.60.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl==0.3.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl==0.3.0) (3.0.1)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->axolotl==0.3.0)\n",
            "  Downloading sentry_sdk-1.39.2-py2.py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->axolotl==0.3.0)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->axolotl==0.3.0)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl==0.3.0) (1.4.4)\n",
            "Collecting botocore<1.31.18,>=1.31.17 (from aiobotocore~=2.5.4->s3fs->axolotl==0.3.0)\n",
            "  Downloading botocore-1.31.17-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore~=2.5.4->s3fs->axolotl==0.3.0) (1.14.1)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore~=2.5.4->s3fs->axolotl==0.3.0)\n",
            "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.34->axolotl==0.3.0) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.34->axolotl==0.3.0) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.34->axolotl==0.3.0) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.34->axolotl==0.3.0) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.34->axolotl==0.3.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.34->axolotl==0.3.0) (4.0.3)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow->axolotl==0.3.0)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.3.0) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.3.0) (0.12.0)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->axolotl==0.3.0) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->axolotl==0.3.0) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->axolotl==0.3.0) (0.9.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow->axolotl==0.3.0) (2.0.7)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<7,>=4.0.0->mlflow->axolotl==0.3.0) (1.7.0)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow->axolotl==0.3.0) (2.1.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow->axolotl==0.3.0)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs->axolotl==0.3.0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs->axolotl==0.3.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs->axolotl==0.3.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib->gcsfs->axolotl==0.3.0) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow->axolotl==0.3.0) (3.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0) (2.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3.0.0->fschat==0.2.34->axolotl==0.3.0) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.13->axolotl==0.3.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.13->axolotl==0.3.0) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score==0.3.13->axolotl==0.3.0) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat==0.2.34->axolotl==0.3.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat==0.2.34->axolotl==0.3.0) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow->axolotl==0.3.0) (3.0.3)\n",
            "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.11->trl>=0.7.9->axolotl==0.3.0)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl>=0.7.9->axolotl==0.3.0)\n",
            "  Downloading shtab-1.6.5-py3-none-any.whl (13 kB)\n",
            "Collecting h11>=0.8 (from uvicorn->fschat==0.2.34->axolotl==0.3.0)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->optimum==1.13.2->axolotl==0.3.0)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.36.0,>=0.35.0 (from fastapi->fschat==0.2.34->axolotl==0.3.0)\n",
            "  Downloading starlette-0.35.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=4.0 (from gradio==3.50.2->axolotl==0.3.0)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs->axolotl==0.3.0) (2.11.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs->axolotl==0.3.0) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs->axolotl==0.3.0) (2.7.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->fschat==0.2.34->axolotl==0.3.0) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->fschat==0.2.34->axolotl==0.3.0)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->fschat==0.2.34->axolotl==0.3.0) (1.3.0)\n",
            "Collecting wavedrom (from markdown2[all]->fschat==0.2.34->axolotl==0.3.0)\n",
            "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum==1.13.2->axolotl==0.3.0) (1.3.0)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore<1.31.18,>=1.31.17->aiobotocore~=2.5.4->s3fs->axolotl==0.3.0)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3<3,>=1.26.7 (from databricks-cli<1,>=0.8.7->mlflow->axolotl==0.3.0)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow->axolotl==0.3.0)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs->axolotl==0.3.0) (1.62.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage->gcsfs->axolotl==0.3.0) (1.5.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.3.0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.3.0) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl==0.3.0) (0.17.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat==0.2.34->axolotl==0.3.0) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs->axolotl==0.3.0) (0.5.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->fschat==0.2.34->axolotl==0.3.0) (1.2.0)\n",
            "Collecting svgwrite (from wavedrom->markdown2[all]->fschat==0.2.34->axolotl==0.3.0)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: flash-attn, optimum, rouge-score, accelerate, transformers, deepspeed, fire, ffmpy, wavedrom, lit\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.3.3-cp310-cp310-linux_x86_64.whl size=57042553 sha256=b1df92cb5bd7657d38b789dd48e907aa3e0bd2715c817eb85f3c4320bb11fb3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/e6/fa/941802ec61d1afd320d27160ab1db98e6dba65381f84b76d4a\n",
            "  Building wheel for optimum (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optimum: filename=optimum-1.13.2-py3-none-any.whl size=395599 sha256=8935e6b044eb03e02674e392680ef444d8b9e9f7f00c5409e410e794307e7e41\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/b7/2c/79405d98f0943373d8546daeae25a3d377f7659ca0cbe48699\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=a7a2d062b30e52f269d11fca8fbcb4721f40454f72cfa7a7d55cc083c176967a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for accelerate: filename=accelerate-0.25.0.dev0-py3-none-any.whl size=270681 sha256=6a4cdf25aa57d7e80d8e98d527282d8af596d966f44b988302c24b1708b9b9a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/68/78/d67f4ac8459107cc58c81947b8d2e023be89000f47a1f126a4\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.37.0.dev0-py3-none-any.whl size=8281628 sha256=b11e97ee53341bdcfa07e80cceb899c724d248fbb52d767524e109e8916a1686\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/a7/ac/d5e9fcb37c493787b4af201cf8e3125002c8269b835a774650\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.13.0-py3-none-any.whl size=1350527 sha256=0d0b72ac3849c12500f8ccd122ab8ff71346c187d274c33468946e27d3489240\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/f3/4a/7479a14c575b5a2c968454d954ef38c11be783eec500d7855d\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=6daa79d64823675a4caeb1ca09890ed32f9ebcfe8655444e2528237162744fde\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=04d870188ede723f05541004b38b4d499963230412f07aa1aa0ce2ae390af310\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=4f91ed3d859396399ea26c8706adbc6c25447ecd1fdf9efc3328d6c57f4a50fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=197cc96cd8b3df0424f0e1eb36498df3637d1953b6cc91fcf5eba3b966a4223c\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
            "Successfully built flash-attn optimum rouge-score accelerate transformers deepspeed fire ffmpy wavedrom lit\n",
            "Installing collected packages: sentencepiece, pydub, ninja, nh3, lit, hjson, ffmpy, addict, websockets, urllib3, typing-extensions, svgwrite, smmap, shtab, shortuuid, setproctitle, semantic-version, querystring-parser, python-multipart, pynvml, orjson, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, markdown2, Mako, jmespath, humanfriendly, hf_transfer, h11, gunicorn, fire, einops, docstring-parser, docker-pycreds, dill, colorama, art, aioitertools, aiofiles, wavedrom, uvicorn, starlette, sentry-sdk, rouge-score, nvidia-cusolver-cu11, nvidia-cudnn-cu11, multiprocess, httpcore, gitdb, coloredlogs, botocore, tyro, tiktoken, responses, httpx, gitpython, fastapi, docker, databricks-cli, bitsandbytes, alembic, aiobotocore, wandb, s3fs, mlflow, gradio-client, fschat, datasets, transformers, gradio, evaluate, triton, torch, accelerate, xformers, trl, peft, optimum, bert-score, flash-attn, deepspeed, axolotl\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.2\n",
            "    Uninstalling torch-2.1.2:\n",
            "      Successfully uninstalled torch-2.1.2\n",
            "  Running setup.py develop for axolotl\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\n",
            "torchaudio 2.1.2 requires torch==2.1.2, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.2 requires torch==2.1.2, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.0 accelerate-0.25.0.dev0 addict-2.4.0 aiobotocore-2.5.4 aiofiles-23.2.1 aioitertools-0.11.0 alembic-1.13.1 art-6.1 axolotl bert-score-0.3.13 bitsandbytes-0.42.0 botocore-1.31.17 colorama-0.4.6 coloredlogs-15.0.1 databricks-cli-0.18.0 datasets-2.16.1 deepspeed-0.13.0 dill-0.3.7 docker-6.1.3 docker-pycreds-0.4.0 docstring-parser-0.15 einops-0.7.0 evaluate-0.4.0 fastapi-0.109.0 ffmpy-0.3.1 fire-0.5.0 flash-attn-2.3.3 fschat-0.2.34 gitdb-4.0.11 gitpython-3.1.41 gradio-3.50.2 gradio-client-0.6.1 gunicorn-21.2.0 h11-0.14.0 hf_transfer-0.1.4 hjson-3.1.0 httpcore-1.0.2 httpx-0.26.0 humanfriendly-10.0 jmespath-1.0.1 lit-17.0.6 markdown2-2.4.12 mlflow-2.9.2 multiprocess-0.70.15 nh3-0.2.15 ninja-1.11.1.1 numpy-1.26.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 optimum-1.13.2 orjson-3.9.12 peft-0.7.0 pydub-0.25.1 pynvml-11.5.0 python-multipart-0.0.6 querystring-parser-1.2.4 responses-0.18.0 rouge-score-0.1.2 s3fs-2023.6.0 semantic-version-2.10.0 sentencepiece-0.1.99 sentry-sdk-1.39.2 setproctitle-1.3.3 shortuuid-1.0.11 shtab-1.6.5 smmap-5.0.1 starlette-0.35.1 svgwrite-1.4.3 tiktoken-0.5.2 torch-2.0.1 transformers-4.37.0.dev0 triton-2.0.0 trl-0.7.10 typing-extensions-4.9.0 tyro-0.6.6 urllib3-1.26.18 uvicorn-0.26.0 wandb-0.16.2 wavedrom-2.0.3.post3 websockets-11.0.3 xformers-0.0.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U git+https://github.com/huggingface/peft.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCjFq30GOlff",
        "outputId": "657bab48-3a46-4277-adac-4b3bb792b173"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/peft.git\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-askj8y2l\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-askj8y2l\n",
            "  Resolved https://github.com/huggingface/peft.git to commit ebbff4023ad276cbcb2466fd7e99be7d3ae0ae11\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (1.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (2.0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (4.37.0.dev0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (4.66.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (0.25.0.dev0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (0.4.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.2.dev0) (0.20.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.2.dev0) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.2.dev0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.2.dev0) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.7.2.dev0) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.2.dev0) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.7.2.dev0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.7.2.dev0) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.7.2.dev0) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.7.2.dev0) (17.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.7.2.dev0) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.7.2.dev0) (0.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.7.2.dev0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.2.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.2.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.2.dev0) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.7.2.dev0) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.7.2.dev0) (1.3.0)\n",
            "Building wheels for collected packages: peft\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.7.2.dev0-py3-none-any.whl size=183138 sha256=3d87626910ac698571f5e0237b4f9700ea73ed08a8b088f00f2320e30fc12d38\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mu6yujqn/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n",
            "Successfully built peft\n",
            "Installing collected packages: peft\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.7.0\n",
            "    Uninstalling peft-0.7.0:\n",
            "      Successfully uninstalled peft-0.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "axolotl 0.3.0 requires peft==0.7.0, but you have peft 0.7.2.dev0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed peft-0.7.2.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U flash-attn --no-build-isolation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSkkFsAlYK7h",
        "outputId": "b81a278f-0e57-4bee-d29a-8aa326d6c3dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flash-attn in /usr/local/lib/python3.10/dist-packages (2.3.3)\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.4.2.tar.gz (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.0.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from flash-attn) (23.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from flash-attn) (1.11.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->flash-attn) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->flash-attn) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flash-attn) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->flash-attn) (17.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.4.2-cp310-cp310-linux_x86_64.whl size=113930372 sha256=2c7ddc942e0715ef4a7ab62e3404b519a7ac040b3b6eae8fedcdc08a36ced786\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/cf/7f/d14555553b5b30698dae0a4159fdd058157e7021cec565ecaa\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "  Attempting uninstall: flash-attn\n",
            "    Found existing installation: flash-attn 2.3.3\n",
            "    Uninstalling flash-attn-2.3.3:\n",
            "      Successfully uninstalled flash-attn-2.3.3\n",
            "Successfully installed flash-attn-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Skower/mlpops/blob/908893f707d2b28b0bcc7dd1bc501b759a52df64/model-finetuning/pytiny.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUdsJh_-U6I-",
        "outputId": "5e3495f8-a420-4b62-be39-bd8bbb0bd94d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%wget` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env HUGGING_FACE_HUB_TOKEN=\"<YOUR_KEY_HERE>\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fixS01ylPyGJ",
        "outputId": "1f77f0c0-4cfa-4680-cb43-1018f9e7f1ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: HUGGING_FACE_HUB_TOKEN=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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env WANDB_API_KEY=\"<YOUR_KEY_HERE>\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GizI-Dm5QKOq",
        "outputId": "d6c66f1b-daa8-4bc6-eda7-22378927ef34"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_API_KEY=fcbdc8ae35ee4c6ccbb132cb80ec158938fb44bb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch -m axolotl.cli.train pytiny.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od2rgdY4PiwR",
        "outputId": "c587c6cc-826a-428c-e2b9-57c4e4ad22bf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2024-01-21 11:55:09.547232: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-21 11:55:09.547295: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-21 11:55:09.549614: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-21 11:55:11.016214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
            "  warnings.warn(\n",
            "[2024-01-21 11:55:12,875] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "config.json: 100% 608/608 [00:00<00:00, 3.07MB/s]\n",
            "[2024-01-21 11:55:21,724] [INFO] [axolotl.normalize_config:163] [PID:8731] [RANK:0] GPU memory usage baseline: 0.000GB (+0.255GB misc)\u001b[39m\n",
            "                                 dP            dP   dP \n",
            "                                 88            88   88 \n",
            "      .d8888b. dP.  .dP .d8888b. 88 .d8888b. d8888P 88 \n",
            "      88'  `88  `8bd8'  88'  `88 88 88'  `88   88   88 \n",
            "      88.  .88  .d88b.  88.  .88 88 88.  .88   88   88 \n",
            "      `88888P8 dP'  `dP `88888P' dP `88888P'   dP   dP \n",
            "                                                       \n",
            "                                                       \n",
            "\n",
            "tokenizer_config.json: 100% 1.29k/1.29k [00:00<00:00, 2.76MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 10.5MB/s]\n",
            "special_tokens_map.json: 100% 551/551 [00:00<00:00, 4.44MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 25.4MB/s]\n",
            "[2024-01-21 11:55:23,026] [DEBUG] [axolotl.load_tokenizer:210] [PID:8731] [RANK:0] EOS: 2 / </s>\u001b[39m\n",
            "[2024-01-21 11:55:23,027] [DEBUG] [axolotl.load_tokenizer:211] [PID:8731] [RANK:0] BOS: 1 / <s>\u001b[39m\n",
            "[2024-01-21 11:55:23,027] [DEBUG] [axolotl.load_tokenizer:212] [PID:8731] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
            "[2024-01-21 11:55:23,027] [DEBUG] [axolotl.load_tokenizer:213] [PID:8731] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
            "[2024-01-21 11:55:23,027] [INFO] [axolotl.load_tokenizer:218] [PID:8731] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2024-01-21 11:55:23,027] [INFO] [axolotl.load_tokenized_prepared_datasets:161] [PID:8731] [RANK:0] Unable to find prepared dataset in last_run_prepared/4a4d20264815633036339c11c7767fab\u001b[39m\n",
            "[2024-01-21 11:55:23,027] [INFO] [axolotl.load_tokenized_prepared_datasets:162] [PID:8731] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "\u001b[33m[2024-01-21 11:55:23,027] [WARNING] [axolotl.load_tokenized_prepared_datasets:164] [PID:8731] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset\u001b[39m\n",
            "[2024-01-21 11:55:23,027] [INFO] [axolotl.load_tokenized_prepared_datasets:171] [PID:8731] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
            "Downloading readme: 100% 756/756 [00:00<00:00, 5.82MB/s]\n",
            "Downloading data: 100% 2.32M/2.32M [00:00<00:00, 9.45MB/s]\n",
            "Generating train split: 100% 1000/1000 [00:00<00:00, 14976.50 examples/s]\n",
            "Map (num_proc=2): 100% 1000/1000 [00:12<00:00, 82.34 examples/s]\n",
            "[2024-01-21 11:55:38,339] [INFO] [axolotl.load_tokenized_prepared_datasets:380] [PID:8731] [RANK:0] merging datasets\u001b[39m\n",
            "Map (num_proc=2): 100% 1000/1000 [00:01<00:00, 894.81 examples/s]\n",
            "[2024-01-21 11:55:39,523] [DEBUG] [axolotl.log:61] [PID:8731] [RANK:0] max_input_len: 2088\u001b[39m\n",
            "Filter (num_proc=2): 100% 1000/1000 [00:02<00:00, 384.94 examples/s]\n",
            "[2024-01-21 11:55:42,184] [INFO] [axolotl.load_tokenized_prepared_datasets:390] [PID:8731] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/4a4d20264815633036339c11c7767fab\u001b[39m\n",
            "Saving the dataset (1/1 shards): 100% 986/986 [00:00<00:00, 15583.92 examples/s]\n",
            "[2024-01-21 11:55:42,263] [DEBUG] [axolotl.log:61] [PID:8731] [RANK:0] total_num_tokens: 1532799\u001b[39m\n",
            "[2024-01-21 11:55:42,277] [DEBUG] [axolotl.log:61] [PID:8731] [RANK:0] `total_supervised_tokens: 1081957`\u001b[39m\n",
            "[2024-01-21 11:55:47,947] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 11:55:47,947] [DEBUG] [axolotl.log:61] [PID:8731] [RANK:0] data_loader_len: 739\u001b[39m\n",
            "[2024-01-21 11:55:47,947] [INFO] [axolotl.log:61] [PID:8731] [RANK:0] sample_packing_eff_est across ranks: [1.0073486328125]\u001b[39m\n",
            "[2024-01-21 11:55:47,947] [DEBUG] [axolotl.log:61] [PID:8731] [RANK:0] sample_packing_eff_est: None\u001b[39m\n",
            "[2024-01-21 11:55:47,947] [DEBUG] [axolotl.log:61] [PID:8731] [RANK:0] total_num_steps: 2956\u001b[39m\n",
            "[2024-01-21 11:55:47,953] [DEBUG] [axolotl.log:61] [PID:8731] [RANK:0] total_num_tokens: 1532799\u001b[39m\n",
            "[2024-01-21 11:55:47,973] [DEBUG] [axolotl.log:61] [PID:8731] [RANK:0] `total_supervised_tokens: 1081957`\u001b[39m\n",
            "[2024-01-21 11:55:47,978] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 11:55:47,978] [DEBUG] [axolotl.log:61] [PID:8731] [RANK:0] data_loader_len: 739\u001b[39m\n",
            "[2024-01-21 11:55:47,978] [INFO] [axolotl.log:61] [PID:8731] [RANK:0] sample_packing_eff_est across ranks: [0.7526617899197723]\u001b[39m\n",
            "[2024-01-21 11:55:47,978] [DEBUG] [axolotl.log:61] [PID:8731] [RANK:0] sample_packing_eff_est: 0.76\u001b[39m\n",
            "[2024-01-21 11:55:47,978] [DEBUG] [axolotl.log:61] [PID:8731] [RANK:0] total_num_steps: 2956\u001b[39m\n",
            "[2024-01-21 11:55:47,978] [DEBUG] [axolotl.train.log:61] [PID:8731] [RANK:0] loading tokenizer... TinyLlama/TinyLlama-1.1B-Chat-v1.0\u001b[39m\n",
            "[2024-01-21 11:55:48,526] [DEBUG] [axolotl.load_tokenizer:210] [PID:8731] [RANK:0] EOS: 2 / </s>\u001b[39m\n",
            "[2024-01-21 11:55:48,526] [DEBUG] [axolotl.load_tokenizer:211] [PID:8731] [RANK:0] BOS: 1 / <s>\u001b[39m\n",
            "[2024-01-21 11:55:48,526] [DEBUG] [axolotl.load_tokenizer:212] [PID:8731] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
            "[2024-01-21 11:55:48,526] [DEBUG] [axolotl.load_tokenizer:213] [PID:8731] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
            "[2024-01-21 11:55:48,526] [INFO] [axolotl.load_tokenizer:218] [PID:8731] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2024-01-21 11:55:48,526] [DEBUG] [axolotl.train.log:61] [PID:8731] [RANK:0] loading model and peft_config...\u001b[39m\n",
            "[2024-01-21 11:55:48,578] [INFO] [axolotl.load_model:335] [PID:8731] [RANK:0] patching _expand_mask\u001b[39m\n",
            "model.safetensors: 100% 2.20G/2.20G [00:19<00:00, 112MB/s] \n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 504kB/s]\n",
            "[2024-01-21 11:56:15,960] [INFO] [axolotl.load_model:615] [PID:8731] [RANK:0] GPU memory usage after model load: 0.753GB (+0.022GB cache, +0.370GB misc)\u001b[39m\n",
            "[2024-01-21 11:56:15,973] [INFO] [axolotl.load_model:639] [PID:8731] [RANK:0] converting PEFT model w/ prepare_model_for_kbit_training\u001b[39m\n",
            "[2024-01-21 11:56:15,980] [INFO] [axolotl.load_model:651] [PID:8731] [RANK:0] converting modules to torch.float16 for flash attention\u001b[39m\n",
            "[2024-01-21 11:56:15,984] [INFO] [axolotl.load_lora:756] [PID:8731] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'o_proj', 'up_proj', 'v_proj', 'k_proj', 'q_proj']\u001b[39m\n",
            "trainable params: 25,231,360 || all params: 1,125,279,744 || trainable%: 2.2422299996542017\n",
            "[2024-01-21 11:56:16,729] [INFO] [axolotl.load_model:683] [PID:8731] [RANK:0] GPU memory usage after adapters: 0.847GB (+0.514GB cache, +0.370GB misc)\u001b[39m\n",
            "[2024-01-21 11:56:17,293] [INFO] [axolotl.train.log:61] [PID:8731] [RANK:0] Pre-saving adapter config to ./qlora-out\u001b[39m\n",
            "[2024-01-21 11:56:17,298] [INFO] [axolotl.train.log:61] [PID:8731] [RANK:0] Starting trainer...\u001b[39m\n",
            "[2024-01-21 11:56:17,704] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 11:56:17,706] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbastien-pouessel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/axolotl/wandb/run-20240121_115618-0e3121ub\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdifferent-sound-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/bastien-pouessel/axolotl-pytiny\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/bastien-pouessel/axolotl-pytiny/runs/0e3121ub\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n",
            "[2024-01-21 11:56:19,543] [INFO] [axolotl.callbacks.on_train_begin:572] [PID:8731] [RANK:0] The Axolotl config has been saved to the WandB run under files.\u001b[39m\n",
            "  0% 0/1944 [00:00<?, ?it/s][2024-01-21 11:56:19,547] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "{'loss': 0.5017, 'learning_rate': 2e-05, 'epoch': 0.0}\n",
            "  0% 1/1944 [00:06<3:45:35,  6.97s/it][2024-01-21 11:56:26,517] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 11:56:26,902] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 11:56:26,903] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 0/973 [00:00<?, ?it/s]\u001b[A[2024-01-21 11:56:27,519] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 2/973 [00:00<04:59,  3.25it/s]\u001b[A[2024-01-21 11:56:28,133] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 3/973 [00:01<07:02,  2.30it/s]\u001b[A[2024-01-21 11:56:28,752] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 4/973 [00:01<08:08,  1.98it/s]\u001b[A[2024-01-21 11:56:29,367] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 5/973 [00:02<08:45,  1.84it/s]\u001b[A[2024-01-21 11:56:29,987] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 6/973 [00:03<09:09,  1.76it/s]\u001b[A[2024-01-21 11:56:30,605] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 7/973 [00:03<09:24,  1.71it/s]\u001b[A[2024-01-21 11:56:31,219] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 8/973 [00:04<09:32,  1.69it/s]\u001b[A[2024-01-21 11:56:31,833] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 9/973 [00:04<09:38,  1.67it/s]\u001b[A[2024-01-21 11:56:32,450] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 10/973 [00:05<09:42,  1.65it/s]\u001b[A[2024-01-21 11:56:33,065] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 11/973 [00:06<09:45,  1.64it/s]\u001b[A[2024-01-21 11:56:33,685] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 12/973 [00:06<09:47,  1.63it/s]\u001b[A[2024-01-21 11:56:34,303] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 13/973 [00:07<09:48,  1.63it/s]\u001b[A[2024-01-21 11:56:34,921] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 14/973 [00:08<09:49,  1.63it/s]\u001b[A[2024-01-21 11:56:35,536] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 15/973 [00:08<09:49,  1.63it/s]\u001b[A[2024-01-21 11:56:36,155] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 16/973 [00:09<09:49,  1.62it/s]\u001b[A[2024-01-21 11:56:36,769] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 17/973 [00:09<09:48,  1.62it/s]\u001b[A[2024-01-21 11:56:37,389] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 18/973 [00:10<09:49,  1.62it/s]\u001b[A[2024-01-21 11:56:38,006] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 19/973 [00:11<09:48,  1.62it/s]\u001b[A[2024-01-21 11:56:38,624] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.5829594731330872, 'eval_runtime': 12.3441, 'eval_samples_per_second': 1.62, 'eval_steps_per_second': 1.62, 'epoch': 0.0}\n",
            "  0% 1/1944 [00:19<3:45:35,  6.97s/it]\n",
            "  2% 20/973 [00:11<09:48,  1.62it/s]\u001b[A\n",
            "                                    \u001b[A[2024-01-21 11:56:43,141] [INFO] [axolotl.callbacks.on_step_end:124] [PID:8731] [RANK:0] GPU memory usage while training: 0.963GB (+3.725GB cache, +0.640GB misc)\u001b[39m\n",
            "{'loss': 0.4647, 'learning_rate': 4e-05, 'epoch': 0.0}\n",
            "{'loss': 0.4738, 'learning_rate': 6e-05, 'epoch': 0.01}\n",
            "{'loss': 0.3854, 'learning_rate': 8e-05, 'epoch': 0.01}\n",
            "{'loss': 0.4874, 'learning_rate': 0.0001, 'epoch': 0.01}\n",
            "{'loss': 0.437, 'learning_rate': 0.00012, 'epoch': 0.01}\n",
            "{'loss': 0.5813, 'learning_rate': 0.00014, 'epoch': 0.01}\n",
            "{'loss': 0.2684, 'learning_rate': 0.00016, 'epoch': 0.02}\n",
            "{'loss': 0.5768, 'learning_rate': 0.00018, 'epoch': 0.02}\n",
            "{'loss': 0.3045, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
            "{'loss': 0.4349, 'learning_rate': 0.00019999986806600454, 'epoch': 0.02}\n",
            "{'loss': 0.5089, 'learning_rate': 0.00019999947226436628, 'epoch': 0.02}\n",
            "{'loss': 0.6225, 'learning_rate': 0.00019999881259612963, 'epoch': 0.03}\n",
            "{'loss': 0.4807, 'learning_rate': 0.00019999788906303518, 'epoch': 0.03}\n",
            "{'loss': 0.2278, 'learning_rate': 0.00019999670166751993, 'epoch': 0.03}\n",
            "{'loss': 0.3251, 'learning_rate': 0.000199995250412717, 'epoch': 0.03}\n",
            "{'loss': 0.5233, 'learning_rate': 0.00019999353530245572, 'epoch': 0.03}\n",
            "{'loss': 0.4724, 'learning_rate': 0.0001999915563412618, 'epoch': 0.04}\n",
            "{'loss': 0.5882, 'learning_rate': 0.00019998931353435709, 'epoch': 0.04}\n",
            "{'loss': 0.5832, 'learning_rate': 0.00019998680688765959, 'epoch': 0.04}\n",
            "{'loss': 0.4675, 'learning_rate': 0.00019998403640778358, 'epoch': 0.04}\n",
            "{'loss': 0.4826, 'learning_rate': 0.00019998100210203942, 'epoch': 0.05}\n",
            "{'loss': 0.4231, 'learning_rate': 0.0001999777039784337, 'epoch': 0.05}\n",
            "{'loss': 0.4668, 'learning_rate': 0.00019997414204566915, 'epoch': 0.05}\n",
            "{'loss': 0.4572, 'learning_rate': 0.0001999703163131445, 'epoch': 0.05}\n",
            "{'loss': 0.3335, 'learning_rate': 0.00019996622679095468, 'epoch': 0.05}\n",
            "{'loss': 0.426, 'learning_rate': 0.00019996187348989063, 'epoch': 0.06}\n",
            "{'loss': 0.3743, 'learning_rate': 0.0001999572564214393, 'epoch': 0.06}\n",
            "{'loss': 0.6784, 'learning_rate': 0.00019995237559778363, 'epoch': 0.06}\n",
            "{'loss': 0.4295, 'learning_rate': 0.00019994723103180265, 'epoch': 0.06}\n",
            "{'loss': 0.4272, 'learning_rate': 0.00019994182273707107, 'epoch': 0.06}\n",
            "{'loss': 0.4484, 'learning_rate': 0.00019993615072785978, 'epoch': 0.07}\n",
            "{'loss': 0.3739, 'learning_rate': 0.00019993021501913536, 'epoch': 0.07}\n",
            "{'loss': 0.1946, 'learning_rate': 0.00019992401562656022, 'epoch': 0.07}\n",
            "{'loss': 0.7114, 'learning_rate': 0.0001999175525664926, 'epoch': 0.07}\n",
            "{'loss': 0.7297, 'learning_rate': 0.0001999108258559864, 'epoch': 0.07}\n",
            "{'loss': 0.4933, 'learning_rate': 0.00019990383551279136, 'epoch': 0.08}\n",
            "{'loss': 0.6544, 'learning_rate': 0.00019989658155535262, 'epoch': 0.08}\n",
            "{'loss': 0.6012, 'learning_rate': 0.00019988906400281116, 'epoch': 0.08}\n",
            "{'loss': 0.5643, 'learning_rate': 0.00019988128287500335, 'epoch': 0.08}\n",
            "{'loss': 0.4816, 'learning_rate': 0.00019987323819246108, 'epoch': 0.08}\n",
            "{'loss': 0.5395, 'learning_rate': 0.00019986492997641175, 'epoch': 0.09}\n",
            "{'loss': 0.3534, 'learning_rate': 0.00019985635824877802, 'epoch': 0.09}\n",
            "{'loss': 0.4147, 'learning_rate': 0.00019984752303217797, 'epoch': 0.09}\n",
            "{'loss': 0.4427, 'learning_rate': 0.0001998384243499249, 'epoch': 0.09}\n",
            "{'loss': 0.2231, 'learning_rate': 0.0001998290622260273, 'epoch': 0.09}\n",
            "{'loss': 0.4001, 'learning_rate': 0.00019981943668518888, 'epoch': 0.1}\n",
            "{'loss': 0.4925, 'learning_rate': 0.00019980954775280832, 'epoch': 0.1}\n",
            "{'loss': 0.6504, 'learning_rate': 0.00019979939545497933, 'epoch': 0.1}\n",
            "{'loss': 0.5755, 'learning_rate': 0.00019978897981849056, 'epoch': 0.1}\n",
            "{'loss': 0.173, 'learning_rate': 0.0001997783008708256, 'epoch': 0.1}\n",
            "{'loss': 0.5799, 'learning_rate': 0.00019976735864016276, 'epoch': 0.11}\n",
            "{'loss': 0.2543, 'learning_rate': 0.00019975615315537506, 'epoch': 0.11}\n",
            "{'loss': 0.7137, 'learning_rate': 0.0001997446844460302, 'epoch': 0.11}\n",
            "{'loss': 0.336, 'learning_rate': 0.00019973295254239044, 'epoch': 0.11}\n",
            "{'loss': 0.4007, 'learning_rate': 0.0001997209574754125, 'epoch': 0.12}\n",
            "{'loss': 0.3558, 'learning_rate': 0.00019970869927674753, 'epoch': 0.12}\n",
            "{'loss': 0.5036, 'learning_rate': 0.000199696177978741, 'epoch': 0.12}\n",
            "{'loss': 0.5129, 'learning_rate': 0.0001996833936144326, 'epoch': 0.12}\n",
            "{'loss': 0.7473, 'learning_rate': 0.00019967034621755622, 'epoch': 0.12}\n",
            "{'loss': 0.4214, 'learning_rate': 0.00019965703582253965, 'epoch': 0.13}\n",
            "{'loss': 0.3426, 'learning_rate': 0.00019964346246450487, 'epoch': 0.13}\n",
            "{'loss': 0.4716, 'learning_rate': 0.00019962962617926756, 'epoch': 0.13}\n",
            "{'loss': 0.3606, 'learning_rate': 0.00019961552700333734, 'epoch': 0.13}\n",
            "{'loss': 0.447, 'learning_rate': 0.00019960116497391733, 'epoch': 0.13}\n",
            "{'loss': 0.3778, 'learning_rate': 0.00019958654012890435, 'epoch': 0.14}\n",
            "{'loss': 0.277, 'learning_rate': 0.0001995716525068887, 'epoch': 0.14}\n",
            "{'loss': 0.8609, 'learning_rate': 0.00019955650214715406, 'epoch': 0.14}\n",
            "{'loss': 0.215, 'learning_rate': 0.00019954108908967736, 'epoch': 0.14}\n",
            "{'loss': 0.6364, 'learning_rate': 0.00019952541337512868, 'epoch': 0.14}\n",
            "{'loss': 0.3862, 'learning_rate': 0.0001995094750448713, 'epoch': 0.15}\n",
            "{'loss': 0.5671, 'learning_rate': 0.00019949327414096134, 'epoch': 0.15}\n",
            "{'loss': 0.3648, 'learning_rate': 0.00019947681070614777, 'epoch': 0.15}\n",
            "{'loss': 0.3976, 'learning_rate': 0.00019946008478387238, 'epoch': 0.15}\n",
            "{'loss': 0.567, 'learning_rate': 0.00019944309641826947, 'epoch': 0.15}\n",
            "{'loss': 0.4559, 'learning_rate': 0.0001994258456541659, 'epoch': 0.16}\n",
            "{'loss': 0.5168, 'learning_rate': 0.00019940833253708097, 'epoch': 0.16}\n",
            "{'loss': 0.4497, 'learning_rate': 0.00019939055711322616, 'epoch': 0.16}\n",
            "{'loss': 0.4994, 'learning_rate': 0.00019937251942950512, 'epoch': 0.16}\n",
            "{'loss': 0.3444, 'learning_rate': 0.0001993542195335135, 'epoch': 0.16}\n",
            "{'loss': 0.4388, 'learning_rate': 0.0001993356574735389, 'epoch': 0.17}\n",
            "{'loss': 0.4995, 'learning_rate': 0.00019931683329856066, 'epoch': 0.17}\n",
            "{'loss': 0.3528, 'learning_rate': 0.00019929774705824973, 'epoch': 0.17}\n",
            "{'loss': 0.3905, 'learning_rate': 0.0001992783988029686, 'epoch': 0.17}\n",
            "{'loss': 0.2981, 'learning_rate': 0.00019925878858377113, 'epoch': 0.17}\n",
            "{'loss': 0.6008, 'learning_rate': 0.00019923891645240238, 'epoch': 0.18}\n",
            "{'loss': 0.4418, 'learning_rate': 0.00019921878246129858, 'epoch': 0.18}\n",
            "{'loss': 0.2813, 'learning_rate': 0.00019919838666358688, 'epoch': 0.18}\n",
            "{'loss': 0.484, 'learning_rate': 0.00019917772911308524, 'epoch': 0.18}\n",
            "{'loss': 0.4639, 'learning_rate': 0.00019915680986430233, 'epoch': 0.18}\n",
            "{'loss': 0.4662, 'learning_rate': 0.00019913562897243736, 'epoch': 0.19}\n",
            "{'loss': 0.6143, 'learning_rate': 0.00019911418649337997, 'epoch': 0.19}\n",
            "{'loss': 0.3914, 'learning_rate': 0.00019909248248370988, 'epoch': 0.19}\n",
            "{'loss': 0.3999, 'learning_rate': 0.00019907051700069714, 'epoch': 0.19}\n",
            "{'loss': 0.2379, 'learning_rate': 0.0001990482901023016, 'epoch': 0.2}\n",
            "{'loss': 0.3044, 'learning_rate': 0.0001990258018471729, 'epoch': 0.2}\n",
            "{'loss': 0.4327, 'learning_rate': 0.00019900305229465036, 'epoch': 0.2}\n",
            "{'loss': 0.892, 'learning_rate': 0.00019898004150476278, 'epoch': 0.2}\n",
            "{'loss': 0.3558, 'learning_rate': 0.00019895676953822822, 'epoch': 0.2}\n",
            "{'loss': 0.3893, 'learning_rate': 0.00019893323645645404, 'epoch': 0.21}\n",
            "{'loss': 0.4967, 'learning_rate': 0.00019890944232153643, 'epoch': 0.21}\n",
            "{'loss': 0.3797, 'learning_rate': 0.00019888538719626053, 'epoch': 0.21}\n",
            "{'loss': 0.2347, 'learning_rate': 0.0001988610711441001, 'epoch': 0.21}\n",
            "{'loss': 0.5212, 'learning_rate': 0.00019883649422921745, 'epoch': 0.21}\n",
            "{'loss': 0.4437, 'learning_rate': 0.00019881165651646317, 'epoch': 0.22}\n",
            "{'loss': 0.3252, 'learning_rate': 0.00019878655807137603, 'epoch': 0.22}\n",
            "{'loss': 0.7138, 'learning_rate': 0.0001987611989601828, 'epoch': 0.22}\n",
            "{'loss': 0.3679, 'learning_rate': 0.00019873557924979804, 'epoch': 0.22}\n",
            "{'loss': 0.3503, 'learning_rate': 0.000198709699007824, 'epoch': 0.22}\n",
            "{'loss': 0.3744, 'learning_rate': 0.00019868355830255033, 'epoch': 0.23}\n",
            "{'loss': 0.5586, 'learning_rate': 0.00019865715720295397, 'epoch': 0.23}\n",
            "{'loss': 0.3118, 'learning_rate': 0.00019863049577869898, 'epoch': 0.23}\n",
            "{'loss': 0.564, 'learning_rate': 0.00019860357410013638, 'epoch': 0.23}\n",
            "{'loss': 0.4115, 'learning_rate': 0.00019857639223830377, 'epoch': 0.23}\n",
            "{'loss': 0.4142, 'learning_rate': 0.00019854895026492545, 'epoch': 0.24}\n",
            "{'loss': 0.4639, 'learning_rate': 0.00019852124825241201, 'epoch': 0.24}\n",
            "{'loss': 0.3883, 'learning_rate': 0.0001984932862738601, 'epoch': 0.24}\n",
            "{'loss': 0.3453, 'learning_rate': 0.00019846506440305257, 'epoch': 0.24}\n",
            "{'loss': 0.3743, 'learning_rate': 0.00019843658271445776, 'epoch': 0.24}\n",
            "{'loss': 0.5851, 'learning_rate': 0.00019840784128322985, 'epoch': 0.25}\n",
            "{'loss': 0.3698, 'learning_rate': 0.0001983788401852082, 'epoch': 0.25}\n",
            "{'loss': 0.2955, 'learning_rate': 0.00019834957949691747, 'epoch': 0.25}\n",
            "{'loss': 0.4283, 'learning_rate': 0.00019832005929556722, 'epoch': 0.25}\n",
            "{'loss': 0.1783, 'learning_rate': 0.00019829027965905186, 'epoch': 0.25}\n",
            "{'loss': 0.2887, 'learning_rate': 0.00019826024066595027, 'epoch': 0.26}\n",
            "{'loss': 0.4947, 'learning_rate': 0.00019822994239552573, 'epoch': 0.26}\n",
            "{'loss': 0.6057, 'learning_rate': 0.00019819938492772568, 'epoch': 0.26}\n",
            "{'loss': 0.4422, 'learning_rate': 0.00019816856834318155, 'epoch': 0.26}\n",
            "{'loss': 0.2999, 'learning_rate': 0.0001981374927232084, 'epoch': 0.27}\n",
            "{'loss': 0.4334, 'learning_rate': 0.00019810615814980483, 'epoch': 0.27}\n",
            "{'loss': 0.4974, 'learning_rate': 0.00019807456470565283, 'epoch': 0.27}\n",
            "{'loss': 0.3329, 'learning_rate': 0.00019804271247411727, 'epoch': 0.27}\n",
            "{'loss': 0.3269, 'learning_rate': 0.00019801060153924608, 'epoch': 0.27}\n",
            "{'loss': 0.3648, 'learning_rate': 0.0001979782319857697, 'epoch': 0.28}\n",
            "{'loss': 0.3648, 'learning_rate': 0.00019794560389910102, 'epoch': 0.28}\n",
            "{'loss': 0.3697, 'learning_rate': 0.00019791271736533512, 'epoch': 0.28}\n",
            "{'loss': 0.5087, 'learning_rate': 0.00019787957247124907, 'epoch': 0.28}\n",
            "{'loss': 0.4102, 'learning_rate': 0.00019784616930430157, 'epoch': 0.28}\n",
            "{'loss': 0.3968, 'learning_rate': 0.00019781250795263295, 'epoch': 0.29}\n",
            "{'loss': 0.5714, 'learning_rate': 0.0001977785885050647, 'epoch': 0.29}\n",
            "{'loss': 0.3273, 'learning_rate': 0.00019774441105109943, 'epoch': 0.29}\n",
            "{'loss': 0.2736, 'learning_rate': 0.00019770997568092046, 'epoch': 0.29}\n",
            "{'loss': 0.3482, 'learning_rate': 0.0001976752824853917, 'epoch': 0.29}\n",
            "{'loss': 0.2084, 'learning_rate': 0.00019764033155605747, 'epoch': 0.3}\n",
            "{'loss': 0.4754, 'learning_rate': 0.00019760512298514198, 'epoch': 0.3}\n",
            "{'loss': 0.4101, 'learning_rate': 0.0001975696568655494, 'epoch': 0.3}\n",
            "{'loss': 0.375, 'learning_rate': 0.00019753393329086354, 'epoch': 0.3}\n",
            "{'loss': 0.4426, 'learning_rate': 0.00019749795235534737, 'epoch': 0.3}\n",
            "{'loss': 0.3529, 'learning_rate': 0.0001974617141539432, 'epoch': 0.31}\n",
            "{'loss': 0.3122, 'learning_rate': 0.0001974252187822719, 'epoch': 0.31}\n",
            "{'loss': 0.4429, 'learning_rate': 0.00019738846633663318, 'epoch': 0.31}\n",
            "{'loss': 0.3615, 'learning_rate': 0.0001973514569140049, 'epoch': 0.31}\n",
            "{'loss': 0.6665, 'learning_rate': 0.00019731419061204316, 'epoch': 0.31}\n",
            "{'loss': 0.4702, 'learning_rate': 0.00019727666752908173, 'epoch': 0.32}\n",
            "{'loss': 0.2138, 'learning_rate': 0.00019723888776413206, 'epoch': 0.32}\n",
            "{'loss': 0.401, 'learning_rate': 0.00019720085141688285, 'epoch': 0.32}\n",
            "{'loss': 0.4153, 'learning_rate': 0.00019716255858769982, 'epoch': 0.32}\n",
            "{'loss': 0.3146, 'learning_rate': 0.0001971240093776255, 'epoch': 0.32}\n",
            "{'loss': 0.4344, 'learning_rate': 0.00019708520388837897, 'epoch': 0.33}\n",
            "{'loss': 0.3955, 'learning_rate': 0.00019704614222235543, 'epoch': 0.33}\n",
            "{'loss': 0.2981, 'learning_rate': 0.0001970068244826261, 'epoch': 0.33}\n",
            "{'loss': 0.4195, 'learning_rate': 0.00019696725077293796, 'epoch': 0.33}\n",
            "{'loss': 0.6973, 'learning_rate': 0.00019692742119771338, 'epoch': 0.34}\n",
            "{'loss': 0.7502, 'learning_rate': 0.00019688733586204976, 'epoch': 0.34}\n",
            "{'loss': 0.348, 'learning_rate': 0.00019684699487171957, 'epoch': 0.34}\n",
            "{'loss': 0.3991, 'learning_rate': 0.00019680639833316975, 'epoch': 0.34}\n",
            "{'loss': 0.3844, 'learning_rate': 0.00019676554635352154, 'epoch': 0.34}\n",
            "{'loss': 0.5281, 'learning_rate': 0.00019672443904057024, 'epoch': 0.35}\n",
            "{'loss': 0.6239, 'learning_rate': 0.00019668307650278492, 'epoch': 0.35}\n",
            "{'loss': 0.3729, 'learning_rate': 0.00019664145884930808, 'epoch': 0.35}\n",
            "{'loss': 0.4671, 'learning_rate': 0.00019659958618995532, 'epoch': 0.35}\n",
            "{'loss': 0.5733, 'learning_rate': 0.0001965574586352153, 'epoch': 0.35}\n",
            "{'loss': 0.369, 'learning_rate': 0.00019651507629624902, 'epoch': 0.36}\n",
            "{'loss': 0.3517, 'learning_rate': 0.00019647243928489, 'epoch': 0.36}\n",
            "{'loss': 0.3588, 'learning_rate': 0.00019642954771364362, 'epoch': 0.36}\n",
            "{'loss': 0.4944, 'learning_rate': 0.00019638640169568702, 'epoch': 0.36}\n",
            "{'loss': 0.3937, 'learning_rate': 0.00019634300134486877, 'epoch': 0.36}\n",
            "{'loss': 0.319, 'learning_rate': 0.00019629934677570848, 'epoch': 0.37}\n",
            "{'loss': 0.3614, 'learning_rate': 0.00019625543810339652, 'epoch': 0.37}\n",
            "{'loss': 0.5436, 'learning_rate': 0.00019621127544379392, 'epoch': 0.37}\n",
            "{'loss': 0.5861, 'learning_rate': 0.00019616685891343173, 'epoch': 0.37}\n",
            "{'loss': 0.7246, 'learning_rate': 0.00019612218862951098, 'epoch': 0.37}\n",
            "{'loss': 0.7884, 'learning_rate': 0.00019607726470990229, 'epoch': 0.38}\n",
            "{'loss': 0.3441, 'learning_rate': 0.00019603208727314543, 'epoch': 0.38}\n",
            "{'loss': 0.2248, 'learning_rate': 0.00019598665643844924, 'epoch': 0.38}\n",
            "{'loss': 0.4889, 'learning_rate': 0.00019594097232569118, 'epoch': 0.38}\n",
            "{'loss': 0.3502, 'learning_rate': 0.0001958950350554169, 'epoch': 0.38}\n",
            "{'loss': 0.423, 'learning_rate': 0.00019584884474884025, 'epoch': 0.39}\n",
            "{'loss': 0.5289, 'learning_rate': 0.00019580240152784265, 'epoch': 0.39}\n",
            "{'loss': 0.4058, 'learning_rate': 0.00019575570551497287, 'epoch': 0.39}\n",
            "{'loss': 0.5127, 'learning_rate': 0.00019570875683344672, 'epoch': 0.39}\n",
            "{'loss': 0.3248, 'learning_rate': 0.0001956615556071468, 'epoch': 0.39}\n",
            "{'loss': 0.4321, 'learning_rate': 0.000195614101960622, 'epoch': 0.4}\n",
            "{'loss': 0.4452, 'learning_rate': 0.00019556639601908728, 'epoch': 0.4}\n",
            "{'loss': 0.4326, 'learning_rate': 0.00019551843790842338, 'epoch': 0.4}\n",
            "{'loss': 0.2559, 'learning_rate': 0.00019547022775517645, 'epoch': 0.4}\n",
            "{'loss': 0.0998, 'learning_rate': 0.00019542176568655757, 'epoch': 0.4}\n",
            "{'loss': 0.404, 'learning_rate': 0.00019537305183044268, 'epoch': 0.41}\n",
            "{'loss': 0.4666, 'learning_rate': 0.00019532408631537203, 'epoch': 0.41}\n",
            "{'loss': 0.3587, 'learning_rate': 0.00019527486927054994, 'epoch': 0.41}\n",
            "{'loss': 0.5001, 'learning_rate': 0.00019522540082584443, 'epoch': 0.41}\n",
            "{'loss': 0.4476, 'learning_rate': 0.0001951756811117869, 'epoch': 0.42}\n",
            "{'loss': 0.3801, 'learning_rate': 0.00019512571025957182, 'epoch': 0.42}\n",
            "{'loss': 0.2653, 'learning_rate': 0.00019507548840105618, 'epoch': 0.42}\n",
            "{'loss': 0.7443, 'learning_rate': 0.00019502501566875943, 'epoch': 0.42}\n",
            "{'loss': 0.3881, 'learning_rate': 0.00019497429219586296, 'epoch': 0.42}\n",
            "{'loss': 0.5465, 'learning_rate': 0.00019492331811620976, 'epoch': 0.43}\n",
            "{'loss': 0.8316, 'learning_rate': 0.00019487209356430413, 'epoch': 0.43}\n",
            "{'loss': 0.3565, 'learning_rate': 0.00019482061867531127, 'epoch': 0.43}\n",
            "{'loss': 0.4128, 'learning_rate': 0.0001947688935850569, 'epoch': 0.43}\n",
            "{'loss': 0.4196, 'learning_rate': 0.00019471691843002701, 'epoch': 0.43}\n",
            "{'loss': 0.2777, 'learning_rate': 0.00019466469334736739, 'epoch': 0.44}\n",
            "{'loss': 0.4576, 'learning_rate': 0.00019461221847488333, 'epoch': 0.44}\n",
            "{'loss': 0.5326, 'learning_rate': 0.0001945594939510392, 'epoch': 0.44}\n",
            "{'loss': 0.6736, 'learning_rate': 0.00019450651991495812, 'epoch': 0.44}\n",
            "{'loss': 0.376, 'learning_rate': 0.00019445329650642163, 'epoch': 0.44}\n",
            "{'loss': 0.4316, 'learning_rate': 0.00019439982386586932, 'epoch': 0.45}\n",
            "{'loss': 0.351, 'learning_rate': 0.00019434610213439832, 'epoch': 0.45}\n",
            "{'loss': 0.7555, 'learning_rate': 0.0001942921314537631, 'epoch': 0.45}\n",
            "{'loss': 0.3693, 'learning_rate': 0.000194237911966375, 'epoch': 0.45}\n",
            "{'loss': 0.419, 'learning_rate': 0.0001941834438153019, 'epoch': 0.45}\n",
            "{'loss': 0.3309, 'learning_rate': 0.00019412872714426782, 'epoch': 0.46}\n",
            "{'loss': 0.7547, 'learning_rate': 0.00019407376209765255, 'epoch': 0.46}\n",
            "{'loss': 0.4269, 'learning_rate': 0.0001940185488204912, 'epoch': 0.46}\n",
            "{'loss': 0.2073, 'learning_rate': 0.00019396308745847402, 'epoch': 0.46}\n",
            "{'loss': 0.473, 'learning_rate': 0.00019390737815794574, 'epoch': 0.46}\n",
            "{'loss': 0.4914, 'learning_rate': 0.00019385142106590535, 'epoch': 0.47}\n",
            "{'loss': 0.3559, 'learning_rate': 0.00019379521633000572, 'epoch': 0.47}\n",
            "{'loss': 0.383, 'learning_rate': 0.0001937387640985532, 'epoch': 0.47}\n",
            "{'loss': 0.6105, 'learning_rate': 0.00019368206452050713, 'epoch': 0.47}\n",
            "{'loss': 0.4904, 'learning_rate': 0.00019362511774547955, 'epoch': 0.47}\n",
            "{'loss': 0.3708, 'learning_rate': 0.00019356792392373479, 'epoch': 0.48}\n",
            "{'loss': 0.315, 'learning_rate': 0.00019351048320618896, 'epoch': 0.48}\n",
            "{'loss': 0.5308, 'learning_rate': 0.0001934527957444098, 'epoch': 0.48}\n",
            "{'loss': 0.5674, 'learning_rate': 0.00019339486169061608, 'epoch': 0.48}\n",
            "{'loss': 0.3165, 'learning_rate': 0.00019333668119767716, 'epoch': 0.49}\n",
            "{'loss': 0.5015, 'learning_rate': 0.00019327825441911275, 'epoch': 0.49}\n",
            "{'loss': 0.4056, 'learning_rate': 0.00019321958150909243, 'epoch': 0.49}\n",
            "{'loss': 0.3554, 'learning_rate': 0.00019316066262243525, 'epoch': 0.49}\n",
            "{'loss': 0.4683, 'learning_rate': 0.00019310149791460925, 'epoch': 0.49}\n",
            "{'loss': 0.3934, 'learning_rate': 0.00019304208754173117, 'epoch': 0.5}\n",
            "{'loss': 0.4301, 'learning_rate': 0.000192982431660566, 'epoch': 0.5}\n",
            "{'loss': 0.439, 'learning_rate': 0.00019292253042852648, 'epoch': 0.5}\n",
            " 12% 243/1944 [18:39<2:09:34,  4.57s/it][2024-01-21 12:14:59,313] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 12:14:59,728] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 12:14:59,729] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 0/973 [00:00<?, ?it/s]\u001b[A[2024-01-21 12:15:00,430] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 2/973 [00:00<05:39,  2.86it/s]\u001b[A[2024-01-21 12:15:01,100] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 3/973 [00:01<07:49,  2.07it/s]\u001b[A[2024-01-21 12:15:01,791] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 4/973 [00:02<09:03,  1.78it/s]\u001b[A[2024-01-21 12:15:02,475] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 5/973 [00:02<09:44,  1.66it/s]\u001b[A[2024-01-21 12:15:03,152] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 6/973 [00:03<10:07,  1.59it/s]\u001b[A[2024-01-21 12:15:03,839] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 7/973 [00:04<10:25,  1.55it/s]\u001b[A[2024-01-21 12:15:04,522] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 8/973 [00:04<10:35,  1.52it/s]\u001b[A[2024-01-21 12:15:05,201] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 9/973 [00:05<10:41,  1.50it/s]\u001b[A[2024-01-21 12:15:05,889] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 10/973 [00:06<10:47,  1.49it/s]\u001b[A[2024-01-21 12:15:06,569] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 11/973 [00:06<10:48,  1.48it/s]\u001b[A[2024-01-21 12:15:07,250] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 12/973 [00:07<10:50,  1.48it/s]\u001b[A[2024-01-21 12:15:07,939] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 13/973 [00:08<10:53,  1.47it/s]\u001b[A[2024-01-21 12:15:08,621] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 14/973 [00:08<10:52,  1.47it/s]\u001b[A[2024-01-21 12:15:09,303] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 15/973 [00:09<10:52,  1.47it/s]\u001b[A[2024-01-21 12:15:09,990] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 16/973 [00:10<10:53,  1.46it/s]\u001b[A[2024-01-21 12:15:10,675] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 17/973 [00:10<10:53,  1.46it/s]\u001b[A[2024-01-21 12:15:11,359] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 18/973 [00:11<10:52,  1.46it/s]\u001b[A[2024-01-21 12:15:12,042] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 19/973 [00:12<10:51,  1.46it/s]\u001b[A[2024-01-21 12:15:12,721] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 0.5373286008834839, 'eval_runtime': 13.6746, 'eval_samples_per_second': 1.463, 'eval_steps_per_second': 1.463, 'epoch': 0.5}\n",
            " 12% 243/1944 [18:53<2:09:34,  4.57s/it]\n",
            "  2% 20/973 [00:13<10:49,  1.47it/s]\u001b[A\n",
            "{'loss': 0.3326, 'learning_rate': 0.00019286238400367277, 'epoch': 0.5}\n",
            "{'loss': 0.3063, 'learning_rate': 0.0001928019925447121, 'epoch': 0.5}\n",
            "{'loss': 0.4579, 'learning_rate': 0.00019274135621099813, 'epoch': 0.51}\n",
            "{'loss': 0.6368, 'learning_rate': 0.00019268047516253077, 'epoch': 0.51}\n",
            "{'loss': 0.3969, 'learning_rate': 0.00019261934955995563, 'epoch': 0.51}\n",
            "{'loss': 0.3653, 'learning_rate': 0.00019255797956456357, 'epoch': 0.51}\n",
            "{'loss': 0.8721, 'learning_rate': 0.00019249636533829042, 'epoch': 0.51}\n",
            "{'loss': 0.4955, 'learning_rate': 0.00019243450704371632, 'epoch': 0.52}\n",
            "{'loss': 0.6166, 'learning_rate': 0.00019237240484406561, 'epoch': 0.52}\n",
            "{'loss': 0.2288, 'learning_rate': 0.00019231005890320602, 'epoch': 0.52}\n",
            "{'loss': 0.2916, 'learning_rate': 0.00019224746938564859, 'epoch': 0.52}\n",
            "{'loss': 0.1199, 'learning_rate': 0.000192184636456547, 'epoch': 0.52}\n",
            "{'loss': 0.4268, 'learning_rate': 0.00019212156028169724, 'epoch': 0.53}\n",
            "{'loss': 0.5008, 'learning_rate': 0.00019205824102753717, 'epoch': 0.53}\n",
            "{'loss': 0.4857, 'learning_rate': 0.00019199467886114603, 'epoch': 0.53}\n",
            "{'loss': 0.4865, 'learning_rate': 0.00019193087395024397, 'epoch': 0.53}\n",
            "{'loss': 0.2552, 'learning_rate': 0.0001918668264631918, 'epoch': 0.53}\n",
            "{'loss': 0.199, 'learning_rate': 0.0001918025365689903, 'epoch': 0.54}\n",
            "{'loss': 0.3816, 'learning_rate': 0.00019173800443727994, 'epoch': 0.54}\n",
            "{'loss': 0.3419, 'learning_rate': 0.00019167323023834033, 'epoch': 0.54}\n",
            "{'loss': 0.7421, 'learning_rate': 0.00019160821414308988, 'epoch': 0.54}\n",
            "{'loss': 0.2039, 'learning_rate': 0.0001915429563230853, 'epoch': 0.54}\n",
            "{'loss': 0.467, 'learning_rate': 0.00019147745695052097, 'epoch': 0.55}\n",
            "{'loss': 0.376, 'learning_rate': 0.00019141171619822882, 'epoch': 0.55}\n",
            "{'loss': 0.4073, 'learning_rate': 0.0001913457342396777, 'epoch': 0.55}\n",
            "{'loss': 0.2004, 'learning_rate': 0.00019127951124897283, 'epoch': 0.55}\n",
            "{'loss': 0.6391, 'learning_rate': 0.00019121304740085546, 'epoch': 0.55}\n",
            "{'loss': 0.4133, 'learning_rate': 0.0001911463428707025, 'epoch': 0.56}\n",
            "{'loss': 0.3348, 'learning_rate': 0.00019107939783452577, 'epoch': 0.56}\n",
            "{'loss': 0.3112, 'learning_rate': 0.00019101221246897184, 'epoch': 0.56}\n",
            "{'loss': 0.4377, 'learning_rate': 0.00019094478695132138, 'epoch': 0.56}\n",
            "{'loss': 0.8021, 'learning_rate': 0.00019087712145948868, 'epoch': 0.57}\n",
            "{'loss': 0.4179, 'learning_rate': 0.0001908092161720214, 'epoch': 0.57}\n",
            "{'loss': 0.3215, 'learning_rate': 0.00019074107126809984, 'epoch': 0.57}\n",
            "{'loss': 0.2618, 'learning_rate': 0.00019067268692753655, 'epoch': 0.57}\n",
            "{'loss': 0.5313, 'learning_rate': 0.00019060406333077596, 'epoch': 0.57}\n",
            "{'loss': 0.2659, 'learning_rate': 0.00019053520065889375, 'epoch': 0.58}\n",
            "{'loss': 0.3511, 'learning_rate': 0.00019046609909359648, 'epoch': 0.58}\n",
            "{'loss': 0.467, 'learning_rate': 0.00019039675881722104, 'epoch': 0.58}\n",
            "{'loss': 0.5441, 'learning_rate': 0.00019032718001273427, 'epoch': 0.58}\n",
            "{'loss': 0.15, 'learning_rate': 0.0001902573628637323, 'epoch': 0.58}\n",
            "{'loss': 0.5622, 'learning_rate': 0.0001901873075544403, 'epoch': 0.59}\n",
            "{'loss': 0.6283, 'learning_rate': 0.00019011701426971178, 'epoch': 0.59}\n",
            "{'loss': 0.3236, 'learning_rate': 0.00019004648319502824, 'epoch': 0.59}\n",
            "{'loss': 0.2753, 'learning_rate': 0.00018997571451649856, 'epoch': 0.59}\n",
            "{'loss': 0.2762, 'learning_rate': 0.00018990470842085867, 'epoch': 0.59}\n",
            "{'loss': 0.8736, 'learning_rate': 0.0001898334650954709, 'epoch': 0.6}\n",
            "{'loss': 0.5324, 'learning_rate': 0.00018976198472832364, 'epoch': 0.6}\n",
            "{'loss': 0.5477, 'learning_rate': 0.00018969026750803063, 'epoch': 0.6}\n",
            "{'loss': 0.3752, 'learning_rate': 0.00018961831362383067, 'epoch': 0.6}\n",
            "{'loss': 0.3971, 'learning_rate': 0.00018954612326558707, 'epoch': 0.6}\n",
            "{'loss': 0.5546, 'learning_rate': 0.00018947369662378704, 'epoch': 0.61}\n",
            "{'loss': 0.7171, 'learning_rate': 0.00018940103388954133, 'epoch': 0.61}\n",
            "{'loss': 0.5471, 'learning_rate': 0.00018932813525458363, 'epoch': 0.61}\n",
            "{'loss': 0.5569, 'learning_rate': 0.00018925500091127007, 'epoch': 0.61}\n",
            "{'loss': 0.5455, 'learning_rate': 0.00018918163105257883, 'epoch': 0.61}\n",
            "{'loss': 0.8046, 'learning_rate': 0.00018910802587210942, 'epoch': 0.62}\n",
            "{'loss': 0.565, 'learning_rate': 0.0001890341855640824, 'epoch': 0.62}\n",
            "{'loss': 0.4557, 'learning_rate': 0.0001889601103233387, 'epoch': 0.62}\n",
            "{'loss': 0.2486, 'learning_rate': 0.00018888580034533915, 'epoch': 0.62}\n",
            "{'loss': 0.3523, 'learning_rate': 0.000188811255826164, 'epoch': 0.62}\n",
            "{'loss': 0.4913, 'learning_rate': 0.0001887364769625124, 'epoch': 0.63}\n",
            "{'loss': 0.4876, 'learning_rate': 0.00018866146395170178, 'epoch': 0.63}\n",
            "{'loss': 0.3255, 'learning_rate': 0.00018858621699166755, 'epoch': 0.63}\n",
            "{'loss': 0.3371, 'learning_rate': 0.00018851073628096225, 'epoch': 0.63}\n",
            "{'loss': 0.3546, 'learning_rate': 0.0001884350220187554, 'epoch': 0.64}\n",
            "{'loss': 0.2438, 'learning_rate': 0.00018835907440483267, 'epoch': 0.64}\n",
            "{'loss': 0.8297, 'learning_rate': 0.0001882828936395955, 'epoch': 0.64}\n",
            "{'loss': 0.5547, 'learning_rate': 0.00018820647992406054, 'epoch': 0.64}\n",
            "{'loss': 0.3732, 'learning_rate': 0.00018812983345985914, 'epoch': 0.64}\n",
            "{'loss': 0.416, 'learning_rate': 0.0001880529544492368, 'epoch': 0.65}\n",
            "{'loss': 0.5396, 'learning_rate': 0.00018797584309505254, 'epoch': 0.65}\n",
            "{'loss': 0.2817, 'learning_rate': 0.00018789849960077864, 'epoch': 0.65}\n",
            "{'loss': 0.423, 'learning_rate': 0.00018782092417049979, 'epoch': 0.65}\n",
            "{'loss': 0.871, 'learning_rate': 0.00018774311700891269, 'epoch': 0.65}\n",
            "{'loss': 0.2437, 'learning_rate': 0.00018766507832132558, 'epoch': 0.66}\n",
            "{'loss': 0.3473, 'learning_rate': 0.00018758680831365755, 'epoch': 0.66}\n",
            "{'loss': 0.4313, 'learning_rate': 0.00018750830719243812, 'epoch': 0.66}\n",
            "{'loss': 0.4987, 'learning_rate': 0.00018742957516480657, 'epoch': 0.66}\n",
            "{'loss': 0.3547, 'learning_rate': 0.00018735061243851158, 'epoch': 0.66}\n",
            "{'loss': 0.3645, 'learning_rate': 0.00018727141922191047, 'epoch': 0.67}\n",
            "{'loss': 0.1464, 'learning_rate': 0.00018719199572396882, 'epoch': 0.67}\n",
            "{'loss': 0.4049, 'learning_rate': 0.00018711234215425978, 'epoch': 0.67}\n",
            "{'loss': 0.4207, 'learning_rate': 0.00018703245872296365, 'epoch': 0.67}\n",
            "{'loss': 0.2782, 'learning_rate': 0.00018695234564086724, 'epoch': 0.67}\n",
            "{'loss': 0.4686, 'learning_rate': 0.00018687200311936328, 'epoch': 0.68}\n",
            "{'loss': 0.7067, 'learning_rate': 0.00018679143137045006, 'epoch': 0.68}\n",
            "{'loss': 0.5768, 'learning_rate': 0.00018671063060673055, 'epoch': 0.68}\n",
            "{'loss': 0.2868, 'learning_rate': 0.00018662960104141215, 'epoch': 0.68}\n",
            "{'loss': 0.7008, 'learning_rate': 0.00018654834288830591, 'epoch': 0.68}\n",
            "{'loss': 0.3528, 'learning_rate': 0.00018646685636182614, 'epoch': 0.69}\n",
            "{'loss': 0.3723, 'learning_rate': 0.00018638514167698965, 'epoch': 0.69}\n",
            "{'loss': 0.3781, 'learning_rate': 0.00018630319904941535, 'epoch': 0.69}\n",
            "{'loss': 0.3119, 'learning_rate': 0.0001862210286953236, 'epoch': 0.69}\n",
            "{'loss': 0.4122, 'learning_rate': 0.0001861386308315357, 'epoch': 0.69}\n",
            "{'loss': 0.4771, 'learning_rate': 0.00018605600567547318, 'epoch': 0.7}\n",
            "{'loss': 0.36, 'learning_rate': 0.00018597315344515744, 'epoch': 0.7}\n",
            "{'loss': 0.4865, 'learning_rate': 0.00018589007435920892, 'epoch': 0.7}\n",
            "{'loss': 0.6553, 'learning_rate': 0.0001858067686368468, 'epoch': 0.7}\n",
            "{'loss': 0.4422, 'learning_rate': 0.00018572323649788822, 'epoch': 0.71}\n",
            "{'loss': 0.2712, 'learning_rate': 0.0001856394781627477, 'epoch': 0.71}\n",
            "{'loss': 0.4905, 'learning_rate': 0.00018555549385243674, 'epoch': 0.71}\n",
            "{'loss': 0.2148, 'learning_rate': 0.000185471283788563, 'epoch': 0.71}\n",
            "{'loss': 0.7178, 'learning_rate': 0.0001853868481933299, 'epoch': 0.71}\n",
            "{'loss': 0.3764, 'learning_rate': 0.00018530218728953597, 'epoch': 0.72}\n",
            "{'loss': 0.5165, 'learning_rate': 0.0001852173013005742, 'epoch': 0.72}\n",
            "{'loss': 0.3025, 'learning_rate': 0.00018513219045043156, 'epoch': 0.72}\n",
            "{'loss': 0.3154, 'learning_rate': 0.00018504685496368838, 'epoch': 0.72}\n",
            "{'loss': 0.5406, 'learning_rate': 0.00018496129506551763, 'epoch': 0.72}\n",
            "{'loss': 0.4357, 'learning_rate': 0.00018487551098168452, 'epoch': 0.73}\n",
            "{'loss': 0.4401, 'learning_rate': 0.0001847895029385458, 'epoch': 0.73}\n",
            "{'loss': 0.4711, 'learning_rate': 0.00018470327116304916, 'epoch': 0.73}\n",
            "{'loss': 0.5766, 'learning_rate': 0.0001846168158827326, 'epoch': 0.73}\n",
            "{'loss': 0.4189, 'learning_rate': 0.00018453013732572403, 'epoch': 0.73}\n",
            "{'loss': 0.514, 'learning_rate': 0.00018444323572074035, 'epoch': 0.74}\n",
            "{'loss': 0.2696, 'learning_rate': 0.00018435611129708713, 'epoch': 0.74}\n",
            "{'loss': 0.4633, 'learning_rate': 0.00018426876428465777, 'epoch': 0.74}\n",
            "{'loss': 0.252, 'learning_rate': 0.00018418119491393312, 'epoch': 0.74}\n",
            "{'loss': 0.4926, 'learning_rate': 0.0001840934034159807, 'epoch': 0.74}\n",
            "{'loss': 0.2806, 'learning_rate': 0.0001840053900224542, 'epoch': 0.75}\n",
            "{'loss': 0.407, 'learning_rate': 0.00018391715496559273, 'epoch': 0.75}\n",
            "{'loss': 0.4692, 'learning_rate': 0.00018382869847822044, 'epoch': 0.75}\n",
            "{'loss': 0.2645, 'learning_rate': 0.00018374002079374569, 'epoch': 0.75}\n",
            "{'loss': 0.6886, 'learning_rate': 0.0001836511221461604, 'epoch': 0.75}\n",
            "{'loss': 0.4999, 'learning_rate': 0.00018356200277003975, 'epoch': 0.76}\n",
            "{'loss': 0.4696, 'learning_rate': 0.00018347266290054116, 'epoch': 0.76}\n",
            "{'loss': 0.4852, 'learning_rate': 0.00018338310277340406, 'epoch': 0.76}\n",
            "{'loss': 0.2802, 'learning_rate': 0.00018329332262494887, 'epoch': 0.76}\n",
            "{'loss': 0.5128, 'learning_rate': 0.00018320332269207667, 'epoch': 0.76}\n",
            "{'loss': 0.5661, 'learning_rate': 0.00018311310321226853, 'epoch': 0.77}\n",
            "{'loss': 0.3092, 'learning_rate': 0.00018302266442358472, 'epoch': 0.77}\n",
            "{'loss': 0.39, 'learning_rate': 0.0001829320065646643, 'epoch': 0.77}\n",
            "{'loss': 0.344, 'learning_rate': 0.0001828411298747243, 'epoch': 0.77}\n",
            "{'loss': 0.5107, 'learning_rate': 0.00018275003459355924, 'epoch': 0.77}\n",
            "{'loss': 0.4687, 'learning_rate': 0.00018265872096154043, 'epoch': 0.78}\n",
            "{'loss': 0.4563, 'learning_rate': 0.00018256718921961525, 'epoch': 0.78}\n",
            "{'loss': 0.5586, 'learning_rate': 0.00018247543960930672, 'epoch': 0.78}\n",
            "{'loss': 0.4284, 'learning_rate': 0.00018238347237271266, 'epoch': 0.78}\n",
            "{'loss': 0.7854, 'learning_rate': 0.00018229128775250523, 'epoch': 0.79}\n",
            "{'loss': 0.333, 'learning_rate': 0.00018219888599193008, 'epoch': 0.79}\n",
            "{'loss': 0.3001, 'learning_rate': 0.00018210626733480593, 'epoch': 0.79}\n",
            "{'loss': 0.1858, 'learning_rate': 0.00018201343202552367, 'epoch': 0.79}\n",
            "{'loss': 0.4506, 'learning_rate': 0.00018192038030904608, 'epoch': 0.79}\n",
            "{'loss': 0.5122, 'learning_rate': 0.00018182711243090678, 'epoch': 0.8}\n",
            "{'loss': 0.5642, 'learning_rate': 0.00018173362863720986, 'epoch': 0.8}\n",
            "{'loss': 0.3452, 'learning_rate': 0.00018163992917462918, 'epoch': 0.8}\n",
            "{'loss': 0.3473, 'learning_rate': 0.00018154601429040757, 'epoch': 0.8}\n",
            "{'loss': 0.4392, 'learning_rate': 0.00018145188423235634, 'epoch': 0.8}\n",
            "{'loss': 0.2852, 'learning_rate': 0.00018135753924885465, 'epoch': 0.81}\n",
            "{'loss': 0.6076, 'learning_rate': 0.00018126297958884866, 'epoch': 0.81}\n",
            "{'loss': 0.2474, 'learning_rate': 0.00018116820550185107, 'epoch': 0.81}\n",
            "{'loss': 0.3944, 'learning_rate': 0.00018107321723794036, 'epoch': 0.81}\n",
            "{'loss': 0.4742, 'learning_rate': 0.00018097801504776012, 'epoch': 0.81}\n",
            "{'loss': 0.2275, 'learning_rate': 0.00018088259918251846, 'epoch': 0.82}\n",
            "{'loss': 0.2779, 'learning_rate': 0.00018078696989398734, 'epoch': 0.82}\n",
            "{'loss': 0.5853, 'learning_rate': 0.00018069112743450183, 'epoch': 0.82}\n",
            "{'loss': 0.0977, 'learning_rate': 0.0001805950720569595, 'epoch': 0.82}\n",
            "{'loss': 0.7514, 'learning_rate': 0.00018049880401481972, 'epoch': 0.82}\n",
            "{'loss': 0.692, 'learning_rate': 0.00018040232356210308, 'epoch': 0.83}\n",
            "{'loss': 0.2787, 'learning_rate': 0.00018030563095339062, 'epoch': 0.83}\n",
            "{'loss': 0.2826, 'learning_rate': 0.00018020872644382313, 'epoch': 0.83}\n",
            "{'loss': 0.4022, 'learning_rate': 0.0001801116102891006, 'epoch': 0.83}\n",
            "{'loss': 0.8116, 'learning_rate': 0.00018001428274548156, 'epoch': 0.83}\n",
            "{'loss': 0.4949, 'learning_rate': 0.00017991674406978215, 'epoch': 0.84}\n",
            "{'loss': 0.5348, 'learning_rate': 0.00017981899451937573, 'epoch': 0.84}\n",
            "{'loss': 0.487, 'learning_rate': 0.0001797210343521921, 'epoch': 0.84}\n",
            "{'loss': 0.3582, 'learning_rate': 0.00017962286382671678, 'epoch': 0.84}\n",
            "{'loss': 0.3178, 'learning_rate': 0.00017952448320199035, 'epoch': 0.84}\n",
            "{'loss': 0.4576, 'learning_rate': 0.00017942589273760783, 'epoch': 0.85}\n",
            "{'loss': 0.2953, 'learning_rate': 0.00017932709269371784, 'epoch': 0.85}\n",
            "{'loss': 0.3885, 'learning_rate': 0.00017922808333102207, 'epoch': 0.85}\n",
            "{'loss': 0.4267, 'learning_rate': 0.00017912886491077462, 'epoch': 0.85}\n",
            "{'loss': 0.5676, 'learning_rate': 0.000179029437694781, 'epoch': 0.86}\n",
            "{'loss': 0.3711, 'learning_rate': 0.00017892980194539798, 'epoch': 0.86}\n",
            "{'loss': 0.336, 'learning_rate': 0.00017882995792553228, 'epoch': 0.86}\n",
            "{'loss': 0.2489, 'learning_rate': 0.00017872990589864034, 'epoch': 0.86}\n",
            "{'loss': 0.6025, 'learning_rate': 0.00017862964612872748, 'epoch': 0.86}\n",
            "{'loss': 0.2049, 'learning_rate': 0.00017852917888034706, 'epoch': 0.87}\n",
            "{'loss': 0.5012, 'learning_rate': 0.00017842850441860005, 'epoch': 0.87}\n",
            "{'loss': 0.2935, 'learning_rate': 0.00017832762300913413, 'epoch': 0.87}\n",
            "{'loss': 0.438, 'learning_rate': 0.00017822653491814304, 'epoch': 0.87}\n",
            "{'loss': 0.3553, 'learning_rate': 0.00017812524041236586, 'epoch': 0.87}\n",
            "{'loss': 0.4575, 'learning_rate': 0.0001780237397590864, 'epoch': 0.88}\n",
            "{'loss': 0.3725, 'learning_rate': 0.00017792203322613236, 'epoch': 0.88}\n",
            "{'loss': 0.7082, 'learning_rate': 0.0001778201210818748, 'epoch': 0.88}\n",
            "{'loss': 0.396, 'learning_rate': 0.0001777180035952272, 'epoch': 0.88}\n",
            "{'loss': 0.2354, 'learning_rate': 0.00017761568103564487, 'epoch': 0.88}\n",
            "{'loss': 0.488, 'learning_rate': 0.0001775131536731244, 'epoch': 0.89}\n",
            "{'loss': 0.42, 'learning_rate': 0.00017741042177820258, 'epoch': 0.89}\n",
            "{'loss': 0.303, 'learning_rate': 0.0001773074856219561, 'epoch': 0.89}\n",
            "{'loss': 0.3314, 'learning_rate': 0.00017720434547600043, 'epoch': 0.89}\n",
            "{'loss': 0.2714, 'learning_rate': 0.00017710100161248945, 'epoch': 0.89}\n",
            "{'loss': 0.4095, 'learning_rate': 0.0001769974543041145, 'epoch': 0.9}\n",
            "{'loss': 0.304, 'learning_rate': 0.00017689370382410386, 'epoch': 0.9}\n",
            "{'loss': 0.4071, 'learning_rate': 0.00017678975044622174, 'epoch': 0.9}\n",
            "{'loss': 0.4673, 'learning_rate': 0.00017668559444476793, 'epoch': 0.9}\n",
            "{'loss': 0.4802, 'learning_rate': 0.00017658123609457668, 'epoch': 0.9}\n",
            "{'loss': 0.5388, 'learning_rate': 0.00017647667567101632, 'epoch': 0.91}\n",
            "{'loss': 0.2477, 'learning_rate': 0.00017637191344998837, 'epoch': 0.91}\n",
            "{'loss': 0.3632, 'learning_rate': 0.00017626694970792673, 'epoch': 0.91}\n",
            "{'loss': 0.3372, 'learning_rate': 0.00017616178472179715, 'epoch': 0.91}\n",
            "{'loss': 0.2047, 'learning_rate': 0.0001760564187690964, 'epoch': 0.91}\n",
            "{'loss': 0.4775, 'learning_rate': 0.00017595085212785146, 'epoch': 0.92}\n",
            "{'loss': 0.1717, 'learning_rate': 0.0001758450850766189, 'epoch': 0.92}\n",
            "{'loss': 0.4609, 'learning_rate': 0.00017573911789448414, 'epoch': 0.92}\n",
            "{'loss': 0.4988, 'learning_rate': 0.00017563295086106063, 'epoch': 0.92}\n",
            "{'loss': 0.4039, 'learning_rate': 0.00017552658425648923, 'epoch': 0.92}\n",
            "{'loss': 0.4247, 'learning_rate': 0.00017542001836143731, 'epoch': 0.93}\n",
            "{'loss': 0.3792, 'learning_rate': 0.00017531325345709816, 'epoch': 0.93}\n",
            "{'loss': 0.3361, 'learning_rate': 0.00017520628982519023, 'epoch': 0.93}\n",
            "{'loss': 0.4339, 'learning_rate': 0.0001750991277479563, 'epoch': 0.93}\n",
            "{'loss': 0.6562, 'learning_rate': 0.00017499176750816276, 'epoch': 0.94}\n",
            "{'loss': 0.475, 'learning_rate': 0.00017488420938909893, 'epoch': 0.94}\n",
            "{'loss': 0.4244, 'learning_rate': 0.00017477645367457628, 'epoch': 0.94}\n",
            "{'loss': 0.459, 'learning_rate': 0.00017466850064892762, 'epoch': 0.94}\n",
            "{'loss': 0.1999, 'learning_rate': 0.0001745603505970064, 'epoch': 0.94}\n",
            "{'loss': 0.4501, 'learning_rate': 0.00017445200380418607, 'epoch': 0.95}\n",
            "{'loss': 0.7725, 'learning_rate': 0.00017434346055635912, 'epoch': 0.95}\n",
            "{'loss': 0.301, 'learning_rate': 0.00017423472113993634, 'epoch': 0.95}\n",
            "{'loss': 0.5747, 'learning_rate': 0.00017412578584184637, 'epoch': 0.95}\n",
            "{'loss': 0.3434, 'learning_rate': 0.00017401665494953453, 'epoch': 0.95}\n",
            "{'loss': 0.1772, 'learning_rate': 0.00017390732875096227, 'epoch': 0.96}\n",
            "{'loss': 0.2941, 'learning_rate': 0.00017379780753460654, 'epoch': 0.96}\n",
            "{'loss': 0.3506, 'learning_rate': 0.00017368809158945872, 'epoch': 0.96}\n",
            "{'loss': 0.5215, 'learning_rate': 0.00017357818120502402, 'epoch': 0.96}\n",
            "{'loss': 0.2596, 'learning_rate': 0.00017346807667132085, 'epoch': 0.96}\n",
            "{'loss': 0.3889, 'learning_rate': 0.00017335777827887978, 'epoch': 0.97}\n",
            "{'loss': 0.5627, 'learning_rate': 0.00017324728631874298, 'epoch': 0.97}\n",
            "{'loss': 0.3396, 'learning_rate': 0.00017313660108246337, 'epoch': 0.97}\n",
            "{'loss': 0.3904, 'learning_rate': 0.00017302572286210382, 'epoch': 0.97}\n",
            "{'loss': 0.345, 'learning_rate': 0.00017291465195023653, 'epoch': 0.97}\n",
            "{'loss': 0.3392, 'learning_rate': 0.000172803388639942, 'epoch': 0.98}\n",
            "{'loss': 0.2783, 'learning_rate': 0.00017269193322480856, 'epoch': 0.98}\n",
            "{'loss': 0.3632, 'learning_rate': 0.00017258028599893136, 'epoch': 0.98}\n",
            "{'loss': 0.2202, 'learning_rate': 0.00017246844725691166, 'epoch': 0.98}\n",
            "{'loss': 0.4017, 'learning_rate': 0.00017235641729385615, 'epoch': 0.98}\n",
            "{'loss': 0.6497, 'learning_rate': 0.00017224419640537598, 'epoch': 0.99}\n",
            "{'loss': 0.5883, 'learning_rate': 0.00017213178488758622, 'epoch': 0.99}\n",
            "{'loss': 0.522, 'learning_rate': 0.00017201918303710482, 'epoch': 0.99}\n",
            "{'loss': 0.3548, 'learning_rate': 0.0001719063911510521, 'epoch': 0.99}\n",
            " 25% 483/1944 [37:10<1:51:32,  4.58s/it][2024-01-21 12:33:29,737] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "{'loss': 0.2425, 'learning_rate': 0.0001717934095270497, 'epoch': 1.0}\n",
            "{'loss': 0.4591, 'learning_rate': 0.0001716802384632199, 'epoch': 1.0}\n",
            "{'loss': 0.514, 'learning_rate': 0.00017156687825818504, 'epoch': 1.01}\n",
            " 25% 486/1944 [37:23<1:50:58,  4.57s/it][2024-01-21 12:33:43,436] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 12:33:43,852] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 12:33:43,852] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 0/973 [00:00<?, ?it/s]\u001b[A[2024-01-21 12:33:44,557] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 2/973 [00:00<05:41,  2.84it/s]\u001b[A[2024-01-21 12:33:45,229] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 3/973 [00:01<07:50,  2.06it/s]\u001b[A[2024-01-21 12:33:45,916] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 4/973 [00:02<09:03,  1.78it/s]\u001b[A[2024-01-21 12:33:46,605] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 5/973 [00:02<09:46,  1.65it/s]\u001b[A[2024-01-21 12:33:47,284] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 6/973 [00:03<10:08,  1.59it/s]\u001b[A[2024-01-21 12:33:47,969] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 7/973 [00:04<10:27,  1.54it/s]\u001b[A[2024-01-21 12:33:48,655] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 8/973 [00:04<10:36,  1.52it/s]\u001b[A[2024-01-21 12:33:49,337] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 9/973 [00:05<10:42,  1.50it/s]\u001b[A[2024-01-21 12:33:50,025] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 10/973 [00:06<10:48,  1.49it/s]\u001b[A[2024-01-21 12:33:50,713] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 11/973 [00:06<10:51,  1.48it/s]\u001b[A[2024-01-21 12:33:51,393] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 12/973 [00:07<10:51,  1.47it/s]\u001b[A[2024-01-21 12:33:52,079] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 13/973 [00:08<10:53,  1.47it/s]\u001b[A[2024-01-21 12:33:52,761] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 14/973 [00:08<10:53,  1.47it/s]\u001b[A[2024-01-21 12:33:53,443] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 15/973 [00:09<10:52,  1.47it/s]\u001b[A[2024-01-21 12:33:54,133] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 16/973 [00:10<10:54,  1.46it/s]\u001b[A[2024-01-21 12:33:54,813] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 17/973 [00:10<10:52,  1.46it/s]\u001b[A[2024-01-21 12:33:55,495] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 18/973 [00:11<10:51,  1.47it/s]\u001b[A[2024-01-21 12:33:56,179] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 19/973 [00:12<10:51,  1.46it/s]\u001b[A[2024-01-21 12:33:56,859] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 0.5294363498687744, 'eval_runtime': 13.688, 'eval_samples_per_second': 1.461, 'eval_steps_per_second': 1.461, 'epoch': 1.01}\n",
            " 25% 486/1944 [37:37<1:50:58,  4.57s/it]\n",
            "  2% 20/973 [00:13<10:49,  1.47it/s]\u001b[A\n",
            "{'loss': 0.2904, 'learning_rate': 0.00017145332921106633, 'epoch': 1.01}\n",
            "{'loss': 0.4814, 'learning_rate': 0.00017133959162148336, 'epoch': 1.01}\n",
            "{'loss': 0.3581, 'learning_rate': 0.00017122566578955324, 'epoch': 1.01}\n",
            "{'loss': 0.3957, 'learning_rate': 0.00017111155201588978, 'epoch': 1.01}\n",
            "{'loss': 0.3239, 'learning_rate': 0.0001709972506016027, 'epoch': 1.02}\n",
            "{'loss': 0.3784, 'learning_rate': 0.00017088276184829685, 'epoch': 1.02}\n",
            "{'loss': 0.1974, 'learning_rate': 0.00017076808605807138, 'epoch': 1.02}\n",
            "{'loss': 0.3453, 'learning_rate': 0.00017065322353351903, 'epoch': 1.02}\n",
            "{'loss': 0.3368, 'learning_rate': 0.0001705381745777252, 'epoch': 1.02}\n",
            "{'loss': 0.4846, 'learning_rate': 0.00017042293949426726, 'epoch': 1.03}\n",
            "{'loss': 0.3171, 'learning_rate': 0.00017030751858721375, 'epoch': 1.03}\n",
            "{'loss': 0.2919, 'learning_rate': 0.00017019191216112342, 'epoch': 1.03}\n",
            "{'loss': 0.1608, 'learning_rate': 0.00017007612052104474, 'epoch': 1.03}\n",
            "{'loss': 0.4071, 'learning_rate': 0.00016996014397251466, 'epoch': 1.03}\n",
            "{'loss': 0.3769, 'learning_rate': 0.00016984398282155825, 'epoch': 1.04}\n",
            "{'loss': 0.4473, 'learning_rate': 0.00016972763737468758, 'epoch': 1.04}\n",
            "{'loss': 0.2608, 'learning_rate': 0.00016961110793890108, 'epoch': 1.04}\n",
            "{'loss': 0.4686, 'learning_rate': 0.00016949439482168255, 'epoch': 1.04}\n",
            "{'loss': 0.3717, 'learning_rate': 0.00016937749833100064, 'epoch': 1.05}\n",
            "{'loss': 0.2992, 'learning_rate': 0.0001692604187753077, 'epoch': 1.05}\n",
            "{'loss': 0.2641, 'learning_rate': 0.0001691431564635392, 'epoch': 1.05}\n",
            "{'loss': 0.4062, 'learning_rate': 0.00016902571170511292, 'epoch': 1.05}\n",
            "{'loss': 0.2953, 'learning_rate': 0.0001689080848099279, 'epoch': 1.05}\n",
            "{'loss': 0.1792, 'learning_rate': 0.00016879027608836394, 'epoch': 1.06}\n",
            "{'loss': 0.6937, 'learning_rate': 0.00016867228585128047, 'epoch': 1.06}\n",
            "{'loss': 0.3999, 'learning_rate': 0.000168554114410016, 'epoch': 1.06}\n",
            "{'loss': 0.4678, 'learning_rate': 0.0001684357620763872, 'epoch': 1.06}\n",
            "{'loss': 0.5662, 'learning_rate': 0.00016831722916268787, 'epoch': 1.06}\n",
            "{'loss': 0.3961, 'learning_rate': 0.0001681985159816885, 'epoch': 1.07}\n",
            "{'loss': 0.3761, 'learning_rate': 0.00016807962284663518, 'epoch': 1.07}\n",
            "{'loss': 0.2904, 'learning_rate': 0.0001679605500712488, 'epoch': 1.07}\n",
            "{'loss': 0.3139, 'learning_rate': 0.00016784129796972431, 'epoch': 1.07}\n",
            "{'loss': 0.2211, 'learning_rate': 0.0001677218668567299, 'epoch': 1.07}\n",
            "{'loss': 0.3131, 'learning_rate': 0.00016760225704740594, 'epoch': 1.08}\n",
            "{'loss': 0.2363, 'learning_rate': 0.00016748246885736452, 'epoch': 1.08}\n",
            "{'loss': 0.2237, 'learning_rate': 0.00016736250260268828, 'epoch': 1.08}\n",
            "{'loss': 0.2923, 'learning_rate': 0.0001672423585999298, 'epoch': 1.08}\n",
            "{'loss': 0.5364, 'learning_rate': 0.0001671220371661106, 'epoch': 1.08}\n",
            "{'loss': 0.256, 'learning_rate': 0.0001670015386187205, 'epoch': 1.09}\n",
            "{'loss': 0.3097, 'learning_rate': 0.00016688086327571648, 'epoch': 1.09}\n",
            "{'loss': 0.3181, 'learning_rate': 0.00016676001145552228, 'epoch': 1.09}\n",
            "{'loss': 0.3053, 'learning_rate': 0.0001666389834770271, 'epoch': 1.09}\n",
            "{'loss': 0.3144, 'learning_rate': 0.00016651777965958503, 'epoch': 1.09}\n",
            "{'loss': 0.4947, 'learning_rate': 0.00016639640032301413, 'epoch': 1.1}\n",
            "{'loss': 0.3137, 'learning_rate': 0.0001662748457875957, 'epoch': 1.1}\n",
            "{'loss': 0.5872, 'learning_rate': 0.00016615311637407316, 'epoch': 1.1}\n",
            "{'loss': 0.4668, 'learning_rate': 0.00016603121240365152, 'epoch': 1.1}\n",
            "{'loss': 0.2922, 'learning_rate': 0.00016590913419799633, 'epoch': 1.1}\n",
            "{'loss': 0.2901, 'learning_rate': 0.00016578688207923289, 'epoch': 1.11}\n",
            "{'loss': 0.4794, 'learning_rate': 0.0001656644563699454, 'epoch': 1.11}\n",
            "{'loss': 0.4375, 'learning_rate': 0.00016554185739317616, 'epoch': 1.11}\n",
            "{'loss': 0.1995, 'learning_rate': 0.00016541908547242459, 'epoch': 1.11}\n",
            "{'loss': 0.2886, 'learning_rate': 0.00016529614093164648, 'epoch': 1.12}\n",
            "{'loss': 0.3168, 'learning_rate': 0.00016517302409525315, 'epoch': 1.12}\n",
            "{'loss': 0.4961, 'learning_rate': 0.0001650497352881105, 'epoch': 1.12}\n",
            "{'loss': 0.3098, 'learning_rate': 0.00016492627483553822, 'epoch': 1.12}\n",
            "{'loss': 0.4811, 'learning_rate': 0.00016480264306330898, 'epoch': 1.12}\n",
            "{'loss': 0.3959, 'learning_rate': 0.0001646788402976474, 'epoch': 1.13}\n",
            "{'loss': 0.3309, 'learning_rate': 0.0001645548668652294, 'epoch': 1.13}\n",
            "{'loss': 0.3147, 'learning_rate': 0.0001644307230931811, 'epoch': 1.13}\n",
            "{'loss': 0.4494, 'learning_rate': 0.00016430640930907827, 'epoch': 1.13}\n",
            "{'loss': 0.2972, 'learning_rate': 0.00016418192584094515, 'epoch': 1.13}\n",
            "{'loss': 0.3824, 'learning_rate': 0.00016405727301725377, 'epoch': 1.14}\n",
            "{'loss': 0.2619, 'learning_rate': 0.00016393245116692304, 'epoch': 1.14}\n",
            "{'loss': 0.1754, 'learning_rate': 0.00016380746061931786, 'epoch': 1.14}\n",
            "{'loss': 0.3193, 'learning_rate': 0.00016368230170424826, 'epoch': 1.14}\n",
            "{'loss': 0.1389, 'learning_rate': 0.0001635569747519686, 'epoch': 1.14}\n",
            "{'loss': 0.2708, 'learning_rate': 0.00016343148009317657, 'epoch': 1.15}\n",
            "{'loss': 0.3774, 'learning_rate': 0.00016330581805901239, 'epoch': 1.15}\n",
            "{'loss': 0.2513, 'learning_rate': 0.00016317998898105797, 'epoch': 1.15}\n",
            "{'loss': 0.2054, 'learning_rate': 0.00016305399319133595, 'epoch': 1.15}\n",
            "{'loss': 0.3938, 'learning_rate': 0.00016292783102230888, 'epoch': 1.15}\n",
            "{'loss': 0.3702, 'learning_rate': 0.00016280150280687834, 'epoch': 1.16}\n",
            "{'loss': 0.3067, 'learning_rate': 0.00016267500887838412, 'epoch': 1.16}\n",
            "{'loss': 0.2055, 'learning_rate': 0.00016254834957060309, 'epoch': 1.16}\n",
            "{'loss': 0.3575, 'learning_rate': 0.00016242152521774874, 'epoch': 1.16}\n",
            "{'loss': 0.2558, 'learning_rate': 0.0001622945361544699, 'epoch': 1.16}\n",
            "{'loss': 0.4393, 'learning_rate': 0.00016216738271584999, 'epoch': 1.17}\n",
            "{'loss': 0.5454, 'learning_rate': 0.00016204006523740634, 'epoch': 1.17}\n",
            "{'loss': 0.359, 'learning_rate': 0.00016191258405508896, 'epoch': 1.17}\n",
            "{'loss': 0.2741, 'learning_rate': 0.0001617849395052799, 'epoch': 1.17}\n",
            "{'loss': 0.3429, 'learning_rate': 0.00016165713192479227, 'epoch': 1.17}\n",
            "{'loss': 0.4056, 'learning_rate': 0.00016152916165086936, 'epoch': 1.18}\n",
            "{'loss': 0.6838, 'learning_rate': 0.00016140102902118377, 'epoch': 1.18}\n",
            "{'loss': 0.2999, 'learning_rate': 0.0001612727343738365, 'epoch': 1.18}\n",
            "{'loss': 0.3667, 'learning_rate': 0.00016114427804735603, 'epoch': 1.18}\n",
            "{'loss': 0.2495, 'learning_rate': 0.00016101566038069756, 'epoch': 1.18}\n",
            "{'loss': 0.2048, 'learning_rate': 0.00016088688171324184, 'epoch': 1.19}\n",
            "{'loss': 0.304, 'learning_rate': 0.0001607579423847946, 'epoch': 1.19}\n",
            "{'loss': 0.3546, 'learning_rate': 0.00016062884273558545, 'epoch': 1.19}\n",
            "{'loss': 0.4934, 'learning_rate': 0.00016049958310626708, 'epoch': 1.19}\n",
            "{'loss': 0.3237, 'learning_rate': 0.00016037016383791425, 'epoch': 1.2}\n",
            "{'loss': 0.3687, 'learning_rate': 0.00016024058527202298, 'epoch': 1.2}\n",
            "{'loss': 0.4098, 'learning_rate': 0.00016011084775050959, 'epoch': 1.2}\n",
            "{'loss': 0.3975, 'learning_rate': 0.00015998095161570995, 'epoch': 1.2}\n",
            "{'loss': 0.3684, 'learning_rate': 0.00015985089721037832, 'epoch': 1.2}\n",
            "{'loss': 0.3167, 'learning_rate': 0.00015972068487768665, 'epoch': 1.21}\n",
            "{'loss': 0.2898, 'learning_rate': 0.00015959031496122364, 'epoch': 1.21}\n",
            "{'loss': 0.3651, 'learning_rate': 0.00015945978780499375, 'epoch': 1.21}\n",
            "{'loss': 0.3619, 'learning_rate': 0.00015932910375341639, 'epoch': 1.21}\n",
            "{'loss': 0.3513, 'learning_rate': 0.0001591982631513249, 'epoch': 1.21}\n",
            "{'loss': 0.4004, 'learning_rate': 0.00015906726634396575, 'epoch': 1.22}\n",
            "{'loss': 0.3248, 'learning_rate': 0.00015893611367699762, 'epoch': 1.22}\n",
            "{'loss': 0.1201, 'learning_rate': 0.00015880480549649038, 'epoch': 1.22}\n",
            "{'loss': 0.3801, 'learning_rate': 0.00015867334214892436, 'epoch': 1.22}\n",
            "{'loss': 0.3396, 'learning_rate': 0.00015854172398118913, 'epoch': 1.22}\n",
            "{'loss': 0.4066, 'learning_rate': 0.000158409951340583, 'epoch': 1.23}\n",
            "{'loss': 0.3914, 'learning_rate': 0.0001582780245748118, 'epoch': 1.23}\n",
            "{'loss': 0.3521, 'learning_rate': 0.00015814594403198794, 'epoch': 1.23}\n",
            "{'loss': 0.1748, 'learning_rate': 0.00015801371006062982, 'epoch': 1.23}\n",
            "{'loss': 0.8917, 'learning_rate': 0.00015788132300966046, 'epoch': 1.23}\n",
            "{'loss': 0.2256, 'learning_rate': 0.00015774878322840694, 'epoch': 1.24}\n",
            "{'loss': 0.3967, 'learning_rate': 0.00015761609106659935, 'epoch': 1.24}\n",
            "{'loss': 0.3207, 'learning_rate': 0.0001574832468743698, 'epoch': 1.24}\n",
            "{'loss': 0.4069, 'learning_rate': 0.0001573502510022516, 'epoch': 1.24}\n",
            "{'loss': 0.3591, 'learning_rate': 0.00015721710380117826, 'epoch': 1.24}\n",
            "{'loss': 0.5213, 'learning_rate': 0.0001570838056224827, 'epoch': 1.25}\n",
            "{'loss': 0.4392, 'learning_rate': 0.0001569503568178961, 'epoch': 1.25}\n",
            "{'loss': 0.2538, 'learning_rate': 0.0001568167577395471, 'epoch': 1.25}\n",
            "{'loss': 0.4524, 'learning_rate': 0.00015668300873996095, 'epoch': 1.25}\n",
            "{'loss': 0.2821, 'learning_rate': 0.00015654911017205846, 'epoch': 1.25}\n",
            "{'loss': 0.7227, 'learning_rate': 0.000156415062389155, 'epoch': 1.26}\n",
            "{'loss': 0.1899, 'learning_rate': 0.00015628086574495992, 'epoch': 1.26}\n",
            "{'loss': 0.5631, 'learning_rate': 0.00015614652059357508, 'epoch': 1.26}\n",
            "{'loss': 0.2472, 'learning_rate': 0.00015601202728949436, 'epoch': 1.26}\n",
            "{'loss': 0.352, 'learning_rate': 0.00015587738618760258, 'epoch': 1.27}\n",
            "{'loss': 0.436, 'learning_rate': 0.00015574259764317448, 'epoch': 1.27}\n",
            "{'loss': 0.276, 'learning_rate': 0.00015560766201187386, 'epoch': 1.27}\n",
            "{'loss': 0.3063, 'learning_rate': 0.00015547257964975273, 'epoch': 1.27}\n",
            "{'loss': 0.494, 'learning_rate': 0.0001553373509132501, 'epoch': 1.27}\n",
            "{'loss': 0.9378, 'learning_rate': 0.00015520197615919145, 'epoch': 1.28}\n",
            "{'loss': 0.4658, 'learning_rate': 0.0001550664557447873, 'epoch': 1.28}\n",
            "{'loss': 0.3375, 'learning_rate': 0.0001549307900276327, 'epoch': 1.28}\n",
            "{'loss': 0.5186, 'learning_rate': 0.0001547949793657061, 'epoch': 1.28}\n",
            "{'loss': 0.4138, 'learning_rate': 0.00015465902411736828, 'epoch': 1.28}\n",
            "{'loss': 0.489, 'learning_rate': 0.00015452292464136167, 'epoch': 1.29}\n",
            "{'loss': 0.4201, 'learning_rate': 0.0001543866812968092, 'epoch': 1.29}\n",
            "{'loss': 0.2493, 'learning_rate': 0.00015425029444321347, 'epoch': 1.29}\n",
            "{'loss': 0.1921, 'learning_rate': 0.0001541137644404557, 'epoch': 1.29}\n",
            "{'loss': 0.3592, 'learning_rate': 0.0001539770916487949, 'epoch': 1.29}\n",
            "{'loss': 0.3788, 'learning_rate': 0.0001538402764288668, 'epoch': 1.3}\n",
            "{'loss': 0.4701, 'learning_rate': 0.00015370331914168296, 'epoch': 1.3}\n",
            "{'loss': 0.3071, 'learning_rate': 0.00015356622014862988, 'epoch': 1.3}\n",
            "{'loss': 0.4557, 'learning_rate': 0.00015342897981146785, 'epoch': 1.3}\n",
            "{'loss': 0.2403, 'learning_rate': 0.00015329159849233022, 'epoch': 1.3}\n",
            "{'loss': 0.3408, 'learning_rate': 0.0001531540765537223, 'epoch': 1.31}\n",
            "{'loss': 0.4815, 'learning_rate': 0.00015301641435852046, 'epoch': 1.31}\n",
            "{'loss': 0.3026, 'learning_rate': 0.00015287861226997125, 'epoch': 1.31}\n",
            "{'loss': 0.3613, 'learning_rate': 0.00015274067065169017, 'epoch': 1.31}\n",
            "{'loss': 0.1597, 'learning_rate': 0.00015260258986766104, 'epoch': 1.31}\n",
            "{'loss': 0.2255, 'learning_rate': 0.00015246437028223486, 'epoch': 1.32}\n",
            "{'loss': 0.3776, 'learning_rate': 0.00015232601226012886, 'epoch': 1.32}\n",
            "{'loss': 0.2484, 'learning_rate': 0.0001521875161664256, 'epoch': 1.32}\n",
            "{'loss': 0.2339, 'learning_rate': 0.00015204888236657188, 'epoch': 1.32}\n",
            "{'loss': 0.457, 'learning_rate': 0.00015191011122637796, 'epoch': 1.32}\n",
            "{'loss': 0.2669, 'learning_rate': 0.00015177120311201647, 'epoch': 1.33}\n",
            "{'loss': 0.1852, 'learning_rate': 0.00015163215839002146, 'epoch': 1.33}\n",
            "{'loss': 0.4411, 'learning_rate': 0.0001514929774272874, 'epoch': 1.33}\n",
            "{'loss': 0.3334, 'learning_rate': 0.00015135366059106832, 'epoch': 1.33}\n",
            "{'loss': 0.5427, 'learning_rate': 0.00015121420824897678, 'epoch': 1.34}\n",
            "{'loss': 0.2678, 'learning_rate': 0.00015107462076898289, 'epoch': 1.34}\n",
            "{'loss': 0.2635, 'learning_rate': 0.00015093489851941328, 'epoch': 1.34}\n",
            "{'loss': 0.3563, 'learning_rate': 0.0001507950418689503, 'epoch': 1.34}\n",
            "{'loss': 0.3118, 'learning_rate': 0.00015065505118663078, 'epoch': 1.34}\n",
            "{'loss': 0.3135, 'learning_rate': 0.00015051492684184546, 'epoch': 1.35}\n",
            "{'loss': 0.2385, 'learning_rate': 0.00015037466920433753, 'epoch': 1.35}\n",
            "{'loss': 0.1336, 'learning_rate': 0.00015023427864420202, 'epoch': 1.35}\n",
            "{'loss': 0.2594, 'learning_rate': 0.00015009375553188468, 'epoch': 1.35}\n",
            "{'loss': 0.3803, 'learning_rate': 0.00014995310023818107, 'epoch': 1.35}\n",
            "{'loss': 0.2949, 'learning_rate': 0.00014981231313423545, 'epoch': 1.36}\n",
            "{'loss': 0.6577, 'learning_rate': 0.00014967139459153993, 'epoch': 1.36}\n",
            "{'loss': 0.8265, 'learning_rate': 0.00014953034498193341, 'epoch': 1.36}\n",
            "{'loss': 0.1812, 'learning_rate': 0.0001493891646776007, 'epoch': 1.36}\n",
            "{'loss': 0.4412, 'learning_rate': 0.00014924785405107143, 'epoch': 1.36}\n",
            "{'loss': 0.3569, 'learning_rate': 0.00014910641347521907, 'epoch': 1.37}\n",
            "{'loss': 0.3805, 'learning_rate': 0.0001489648433232601, 'epoch': 1.37}\n",
            "{'loss': 0.3983, 'learning_rate': 0.00014882314396875274, 'epoch': 1.37}\n",
            "{'loss': 0.3428, 'learning_rate': 0.00014868131578559633, 'epoch': 1.37}\n",
            "{'loss': 0.2494, 'learning_rate': 0.00014853935914802994, 'epoch': 1.37}\n",
            "{'loss': 0.2044, 'learning_rate': 0.0001483972744306318, 'epoch': 1.38}\n",
            "{'loss': 0.5914, 'learning_rate': 0.00014825506200831794, 'epoch': 1.38}\n",
            "{'loss': 0.1983, 'learning_rate': 0.00014811272225634145, 'epoch': 1.38}\n",
            "{'loss': 0.1899, 'learning_rate': 0.00014797025555029133, 'epoch': 1.38}\n",
            "{'loss': 0.4269, 'learning_rate': 0.00014782766226609166, 'epoch': 1.38}\n",
            "{'loss': 0.4886, 'learning_rate': 0.00014768494278000048, 'epoch': 1.39}\n",
            "{'loss': 0.4796, 'learning_rate': 0.00014754209746860878, 'epoch': 1.39}\n",
            "{'loss': 0.3759, 'learning_rate': 0.00014739912670883967, 'epoch': 1.39}\n",
            "{'loss': 0.4513, 'learning_rate': 0.00014725603087794716, 'epoch': 1.39}\n",
            "{'loss': 0.1645, 'learning_rate': 0.0001471128103535154, 'epoch': 1.39}\n",
            "{'loss': 0.4371, 'learning_rate': 0.00014696946551345747, 'epoch': 1.4}\n",
            "{'loss': 0.2926, 'learning_rate': 0.00014682599673601458, 'epoch': 1.4}\n",
            "{'loss': 0.3293, 'learning_rate': 0.00014668240439975482, 'epoch': 1.4}\n",
            "{'loss': 0.5221, 'learning_rate': 0.00014653868888357249, 'epoch': 1.4}\n",
            "{'loss': 0.2801, 'learning_rate': 0.0001463948505666868, 'epoch': 1.4}\n",
            "{'loss': 0.35, 'learning_rate': 0.00014625088982864098, 'epoch': 1.41}\n",
            "{'loss': 0.3397, 'learning_rate': 0.00014610680704930142, 'epoch': 1.41}\n",
            "{'loss': 0.3621, 'learning_rate': 0.0001459626026088564, 'epoch': 1.41}\n",
            "{'loss': 0.3278, 'learning_rate': 0.0001458182768878153, 'epoch': 1.41}\n",
            "{'loss': 0.381, 'learning_rate': 0.00014567383026700752, 'epoch': 1.42}\n",
            "{'loss': 0.2624, 'learning_rate': 0.0001455292631275814, 'epoch': 1.42}\n",
            "{'loss': 0.5405, 'learning_rate': 0.0001453845758510034, 'epoch': 1.42}\n",
            "{'loss': 0.3031, 'learning_rate': 0.0001452397688190569, 'epoch': 1.42}\n",
            "{'loss': 0.2272, 'learning_rate': 0.00014509484241384134, 'epoch': 1.42}\n",
            "{'loss': 0.302, 'learning_rate': 0.00014494979701777102, 'epoch': 1.43}\n",
            "{'loss': 0.314, 'learning_rate': 0.00014480463301357445, 'epoch': 1.43}\n",
            "{'loss': 0.5746, 'learning_rate': 0.00014465935078429286, 'epoch': 1.43}\n",
            "{'loss': 0.499, 'learning_rate': 0.00014451395071327964, 'epoch': 1.43}\n",
            "{'loss': 0.5509, 'learning_rate': 0.00014436843318419896, 'epoch': 1.43}\n",
            "{'loss': 0.3366, 'learning_rate': 0.00014422279858102504, 'epoch': 1.44}\n",
            "{'loss': 0.1404, 'learning_rate': 0.00014407704728804097, 'epoch': 1.44}\n",
            "{'loss': 0.3094, 'learning_rate': 0.00014393117968983777, 'epoch': 1.44}\n",
            "{'loss': 0.3228, 'learning_rate': 0.0001437851961713133, 'epoch': 1.44}\n",
            "{'loss': 0.2699, 'learning_rate': 0.0001436390971176714, 'epoch': 1.44}\n",
            "{'loss': 0.3699, 'learning_rate': 0.0001434928829144206, 'epoch': 1.45}\n",
            "{'loss': 0.4832, 'learning_rate': 0.00014334655394737355, 'epoch': 1.45}\n",
            "{'loss': 0.283, 'learning_rate': 0.0001432001106026454, 'epoch': 1.45}\n",
            "{'loss': 0.36, 'learning_rate': 0.00014305355326665339, 'epoch': 1.45}\n",
            "{'loss': 0.1463, 'learning_rate': 0.00014290688232611526, 'epoch': 1.45}\n",
            "{'loss': 0.3301, 'learning_rate': 0.00014276009816804885, 'epoch': 1.46}\n",
            "{'loss': 0.2842, 'learning_rate': 0.00014261320117977042, 'epoch': 1.46}\n",
            "{'loss': 0.9179, 'learning_rate': 0.00014246619174889422, 'epoch': 1.46}\n",
            "{'loss': 0.5208, 'learning_rate': 0.00014231907026333098, 'epoch': 1.46}\n",
            "{'loss': 0.5139, 'learning_rate': 0.0001421718371112873, 'epoch': 1.46}\n",
            "{'loss': 0.2443, 'learning_rate': 0.00014202449268126426, 'epoch': 1.47}\n",
            "{'loss': 0.2059, 'learning_rate': 0.00014187703736205667, 'epoch': 1.47}\n",
            "{'loss': 0.3399, 'learning_rate': 0.00014172947154275195, 'epoch': 1.47}\n",
            "{'loss': 0.2984, 'learning_rate': 0.00014158179561272907, 'epoch': 1.47}\n",
            "{'loss': 0.2852, 'learning_rate': 0.00014143400996165746, 'epoch': 1.47}\n",
            "{'loss': 0.225, 'learning_rate': 0.00014128611497949626, 'epoch': 1.48}\n",
            "{'loss': 0.4259, 'learning_rate': 0.0001411381110564929, 'epoch': 1.48}\n",
            "{'loss': 0.4343, 'learning_rate': 0.0001409899985831824, 'epoch': 1.48}\n",
            "{'loss': 0.2586, 'learning_rate': 0.00014084177795038613, 'epoch': 1.48}\n",
            "{'loss': 0.5346, 'learning_rate': 0.00014069344954921096, 'epoch': 1.49}\n",
            "{'loss': 0.3444, 'learning_rate': 0.00014054501377104797, 'epoch': 1.49}\n",
            "{'loss': 0.3152, 'learning_rate': 0.00014039647100757177, 'epoch': 1.49}\n",
            "{'loss': 0.236, 'learning_rate': 0.00014024782165073912, 'epoch': 1.49}\n",
            "{'loss': 0.42, 'learning_rate': 0.00014009906609278806, 'epoch': 1.49}\n",
            "{'loss': 0.2745, 'learning_rate': 0.00013995020472623693, 'epoch': 1.5}\n",
            "{'loss': 0.3776, 'learning_rate': 0.0001398012379438832, 'epoch': 1.5}\n",
            "{'loss': 0.5386, 'learning_rate': 0.00013965216613880257, 'epoch': 1.5}\n",
            "{'loss': 0.282, 'learning_rate': 0.00013950298970434775, 'epoch': 1.5}\n",
            "{'loss': 0.2439, 'learning_rate': 0.00013935370903414768, 'epoch': 1.5}\n",
            "{'loss': 0.2097, 'learning_rate': 0.00013920432452210619, 'epoch': 1.51}\n",
            " 38% 729/1944 [56:13<1:32:55,  4.59s/it][2024-01-21 12:52:33,332] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 12:52:33,749] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 12:52:33,750] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 0/973 [00:00<?, ?it/s]\u001b[A[2024-01-21 12:52:34,445] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 2/973 [00:00<05:37,  2.88it/s]\u001b[A[2024-01-21 12:52:35,121] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 3/973 [00:01<07:49,  2.07it/s]\u001b[A[2024-01-21 12:52:35,817] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 4/973 [00:02<09:05,  1.78it/s]\u001b[A[2024-01-21 12:52:36,502] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 5/973 [00:02<09:46,  1.65it/s]\u001b[A[2024-01-21 12:52:37,181] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 6/973 [00:03<10:09,  1.59it/s]\u001b[A[2024-01-21 12:52:37,870] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 7/973 [00:04<10:27,  1.54it/s]\u001b[A[2024-01-21 12:52:38,559] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 8/973 [00:04<10:38,  1.51it/s]\u001b[A[2024-01-21 12:52:39,243] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 9/973 [00:05<10:44,  1.50it/s]\u001b[A[2024-01-21 12:52:39,933] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 10/973 [00:06<10:50,  1.48it/s]\u001b[A[2024-01-21 12:52:40,621] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 11/973 [00:06<10:53,  1.47it/s]\u001b[A[2024-01-21 12:52:41,307] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 12/973 [00:07<10:54,  1.47it/s]\u001b[A[2024-01-21 12:52:41,996] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 13/973 [00:08<10:55,  1.46it/s]\u001b[A[2024-01-21 12:52:42,685] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 14/973 [00:08<10:57,  1.46it/s]\u001b[A[2024-01-21 12:52:43,372] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 15/973 [00:09<10:56,  1.46it/s]\u001b[A[2024-01-21 12:52:44,060] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 16/973 [00:10<10:56,  1.46it/s]\u001b[A[2024-01-21 12:52:44,746] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 17/973 [00:10<10:56,  1.46it/s]\u001b[A[2024-01-21 12:52:45,429] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 18/973 [00:11<10:54,  1.46it/s]\u001b[A[2024-01-21 12:52:46,116] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 19/973 [00:12<10:54,  1.46it/s]\u001b[A[2024-01-21 12:52:46,801] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 0.5334182977676392, 'eval_runtime': 13.7316, 'eval_samples_per_second': 1.456, 'eval_steps_per_second': 1.456, 'epoch': 1.51}\n",
            " 38% 729/1944 [56:27<1:32:55,  4.59s/it]\n",
            "  2% 20/973 [00:13<10:53,  1.46it/s]\u001b[A\n",
            "{'loss': 0.2906, 'learning_rate': 0.00013905483656240125, 'epoch': 1.51}\n",
            "{'loss': 0.4012, 'learning_rate': 0.0001389052455494837, 'epoch': 1.51}\n",
            "{'loss': 0.2084, 'learning_rate': 0.00013875555187807637, 'epoch': 1.51}\n",
            "{'loss': 0.3729, 'learning_rate': 0.00013860575594317292, 'epoch': 1.51}\n",
            "{'loss': 0.502, 'learning_rate': 0.00013845585814003684, 'epoch': 1.52}\n",
            "{'loss': 0.6161, 'learning_rate': 0.00013830585886420054, 'epoch': 1.52}\n",
            "{'loss': 0.3128, 'learning_rate': 0.000138155758511464, 'epoch': 1.52}\n",
            "{'loss': 0.308, 'learning_rate': 0.0001380055574778941, 'epoch': 1.52}\n",
            "{'loss': 0.207, 'learning_rate': 0.00013785525615982319, 'epoch': 1.52}\n",
            "{'loss': 0.4768, 'learning_rate': 0.00013770485495384843, 'epoch': 1.53}\n",
            "{'loss': 0.2988, 'learning_rate': 0.0001375543542568304, 'epoch': 1.53}\n",
            "{'loss': 0.4742, 'learning_rate': 0.00013740375446589232, 'epoch': 1.53}\n",
            "{'loss': 0.2565, 'learning_rate': 0.00013725305597841878, 'epoch': 1.53}\n",
            "{'loss': 0.4168, 'learning_rate': 0.00013710225919205484, 'epoch': 1.53}\n",
            "{'loss': 0.3111, 'learning_rate': 0.000136951364504705, 'epoch': 1.54}\n",
            "{'loss': 0.2924, 'learning_rate': 0.00013680037231453203, 'epoch': 1.54}\n",
            "{'loss': 0.226, 'learning_rate': 0.000136649283019956, 'epoch': 1.54}\n",
            "{'loss': 0.2438, 'learning_rate': 0.00013649809701965311, 'epoch': 1.54}\n",
            "{'loss': 0.3813, 'learning_rate': 0.00013634681471255493, 'epoch': 1.54}\n",
            "{'loss': 0.2794, 'learning_rate': 0.000136195436497847, 'epoch': 1.55}\n",
            "{'loss': 0.4667, 'learning_rate': 0.00013604396277496796, 'epoch': 1.55}\n",
            "{'loss': 0.3558, 'learning_rate': 0.00013589239394360848, 'epoch': 1.55}\n",
            "{'loss': 0.3173, 'learning_rate': 0.00013574073040371022, 'epoch': 1.55}\n",
            "{'loss': 0.2885, 'learning_rate': 0.00013558897255546473, 'epoch': 1.55}\n",
            "{'loss': 0.1737, 'learning_rate': 0.0001354371207993123, 'epoch': 1.56}\n",
            "{'loss': 0.2699, 'learning_rate': 0.00013528517553594124, 'epoch': 1.56}\n",
            "{'loss': 0.2796, 'learning_rate': 0.00013513313716628637, 'epoch': 1.56}\n",
            "{'loss': 0.4571, 'learning_rate': 0.0001349810060915283, 'epoch': 1.56}\n",
            "{'loss': 0.3171, 'learning_rate': 0.00013482878271309226, 'epoch': 1.57}\n",
            "{'loss': 0.5919, 'learning_rate': 0.000134676467432647, 'epoch': 1.57}\n",
            "{'loss': 0.3019, 'learning_rate': 0.00013452406065210382, 'epoch': 1.57}\n",
            "{'loss': 0.2322, 'learning_rate': 0.00013437156277361538, 'epoch': 1.57}\n",
            "{'loss': 0.4336, 'learning_rate': 0.00013421897419957482, 'epoch': 1.57}\n",
            "{'loss': 0.2409, 'learning_rate': 0.0001340662953326145, 'epoch': 1.58}\n",
            "{'loss': 0.2646, 'learning_rate': 0.00013391352657560513, 'epoch': 1.58}\n",
            "{'loss': 0.1575, 'learning_rate': 0.0001337606683316545, 'epoch': 1.58}\n",
            "{'loss': 0.5334, 'learning_rate': 0.00013360772100410665, 'epoch': 1.58}\n",
            "{'loss': 0.6057, 'learning_rate': 0.00013345468499654056, 'epoch': 1.58}\n",
            "{'loss': 0.3007, 'learning_rate': 0.00013330156071276932, 'epoch': 1.59}\n",
            "{'loss': 0.5436, 'learning_rate': 0.00013314834855683886, 'epoch': 1.59}\n",
            "{'loss': 0.3274, 'learning_rate': 0.00013299504893302705, 'epoch': 1.59}\n",
            "{'loss': 0.3901, 'learning_rate': 0.00013284166224584253, 'epoch': 1.59}\n",
            "{'loss': 0.6121, 'learning_rate': 0.0001326881889000236, 'epoch': 1.59}\n",
            "{'loss': 0.3944, 'learning_rate': 0.00013253462930053742, 'epoch': 1.6}\n",
            "{'loss': 0.2756, 'learning_rate': 0.00013238098385257848, 'epoch': 1.6}\n",
            "{'loss': 0.3349, 'learning_rate': 0.00013222725296156807, 'epoch': 1.6}\n",
            "{'loss': 0.4835, 'learning_rate': 0.0001320734370331527, 'epoch': 1.6}\n",
            "{'loss': 0.3487, 'learning_rate': 0.0001319195364732034, 'epoch': 1.6}\n",
            "{'loss': 0.3624, 'learning_rate': 0.00013176555168781451, 'epoch': 1.61}\n",
            "{'loss': 0.2185, 'learning_rate': 0.00013161148308330257, 'epoch': 1.61}\n",
            "{'loss': 0.3319, 'learning_rate': 0.00013145733106620532, 'epoch': 1.61}\n",
            "{'loss': 0.3436, 'learning_rate': 0.00013130309604328057, 'epoch': 1.61}\n",
            "{'loss': 0.2909, 'learning_rate': 0.00013114877842150516, 'epoch': 1.61}\n",
            "{'loss': 0.3265, 'learning_rate': 0.000130994378608074, 'epoch': 1.62}\n",
            "{'loss': 0.3877, 'learning_rate': 0.00013083989701039868, 'epoch': 1.62}\n",
            "{'loss': 0.32, 'learning_rate': 0.0001306853340361067, 'epoch': 1.62}\n",
            "{'loss': 0.5711, 'learning_rate': 0.0001305306900930403, 'epoch': 1.62}\n",
            "{'loss': 0.2096, 'learning_rate': 0.00013037596558925532, 'epoch': 1.62}\n",
            "{'loss': 0.4015, 'learning_rate': 0.00013022116093302022, 'epoch': 1.63}\n",
            "{'loss': 0.388, 'learning_rate': 0.00013006627653281493, 'epoch': 1.63}\n",
            "{'loss': 0.299, 'learning_rate': 0.0001299113127973298, 'epoch': 1.63}\n",
            "{'loss': 0.2581, 'learning_rate': 0.00012975627013546453, 'epoch': 1.63}\n",
            "{'loss': 0.2998, 'learning_rate': 0.0001296011489563271, 'epoch': 1.64}\n",
            "{'loss': 0.4492, 'learning_rate': 0.00012944594966923263, 'epoch': 1.64}\n",
            "{'loss': 0.3429, 'learning_rate': 0.00012929067268370234, 'epoch': 1.64}\n",
            "{'loss': 0.3091, 'learning_rate': 0.00012913531840946248, 'epoch': 1.64}\n",
            "{'loss': 0.222, 'learning_rate': 0.00012897988725644335, 'epoch': 1.64}\n",
            "{'loss': 0.2779, 'learning_rate': 0.0001288243796347779, 'epoch': 1.65}\n",
            "{'loss': 0.3993, 'learning_rate': 0.00012866879595480098, 'epoch': 1.65}\n",
            "{'loss': 0.3223, 'learning_rate': 0.0001285131366270482, 'epoch': 1.65}\n",
            "{'loss': 0.2992, 'learning_rate': 0.00012835740206225464, 'epoch': 1.65}\n",
            "{'loss': 0.1819, 'learning_rate': 0.00012820159267135396, 'epoch': 1.65}\n",
            "{'loss': 0.3456, 'learning_rate': 0.0001280457088654773, 'epoch': 1.66}\n",
            "{'loss': 0.3938, 'learning_rate': 0.00012788975105595214, 'epoch': 1.66}\n",
            "{'loss': 0.3095, 'learning_rate': 0.00012773371965430115, 'epoch': 1.66}\n",
            "{'loss': 0.3799, 'learning_rate': 0.00012757761507224132, 'epoch': 1.66}\n",
            "{'loss': 0.3218, 'learning_rate': 0.00012742143772168264, 'epoch': 1.66}\n",
            "{'loss': 0.3124, 'learning_rate': 0.00012726518801472718, 'epoch': 1.67}\n",
            "{'loss': 0.2422, 'learning_rate': 0.0001271088663636679, 'epoch': 1.67}\n",
            "{'loss': 0.2842, 'learning_rate': 0.0001269524731809875, 'epoch': 1.67}\n",
            "{'loss': 0.2072, 'learning_rate': 0.00012679600887935768, 'epoch': 1.67}\n",
            "{'loss': 0.4759, 'learning_rate': 0.00012663947387163755, 'epoch': 1.67}\n",
            "{'loss': 0.5053, 'learning_rate': 0.00012648286857087294, 'epoch': 1.68}\n",
            "{'loss': 0.4603, 'learning_rate': 0.00012632619339029508, 'epoch': 1.68}\n",
            "{'loss': 0.2033, 'learning_rate': 0.00012616944874331963, 'epoch': 1.68}\n",
            "{'loss': 0.2933, 'learning_rate': 0.00012601263504354555, 'epoch': 1.68}\n",
            "{'loss': 0.146, 'learning_rate': 0.00012585575270475402, 'epoch': 1.68}\n",
            "{'loss': 0.1793, 'learning_rate': 0.00012569880214090726, 'epoch': 1.69}\n",
            "{'loss': 0.2448, 'learning_rate': 0.0001255417837661476, 'epoch': 1.69}\n",
            "{'loss': 0.5842, 'learning_rate': 0.00012538469799479627, 'epoch': 1.69}\n",
            "{'loss': 0.3131, 'learning_rate': 0.00012522754524135228, 'epoch': 1.69}\n",
            "{'loss': 0.3449, 'learning_rate': 0.0001250703259204916, 'epoch': 1.69}\n",
            "{'loss': 0.4244, 'learning_rate': 0.00012491304044706553, 'epoch': 1.7}\n",
            "{'loss': 0.4244, 'learning_rate': 0.00012475568923610015, 'epoch': 1.7}\n",
            "{'loss': 0.3292, 'learning_rate': 0.00012459827270279499, 'epoch': 1.7}\n",
            "{'loss': 0.199, 'learning_rate': 0.0001244407912625218, 'epoch': 1.7}\n",
            "{'loss': 0.3082, 'learning_rate': 0.00012428324533082376, 'epoch': 1.71}\n",
            "{'loss': 0.4603, 'learning_rate': 0.00012412563532341413, 'epoch': 1.71}\n",
            "{'loss': 0.2775, 'learning_rate': 0.0001239679616561753, 'epoch': 1.71}\n",
            "{'loss': 0.5905, 'learning_rate': 0.0001238102247451575, 'epoch': 1.71}\n",
            "{'loss': 0.3109, 'learning_rate': 0.0001236524250065781, 'epoch': 1.71}\n",
            "{'loss': 0.3334, 'learning_rate': 0.00012349456285682002, 'epoch': 1.72}\n",
            "{'loss': 0.5021, 'learning_rate': 0.00012333663871243094, 'epoch': 1.72}\n",
            "{'loss': 0.289, 'learning_rate': 0.00012317865299012212, 'epoch': 1.72}\n",
            "{'loss': 0.38, 'learning_rate': 0.00012302060610676737, 'epoch': 1.72}\n",
            "{'loss': 0.288, 'learning_rate': 0.00012286249847940178, 'epoch': 1.72}\n",
            "{'loss': 0.2557, 'learning_rate': 0.00012270433052522073, 'epoch': 1.73}\n",
            "{'loss': 0.2517, 'learning_rate': 0.0001225461026615789, 'epoch': 1.73}\n",
            "{'loss': 0.467, 'learning_rate': 0.00012238781530598896, 'epoch': 1.73}\n",
            "{'loss': 0.1955, 'learning_rate': 0.00012222946887612056, 'epoch': 1.73}\n",
            "{'loss': 0.2858, 'learning_rate': 0.0001220710637897992, 'epoch': 1.73}\n",
            "{'loss': 0.3278, 'learning_rate': 0.00012191260046500525, 'epoch': 1.74}\n",
            "{'loss': 0.2047, 'learning_rate': 0.00012175407931987273, 'epoch': 1.74}\n",
            "{'loss': 0.2105, 'learning_rate': 0.0001215955007726881, 'epoch': 1.74}\n",
            "{'loss': 0.2643, 'learning_rate': 0.00012143686524188954, 'epoch': 1.74}\n",
            "{'loss': 0.5041, 'learning_rate': 0.00012127817314606526, 'epoch': 1.74}\n",
            "{'loss': 0.2825, 'learning_rate': 0.00012111942490395305, 'epoch': 1.75}\n",
            "{'loss': 0.4078, 'learning_rate': 0.00012096062093443863, 'epoch': 1.75}\n",
            "{'loss': 0.1677, 'learning_rate': 0.00012080176165655488, 'epoch': 1.75}\n",
            "{'loss': 0.1957, 'learning_rate': 0.00012064284748948053, 'epoch': 1.75}\n",
            "{'loss': 0.2953, 'learning_rate': 0.00012048387885253925, 'epoch': 1.75}\n",
            "{'loss': 0.194, 'learning_rate': 0.0001203248561651984, 'epoch': 1.76}\n",
            "{'loss': 0.2424, 'learning_rate': 0.00012016577984706792, 'epoch': 1.76}\n",
            "{'loss': 0.1892, 'learning_rate': 0.0001200066503178993, 'epoch': 1.76}\n",
            "{'loss': 0.4042, 'learning_rate': 0.00011984746799758442, 'epoch': 1.76}\n",
            "{'loss': 0.3893, 'learning_rate': 0.0001196882333061545, 'epoch': 1.76}\n",
            "{'loss': 0.393, 'learning_rate': 0.0001195289466637789, 'epoch': 1.77}\n",
            "{'loss': 0.3743, 'learning_rate': 0.00011936960849076411, 'epoch': 1.77}\n",
            "{'loss': 0.5203, 'learning_rate': 0.00011921021920755253, 'epoch': 1.77}\n",
            "{'loss': 0.3692, 'learning_rate': 0.00011905077923472146, 'epoch': 1.77}\n",
            "{'loss': 0.3989, 'learning_rate': 0.00011889128899298198, 'epoch': 1.77}\n",
            "{'loss': 0.4087, 'learning_rate': 0.00011873174890317775, 'epoch': 1.78}\n",
            "{'loss': 0.9204, 'learning_rate': 0.00011857215938628403, 'epoch': 1.78}\n",
            "{'loss': 0.6903, 'learning_rate': 0.00011841252086340649, 'epoch': 1.78}\n",
            "{'loss': 0.2643, 'learning_rate': 0.00011825283375578005, 'epoch': 1.78}\n",
            "{'loss': 0.3078, 'learning_rate': 0.0001180930984847679, 'epoch': 1.79}\n",
            "{'loss': 0.316, 'learning_rate': 0.00011793331547186026, 'epoch': 1.79}\n",
            "{'loss': 0.2274, 'learning_rate': 0.00011777348513867341, 'epoch': 1.79}\n",
            "{'loss': 0.2415, 'learning_rate': 0.00011761360790694837, 'epoch': 1.79}\n",
            "{'loss': 0.3546, 'learning_rate': 0.00011745368419855005, 'epoch': 1.79}\n",
            "{'loss': 0.205, 'learning_rate': 0.00011729371443546587, 'epoch': 1.8}\n",
            "{'loss': 0.3977, 'learning_rate': 0.00011713369903980485, 'epoch': 1.8}\n",
            "{'loss': 0.0851, 'learning_rate': 0.00011697363843379641, 'epoch': 1.8}\n",
            "{'loss': 0.2766, 'learning_rate': 0.00011681353303978924, 'epoch': 1.8}\n",
            "{'loss': 0.4979, 'learning_rate': 0.00011665338328025027, 'epoch': 1.8}\n",
            "{'loss': 0.3146, 'learning_rate': 0.00011649318957776336, 'epoch': 1.81}\n",
            "{'loss': 0.4412, 'learning_rate': 0.00011633295235502851, 'epoch': 1.81}\n",
            "{'loss': 0.3173, 'learning_rate': 0.0001161726720348604, 'epoch': 1.81}\n",
            "{'loss': 0.3351, 'learning_rate': 0.00011601234904018751, 'epoch': 1.81}\n",
            "{'loss': 0.4018, 'learning_rate': 0.00011585198379405092, 'epoch': 1.81}\n",
            "{'loss': 0.223, 'learning_rate': 0.00011569157671960316, 'epoch': 1.82}\n",
            "{'loss': 0.1096, 'learning_rate': 0.00011553112824010716, 'epoch': 1.82}\n",
            "{'loss': 0.3808, 'learning_rate': 0.00011537063877893513, 'epoch': 1.82}\n",
            "{'loss': 0.3333, 'learning_rate': 0.00011521010875956734, 'epoch': 1.82}\n",
            "{'loss': 0.2878, 'learning_rate': 0.00011504953860559116, 'epoch': 1.82}\n",
            "{'loss': 0.3282, 'learning_rate': 0.00011488892874069981, 'epoch': 1.83}\n",
            "{'loss': 0.1725, 'learning_rate': 0.00011472827958869133, 'epoch': 1.83}\n",
            "{'loss': 0.6516, 'learning_rate': 0.0001145675915734674, 'epoch': 1.83}\n",
            "{'loss': 0.3239, 'learning_rate': 0.00011440686511903223, 'epoch': 1.83}\n",
            "{'loss': 0.3553, 'learning_rate': 0.00011424610064949153, 'epoch': 1.83}\n",
            "{'loss': 0.4616, 'learning_rate': 0.00011408529858905126, 'epoch': 1.84}\n",
            "{'loss': 0.4823, 'learning_rate': 0.0001139244593620166, 'epoch': 1.84}\n",
            "{'loss': 0.573, 'learning_rate': 0.00011376358339279076, 'epoch': 1.84}\n",
            "{'loss': 0.2437, 'learning_rate': 0.00011360267110587393, 'epoch': 1.84}\n",
            "{'loss': 0.2825, 'learning_rate': 0.00011344172292586217, 'epoch': 1.84}\n",
            "{'loss': 0.2842, 'learning_rate': 0.00011328073927744616, 'epoch': 1.85}\n",
            "{'loss': 0.3367, 'learning_rate': 0.00011311972058541023, 'epoch': 1.85}\n",
            "{'loss': 0.3614, 'learning_rate': 0.0001129586672746312, 'epoch': 1.85}\n",
            "{'loss': 0.1983, 'learning_rate': 0.00011279757977007717, 'epoch': 1.85}\n",
            "{'loss': 0.3656, 'learning_rate': 0.0001126364584968065, 'epoch': 1.86}\n",
            "{'loss': 0.2709, 'learning_rate': 0.00011247530387996668, 'epoch': 1.86}\n",
            "{'loss': 0.3843, 'learning_rate': 0.00011231411634479316, 'epoch': 1.86}\n",
            "{'loss': 0.3679, 'learning_rate': 0.00011215289631660823, 'epoch': 1.86}\n",
            "{'loss': 0.2145, 'learning_rate': 0.00011199164422081995, 'epoch': 1.86}\n",
            "{'loss': 0.3144, 'learning_rate': 0.000111830360482921, 'epoch': 1.87}\n",
            "{'loss': 0.2609, 'learning_rate': 0.00011166904552848749, 'epoch': 1.87}\n",
            "{'loss': 0.2458, 'learning_rate': 0.000111507699783178, 'epoch': 1.87}\n",
            "{'loss': 0.3915, 'learning_rate': 0.0001113463236727323, 'epoch': 1.87}\n",
            "{'loss': 0.3587, 'learning_rate': 0.00011118491762297027, 'epoch': 1.87}\n",
            "{'loss': 0.4079, 'learning_rate': 0.0001110234820597908, 'epoch': 1.88}\n",
            "{'loss': 0.2937, 'learning_rate': 0.00011086201740917075, 'epoch': 1.88}\n",
            "{'loss': 0.4229, 'learning_rate': 0.00011070052409716354, 'epoch': 1.88}\n",
            "{'loss': 0.3525, 'learning_rate': 0.00011053900254989837, 'epoch': 1.88}\n",
            "{'loss': 0.2865, 'learning_rate': 0.00011037745319357893, 'epoch': 1.88}\n",
            "{'loss': 0.2039, 'learning_rate': 0.00011021587645448222, 'epoch': 1.89}\n",
            "{'loss': 0.5601, 'learning_rate': 0.00011005427275895756, 'epoch': 1.89}\n",
            "{'loss': 0.3348, 'learning_rate': 0.00010989264253342538, 'epoch': 1.89}\n",
            "{'loss': 0.2548, 'learning_rate': 0.00010973098620437609, 'epoch': 1.89}\n",
            "{'loss': 0.3612, 'learning_rate': 0.00010956930419836899, 'epoch': 1.89}\n",
            "{'loss': 0.422, 'learning_rate': 0.0001094075969420312, 'epoch': 1.9}\n",
            "{'loss': 0.2575, 'learning_rate': 0.00010924586486205632, 'epoch': 1.9}\n",
            "{'loss': 0.553, 'learning_rate': 0.00010908410838520362, 'epoch': 1.9}\n",
            "{'loss': 0.5639, 'learning_rate': 0.00010892232793829659, 'epoch': 1.9}\n",
            "{'loss': 0.2193, 'learning_rate': 0.0001087605239482221, 'epoch': 1.9}\n",
            "{'loss': 0.2693, 'learning_rate': 0.00010859869684192907, 'epoch': 1.91}\n",
            "{'loss': 0.4026, 'learning_rate': 0.00010843684704642744, 'epoch': 1.91}\n",
            "{'loss': 0.3156, 'learning_rate': 0.00010827497498878703, 'epoch': 1.91}\n",
            "{'loss': 0.434, 'learning_rate': 0.00010811308109613634, 'epoch': 1.91}\n",
            "{'loss': 0.4429, 'learning_rate': 0.00010795116579566158, 'epoch': 1.91}\n",
            "{'loss': 0.3217, 'learning_rate': 0.00010778922951460537, 'epoch': 1.92}\n",
            "{'loss': 0.1506, 'learning_rate': 0.00010762727268026571, 'epoch': 1.92}\n",
            "{'loss': 0.3618, 'learning_rate': 0.00010746529571999491, 'epoch': 1.92}\n",
            "{'loss': 0.6472, 'learning_rate': 0.00010730329906119822, 'epoch': 1.92}\n",
            "{'loss': 0.4093, 'learning_rate': 0.00010714128313133307, 'epoch': 1.92}\n",
            "{'loss': 0.3952, 'learning_rate': 0.00010697924835790758, 'epoch': 1.93}\n",
            "{'loss': 0.6025, 'learning_rate': 0.00010681719516847968, 'epoch': 1.93}\n",
            "{'loss': 0.3203, 'learning_rate': 0.00010665512399065582, 'epoch': 1.93}\n",
            "{'loss': 0.2277, 'learning_rate': 0.00010649303525209005, 'epoch': 1.93}\n",
            "{'loss': 0.3625, 'learning_rate': 0.00010633092938048257, 'epoch': 1.94}\n",
            "{'loss': 0.3194, 'learning_rate': 0.00010616880680357892, 'epoch': 1.94}\n",
            "{'loss': 0.2121, 'learning_rate': 0.00010600666794916871, 'epoch': 1.94}\n",
            "{'loss': 0.381, 'learning_rate': 0.00010584451324508444, 'epoch': 1.94}\n",
            "{'loss': 0.3579, 'learning_rate': 0.00010568234311920051, 'epoch': 1.94}\n",
            "{'loss': 0.435, 'learning_rate': 0.00010552015799943193, 'epoch': 1.95}\n",
            "{'loss': 0.215, 'learning_rate': 0.00010535795831373337, 'epoch': 1.95}\n",
            "{'loss': 0.5116, 'learning_rate': 0.00010519574449009784, 'epoch': 1.95}\n",
            "{'loss': 0.3143, 'learning_rate': 0.0001050335169565557, 'epoch': 1.95}\n",
            "{'loss': 0.3623, 'learning_rate': 0.00010487127614117352, 'epoch': 1.95}\n",
            "{'loss': 0.1695, 'learning_rate': 0.00010470902247205283, 'epoch': 1.96}\n",
            "{'loss': 0.584, 'learning_rate': 0.00010454675637732916, 'epoch': 1.96}\n",
            "{'loss': 0.252, 'learning_rate': 0.00010438447828517077, 'epoch': 1.96}\n",
            "{'loss': 0.4532, 'learning_rate': 0.00010422218862377764, 'epoch': 1.96}\n",
            "{'loss': 0.258, 'learning_rate': 0.00010405988782138019, 'epoch': 1.96}\n",
            "{'loss': 0.0722, 'learning_rate': 0.00010389757630623831, 'epoch': 1.97}\n",
            "{'loss': 0.2477, 'learning_rate': 0.00010373525450664016, 'epoch': 1.97}\n",
            "{'loss': 0.2517, 'learning_rate': 0.000103572922850901, 'epoch': 1.97}\n",
            "{'loss': 0.38, 'learning_rate': 0.00010341058176736207, 'epoch': 1.97}\n",
            "{'loss': 0.4648, 'learning_rate': 0.00010324823168438953, 'epoch': 1.97}\n",
            "{'loss': 0.1968, 'learning_rate': 0.00010308587303037334, 'epoch': 1.98}\n",
            "{'loss': 0.2638, 'learning_rate': 0.00010292350623372598, 'epoch': 1.98}\n",
            "{'loss': 0.1854, 'learning_rate': 0.00010276113172288144, 'epoch': 1.98}\n",
            "{'loss': 0.2924, 'learning_rate': 0.0001025987499262941, 'epoch': 1.98}\n",
            "{'loss': 0.4794, 'learning_rate': 0.00010243636127243754, 'epoch': 1.98}\n",
            "{'loss': 0.3888, 'learning_rate': 0.00010227396618980344, 'epoch': 1.99}\n",
            "{'loss': 0.3265, 'learning_rate': 0.00010211156510690043, 'epoch': 1.99}\n",
            "{'loss': 0.5603, 'learning_rate': 0.00010194915845225304, 'epoch': 1.99}\n",
            "{'loss': 0.2502, 'learning_rate': 0.00010178674665440034, 'epoch': 1.99}\n",
            " 50% 966/1944 [1:14:31<1:14:43,  4.58s/it][2024-01-21 13:10:50,553] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "{'loss': 0.1789, 'learning_rate': 0.00010162433014189519, 'epoch': 2.0}\n",
            "{'loss': 0.2168, 'learning_rate': 0.00010146190934330268, 'epoch': 2.0}\n",
            "{'loss': 0.3034, 'learning_rate': 0.00010129948468719939, 'epoch': 2.01}\n",
            "{'loss': 0.245, 'learning_rate': 0.00010113705660217197, 'epoch': 2.01}\n",
            "{'loss': 0.502, 'learning_rate': 0.00010097462551681612, 'epoch': 2.01}\n",
            "{'loss': 0.1888, 'learning_rate': 0.00010081219185973552, 'epoch': 2.01}\n",
            " 50% 972/1944 [1:14:58<1:14:23,  4.59s/it][2024-01-21 13:11:18,109] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 13:11:18,529] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 13:11:18,530] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 0/973 [00:00<?, ?it/s]\u001b[A[2024-01-21 13:11:19,230] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 2/973 [00:00<05:39,  2.86it/s]\u001b[A[2024-01-21 13:11:19,908] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 3/973 [00:01<07:51,  2.06it/s]\u001b[A[2024-01-21 13:11:20,601] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 4/973 [00:02<09:05,  1.78it/s]\u001b[A[2024-01-21 13:11:21,294] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 5/973 [00:02<09:48,  1.64it/s]\u001b[A[2024-01-21 13:11:21,974] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 6/973 [00:03<10:11,  1.58it/s]\u001b[A[2024-01-21 13:11:22,666] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 7/973 [00:04<10:29,  1.53it/s]\u001b[A[2024-01-21 13:11:23,358] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 8/973 [00:04<10:40,  1.51it/s]\u001b[A[2024-01-21 13:11:24,045] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 9/973 [00:05<10:47,  1.49it/s]\u001b[A[2024-01-21 13:11:24,734] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 10/973 [00:06<10:51,  1.48it/s]\u001b[A[2024-01-21 13:11:25,426] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 11/973 [00:06<10:55,  1.47it/s]\u001b[A[2024-01-21 13:11:26,114] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 12/973 [00:07<10:56,  1.46it/s]\u001b[A[2024-01-21 13:11:26,800] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 13/973 [00:08<10:56,  1.46it/s]\u001b[A[2024-01-21 13:11:27,488] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 14/973 [00:08<10:57,  1.46it/s]\u001b[A[2024-01-21 13:11:28,179] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 15/973 [00:09<10:58,  1.46it/s]\u001b[A[2024-01-21 13:11:28,867] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 16/973 [00:10<10:57,  1.46it/s]\u001b[A[2024-01-21 13:11:29,555] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 17/973 [00:11<10:57,  1.45it/s]\u001b[A[2024-01-21 13:11:30,243] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 18/973 [00:11<10:56,  1.45it/s]\u001b[A[2024-01-21 13:11:30,931] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 19/973 [00:12<10:55,  1.45it/s]\u001b[A[2024-01-21 13:11:31,621] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 0.5338848829269409, 'eval_runtime': 13.7761, 'eval_samples_per_second': 1.452, 'eval_steps_per_second': 1.452, 'epoch': 2.01}\n",
            " 50% 972/1944 [1:15:12<1:14:23,  4.59s/it]\n",
            "  2% 20/973 [00:13<10:56,  1.45it/s]\u001b[A\n",
            "{'loss': 0.3044, 'learning_rate': 0.00010064975605954054, 'epoch': 2.01}\n",
            "{'loss': 0.3644, 'learning_rate': 0.00010048731854484735, 'epoch': 2.02}\n",
            "{'loss': 0.2909, 'learning_rate': 0.00010032487974427645, 'epoch': 2.02}\n",
            "{'loss': 0.2158, 'learning_rate': 0.00010016244008645195, 'epoch': 2.02}\n",
            "{'loss': 0.1824, 'learning_rate': 0.0001, 'epoch': 2.02}\n",
            "{'loss': 0.2506, 'learning_rate': 9.983755991354809e-05, 'epoch': 2.02}\n",
            "{'loss': 0.2891, 'learning_rate': 9.967512025572356e-05, 'epoch': 2.03}\n",
            "{'loss': 0.2385, 'learning_rate': 9.951268145515269e-05, 'epoch': 2.03}\n",
            "{'loss': 0.1628, 'learning_rate': 9.935024394045948e-05, 'epoch': 2.03}\n",
            "{'loss': 0.3694, 'learning_rate': 9.918780814026452e-05, 'epoch': 2.03}\n",
            "{'loss': 0.1965, 'learning_rate': 9.90253744831839e-05, 'epoch': 2.03}\n",
            "{'loss': 0.3285, 'learning_rate': 9.886294339782805e-05, 'epoch': 2.04}\n",
            "{'loss': 0.2982, 'learning_rate': 9.870051531280064e-05, 'epoch': 2.04}\n",
            "{'loss': 0.5787, 'learning_rate': 9.853809065669733e-05, 'epoch': 2.04}\n",
            "{'loss': 0.2368, 'learning_rate': 9.837566985810484e-05, 'epoch': 2.04}\n",
            "{'loss': 0.2949, 'learning_rate': 9.821325334559967e-05, 'epoch': 2.05}\n",
            "{'loss': 0.274, 'learning_rate': 9.8050841547747e-05, 'epoch': 2.05}\n",
            "{'loss': 0.2638, 'learning_rate': 9.78884348930996e-05, 'epoch': 2.05}\n",
            "{'loss': 0.1284, 'learning_rate': 9.772603381019658e-05, 'epoch': 2.05}\n",
            "{'loss': 0.4488, 'learning_rate': 9.756363872756249e-05, 'epoch': 2.05}\n",
            "{'loss': 0.3548, 'learning_rate': 9.740125007370592e-05, 'epoch': 2.06}\n",
            "{'loss': 0.1974, 'learning_rate': 9.723886827711857e-05, 'epoch': 2.06}\n",
            "{'loss': 0.1887, 'learning_rate': 9.707649376627406e-05, 'epoch': 2.06}\n",
            "{'loss': 0.2368, 'learning_rate': 9.691412696962667e-05, 'epoch': 2.06}\n",
            "{'loss': 0.1664, 'learning_rate': 9.675176831561048e-05, 'epoch': 2.06}\n",
            "{'loss': 0.2312, 'learning_rate': 9.658941823263797e-05, 'epoch': 2.07}\n",
            "{'loss': 0.25, 'learning_rate': 9.642707714909904e-05, 'epoch': 2.07}\n",
            "{'loss': 0.3936, 'learning_rate': 9.626474549335986e-05, 'epoch': 2.07}\n",
            "{'loss': 0.1029, 'learning_rate': 9.61024236937617e-05, 'epoch': 2.07}\n",
            "{'loss': 0.1892, 'learning_rate': 9.594011217861982e-05, 'epoch': 2.07}\n",
            "{'loss': 0.27, 'learning_rate': 9.577781137622238e-05, 'epoch': 2.08}\n",
            "{'loss': 0.0928, 'learning_rate': 9.561552171482925e-05, 'epoch': 2.08}\n",
            "{'loss': 0.3636, 'learning_rate': 9.545324362267086e-05, 'epoch': 2.08}\n",
            "{'loss': 0.2987, 'learning_rate': 9.52909775279472e-05, 'epoch': 2.08}\n",
            "{'loss': 0.2552, 'learning_rate': 9.51287238588265e-05, 'epoch': 2.08}\n",
            "{'loss': 0.2845, 'learning_rate': 9.496648304344433e-05, 'epoch': 2.09}\n",
            "{'loss': 0.5747, 'learning_rate': 9.480425550990219e-05, 'epoch': 2.09}\n",
            "{'loss': 0.5067, 'learning_rate': 9.464204168626665e-05, 'epoch': 2.09}\n",
            "{'loss': 0.3164, 'learning_rate': 9.447984200056808e-05, 'epoch': 2.09}\n",
            "{'loss': 0.2148, 'learning_rate': 9.43176568807995e-05, 'epoch': 2.09}\n",
            "{'loss': 0.1988, 'learning_rate': 9.415548675491559e-05, 'epoch': 2.1}\n",
            "{'loss': 0.2606, 'learning_rate': 9.399333205083131e-05, 'epoch': 2.1}\n",
            "{'loss': 0.192, 'learning_rate': 9.38311931964211e-05, 'epoch': 2.1}\n",
            "{'loss': 0.2762, 'learning_rate': 9.366907061951745e-05, 'epoch': 2.1}\n",
            "{'loss': 0.3543, 'learning_rate': 9.350696474790999e-05, 'epoch': 2.1}\n",
            "{'loss': 0.1544, 'learning_rate': 9.334487600934416e-05, 'epoch': 2.11}\n",
            "{'loss': 0.1729, 'learning_rate': 9.318280483152033e-05, 'epoch': 2.11}\n",
            "{'loss': 0.2194, 'learning_rate': 9.302075164209241e-05, 'epoch': 2.11}\n",
            "{'loss': 0.3009, 'learning_rate': 9.285871686866692e-05, 'epoch': 2.11}\n",
            "{'loss': 0.293, 'learning_rate': 9.269670093880177e-05, 'epoch': 2.12}\n",
            "{'loss': 0.3365, 'learning_rate': 9.25347042800051e-05, 'epoch': 2.12}\n",
            "{'loss': 0.1499, 'learning_rate': 9.237272731973428e-05, 'epoch': 2.12}\n",
            "{'loss': 0.2772, 'learning_rate': 9.221077048539464e-05, 'epoch': 2.12}\n",
            "{'loss': 0.179, 'learning_rate': 9.204883420433844e-05, 'epoch': 2.12}\n",
            "{'loss': 0.2827, 'learning_rate': 9.188691890386367e-05, 'epoch': 2.13}\n",
            "{'loss': 0.4003, 'learning_rate': 9.172502501121297e-05, 'epoch': 2.13}\n",
            "{'loss': 0.2853, 'learning_rate': 9.156315295357257e-05, 'epoch': 2.13}\n",
            "{'loss': 0.2791, 'learning_rate': 9.140130315807091e-05, 'epoch': 2.13}\n",
            "{'loss': 0.3107, 'learning_rate': 9.123947605177791e-05, 'epoch': 2.13}\n",
            "{'loss': 0.2696, 'learning_rate': 9.107767206170342e-05, 'epoch': 2.14}\n",
            "{'loss': 0.3902, 'learning_rate': 9.09158916147964e-05, 'epoch': 2.14}\n",
            "{'loss': 0.2675, 'learning_rate': 9.075413513794369e-05, 'epoch': 2.14}\n",
            "{'loss': 0.306, 'learning_rate': 9.059240305796884e-05, 'epoch': 2.14}\n",
            "{'loss': 0.1015, 'learning_rate': 9.043069580163099e-05, 'epoch': 2.14}\n",
            "{'loss': 0.2198, 'learning_rate': 9.02690137956239e-05, 'epoch': 2.15}\n",
            "{'loss': 0.2747, 'learning_rate': 9.010735746657462e-05, 'epoch': 2.15}\n",
            "{'loss': 0.1955, 'learning_rate': 8.994572724104242e-05, 'epoch': 2.15}\n",
            "{'loss': 0.2083, 'learning_rate': 8.978412354551779e-05, 'epoch': 2.15}\n",
            "{'loss': 0.1076, 'learning_rate': 8.962254680642107e-05, 'epoch': 2.15}\n",
            "{'loss': 0.2605, 'learning_rate': 8.946099745010164e-05, 'epoch': 2.16}\n",
            "{'loss': 0.0986, 'learning_rate': 8.929947590283647e-05, 'epoch': 2.16}\n",
            "{'loss': 0.1954, 'learning_rate': 8.913798259082928e-05, 'epoch': 2.16}\n",
            "{'loss': 0.1961, 'learning_rate': 8.897651794020918e-05, 'epoch': 2.16}\n",
            "{'loss': 0.2184, 'learning_rate': 8.881508237702973e-05, 'epoch': 2.16}\n",
            "{'loss': 0.26, 'learning_rate': 8.865367632726772e-05, 'epoch': 2.17}\n",
            "{'loss': 0.2942, 'learning_rate': 8.849230021682199e-05, 'epoch': 2.17}\n",
            "{'loss': 0.2907, 'learning_rate': 8.833095447151252e-05, 'epoch': 2.17}\n",
            "{'loss': 0.3617, 'learning_rate': 8.816963951707901e-05, 'epoch': 2.17}\n",
            "{'loss': 0.4201, 'learning_rate': 8.800835577918006e-05, 'epoch': 2.17}\n",
            "{'loss': 0.3107, 'learning_rate': 8.784710368339178e-05, 'epoch': 2.18}\n",
            "{'loss': 0.5247, 'learning_rate': 8.768588365520685e-05, 'epoch': 2.18}\n",
            "{'loss': 0.2976, 'learning_rate': 8.752469612003332e-05, 'epoch': 2.18}\n",
            "{'loss': 0.3169, 'learning_rate': 8.736354150319349e-05, 'epoch': 2.18}\n",
            "{'loss': 0.313, 'learning_rate': 8.720242022992284e-05, 'epoch': 2.18}\n",
            "{'loss': 0.2312, 'learning_rate': 8.704133272536879e-05, 'epoch': 2.19}\n",
            "{'loss': 0.2405, 'learning_rate': 8.68802794145898e-05, 'epoch': 2.19}\n",
            "{'loss': 0.2849, 'learning_rate': 8.671926072255389e-05, 'epoch': 2.19}\n",
            "{'loss': 0.4001, 'learning_rate': 8.655827707413788e-05, 'epoch': 2.19}\n",
            "{'loss': 0.0352, 'learning_rate': 8.63973288941261e-05, 'epoch': 2.2}\n",
            "{'loss': 0.1828, 'learning_rate': 8.623641660720928e-05, 'epoch': 2.2}\n",
            "{'loss': 0.122, 'learning_rate': 8.607554063798346e-05, 'epoch': 2.2}\n",
            "{'loss': 0.2149, 'learning_rate': 8.591470141094878e-05, 'epoch': 2.2}\n",
            "{'loss': 0.3302, 'learning_rate': 8.57538993505085e-05, 'epoch': 2.2}\n",
            "{'loss': 0.7865, 'learning_rate': 8.559313488096782e-05, 'epoch': 2.21}\n",
            "{'loss': 0.2607, 'learning_rate': 8.543240842653266e-05, 'epoch': 2.21}\n",
            "{'loss': 0.3671, 'learning_rate': 8.527172041130874e-05, 'epoch': 2.21}\n",
            "{'loss': 0.1455, 'learning_rate': 8.511107125930022e-05, 'epoch': 2.21}\n",
            "{'loss': 0.3937, 'learning_rate': 8.49504613944089e-05, 'epoch': 2.21}\n",
            "{'loss': 0.2221, 'learning_rate': 8.47898912404327e-05, 'epoch': 2.22}\n",
            "{'loss': 0.2813, 'learning_rate': 8.462936122106489e-05, 'epoch': 2.22}\n",
            "{'loss': 0.2628, 'learning_rate': 8.446887175989286e-05, 'epoch': 2.22}\n",
            "{'loss': 0.1648, 'learning_rate': 8.430842328039686e-05, 'epoch': 2.22}\n",
            "{'loss': 0.2963, 'learning_rate': 8.414801620594912e-05, 'epoch': 2.22}\n",
            "{'loss': 0.4901, 'learning_rate': 8.398765095981251e-05, 'epoch': 2.23}\n",
            "{'loss': 0.2986, 'learning_rate': 8.382732796513966e-05, 'epoch': 2.23}\n",
            "{'loss': 0.1675, 'learning_rate': 8.366704764497154e-05, 'epoch': 2.23}\n",
            "{'loss': 0.2565, 'learning_rate': 8.35068104222367e-05, 'epoch': 2.23}\n",
            "{'loss': 0.1369, 'learning_rate': 8.33466167197498e-05, 'epoch': 2.23}\n",
            "{'loss': 0.2155, 'learning_rate': 8.318646696021077e-05, 'epoch': 2.24}\n",
            "{'loss': 0.235, 'learning_rate': 8.302636156620363e-05, 'epoch': 2.24}\n",
            "{'loss': 0.1896, 'learning_rate': 8.286630096019518e-05, 'epoch': 2.24}\n",
            "{'loss': 0.1555, 'learning_rate': 8.270628556453417e-05, 'epoch': 2.24}\n",
            "{'loss': 0.2226, 'learning_rate': 8.254631580144999e-05, 'epoch': 2.24}\n",
            "{'loss': 0.3051, 'learning_rate': 8.238639209305166e-05, 'epoch': 2.25}\n",
            "{'loss': 0.2469, 'learning_rate': 8.222651486132664e-05, 'epoch': 2.25}\n",
            "{'loss': 0.2362, 'learning_rate': 8.206668452813978e-05, 'epoch': 2.25}\n",
            "{'loss': 0.2678, 'learning_rate': 8.190690151523215e-05, 'epoch': 2.25}\n",
            "{'loss': 0.1858, 'learning_rate': 8.174716624421997e-05, 'epoch': 2.25}\n",
            "{'loss': 0.224, 'learning_rate': 8.158747913659355e-05, 'epoch': 2.26}\n",
            "{'loss': 0.2346, 'learning_rate': 8.142784061371598e-05, 'epoch': 2.26}\n",
            "{'loss': 0.1157, 'learning_rate': 8.126825109682228e-05, 'epoch': 2.26}\n",
            "{'loss': 0.3164, 'learning_rate': 8.110871100701807e-05, 'epoch': 2.26}\n",
            "{'loss': 0.1689, 'learning_rate': 8.094922076527859e-05, 'epoch': 2.27}\n",
            "{'loss': 0.2822, 'learning_rate': 8.078978079244752e-05, 'epoch': 2.27}\n",
            "{'loss': 0.4148, 'learning_rate': 8.063039150923595e-05, 'epoch': 2.27}\n",
            "{'loss': 0.1655, 'learning_rate': 8.047105333622112e-05, 'epoch': 2.27}\n",
            "{'loss': 0.2874, 'learning_rate': 8.031176669384552e-05, 'epoch': 2.27}\n",
            "{'loss': 0.1371, 'learning_rate': 8.01525320024156e-05, 'epoch': 2.28}\n",
            "{'loss': 0.249, 'learning_rate': 7.999334968210073e-05, 'epoch': 2.28}\n",
            "{'loss': 0.2373, 'learning_rate': 7.983422015293212e-05, 'epoch': 2.28}\n",
            "{'loss': 0.1635, 'learning_rate': 7.967514383480161e-05, 'epoch': 2.28}\n",
            "{'loss': 0.4184, 'learning_rate': 7.951612114746076e-05, 'epoch': 2.28}\n",
            "{'loss': 0.2348, 'learning_rate': 7.935715251051949e-05, 'epoch': 2.29}\n",
            "{'loss': 0.2685, 'learning_rate': 7.919823834344516e-05, 'epoch': 2.29}\n",
            "{'loss': 0.278, 'learning_rate': 7.90393790655614e-05, 'epoch': 2.29}\n",
            "{'loss': 0.1674, 'learning_rate': 7.888057509604697e-05, 'epoch': 2.29}\n",
            "{'loss': 0.1645, 'learning_rate': 7.872182685393475e-05, 'epoch': 2.29}\n",
            "{'loss': 0.2906, 'learning_rate': 7.85631347581105e-05, 'epoch': 2.3}\n",
            "{'loss': 0.1142, 'learning_rate': 7.84044992273119e-05, 'epoch': 2.3}\n",
            "{'loss': 0.231, 'learning_rate': 7.82459206801273e-05, 'epoch': 2.3}\n",
            "{'loss': 0.2444, 'learning_rate': 7.808739953499478e-05, 'epoch': 2.3}\n",
            "{'loss': 0.208, 'learning_rate': 7.792893621020082e-05, 'epoch': 2.3}\n",
            "{'loss': 0.2187, 'learning_rate': 7.777053112387949e-05, 'epoch': 2.31}\n",
            "{'loss': 0.1642, 'learning_rate': 7.761218469401108e-05, 'epoch': 2.31}\n",
            "{'loss': 0.1606, 'learning_rate': 7.745389733842112e-05, 'epoch': 2.31}\n",
            "{'loss': 0.2163, 'learning_rate': 7.729566947477928e-05, 'epoch': 2.31}\n",
            "{'loss': 0.146, 'learning_rate': 7.713750152059826e-05, 'epoch': 2.31}\n",
            "{'loss': 0.3516, 'learning_rate': 7.697939389323267e-05, 'epoch': 2.32}\n",
            "{'loss': 0.2701, 'learning_rate': 7.682134700987789e-05, 'epoch': 2.32}\n",
            "{'loss': 0.0923, 'learning_rate': 7.66633612875691e-05, 'epoch': 2.32}\n",
            "{'loss': 0.1823, 'learning_rate': 7.650543714318001e-05, 'epoch': 2.32}\n",
            "{'loss': 0.1695, 'learning_rate': 7.634757499342191e-05, 'epoch': 2.32}\n",
            "{'loss': 0.2916, 'learning_rate': 7.61897752548425e-05, 'epoch': 2.33}\n",
            "{'loss': 0.2846, 'learning_rate': 7.603203834382476e-05, 'epoch': 2.33}\n",
            "{'loss': 0.3939, 'learning_rate': 7.58743646765859e-05, 'epoch': 2.33}\n",
            "{'loss': 0.1515, 'learning_rate': 7.571675466917626e-05, 'epoch': 2.33}\n",
            "{'loss': 0.2397, 'learning_rate': 7.555920873747823e-05, 'epoch': 2.34}\n",
            "{'loss': 0.181, 'learning_rate': 7.540172729720504e-05, 'epoch': 2.34}\n",
            "{'loss': 0.2755, 'learning_rate': 7.524431076389986e-05, 'epoch': 2.34}\n",
            "{'loss': 0.235, 'learning_rate': 7.50869595529345e-05, 'epoch': 2.34}\n",
            "{'loss': 0.2988, 'learning_rate': 7.492967407950844e-05, 'epoch': 2.34}\n",
            "{'loss': 0.3401, 'learning_rate': 7.477245475864771e-05, 'epoch': 2.35}\n",
            "{'loss': 0.3693, 'learning_rate': 7.461530200520377e-05, 'epoch': 2.35}\n",
            "{'loss': 0.2429, 'learning_rate': 7.445821623385245e-05, 'epoch': 2.35}\n",
            "{'loss': 0.0837, 'learning_rate': 7.430119785909278e-05, 'epoch': 2.35}\n",
            "{'loss': 0.2423, 'learning_rate': 7.414424729524602e-05, 'epoch': 2.35}\n",
            "{'loss': 0.373, 'learning_rate': 7.398736495645447e-05, 'epoch': 2.36}\n",
            "{'loss': 0.2801, 'learning_rate': 7.383055125668038e-05, 'epoch': 2.36}\n",
            "{'loss': 0.1476, 'learning_rate': 7.367380660970493e-05, 'epoch': 2.36}\n",
            "{'loss': 0.1311, 'learning_rate': 7.351713142912707e-05, 'epoch': 2.36}\n",
            "{'loss': 0.3449, 'learning_rate': 7.336052612836246e-05, 'epoch': 2.36}\n",
            "{'loss': 0.1528, 'learning_rate': 7.320399112064233e-05, 'epoch': 2.37}\n",
            "{'loss': 0.2244, 'learning_rate': 7.304752681901251e-05, 'epoch': 2.37}\n",
            "{'loss': 0.2018, 'learning_rate': 7.289113363633215e-05, 'epoch': 2.37}\n",
            "{'loss': 0.1806, 'learning_rate': 7.273481198527285e-05, 'epoch': 2.37}\n",
            "{'loss': 0.3684, 'learning_rate': 7.257856227831738e-05, 'epoch': 2.37}\n",
            "{'loss': 0.2414, 'learning_rate': 7.242238492775869e-05, 'epoch': 2.38}\n",
            "{'loss': 0.4505, 'learning_rate': 7.226628034569886e-05, 'epoch': 2.38}\n",
            "{'loss': 0.1549, 'learning_rate': 7.211024894404788e-05, 'epoch': 2.38}\n",
            "{'loss': 0.2211, 'learning_rate': 7.195429113452271e-05, 'epoch': 2.38}\n",
            "{'loss': 0.1408, 'learning_rate': 7.179840732864604e-05, 'epoch': 2.38}\n",
            "{'loss': 0.2532, 'learning_rate': 7.16425979377454e-05, 'epoch': 2.39}\n",
            "{'loss': 0.2771, 'learning_rate': 7.148686337295181e-05, 'epoch': 2.39}\n",
            "{'loss': 0.4098, 'learning_rate': 7.133120404519903e-05, 'epoch': 2.39}\n",
            "{'loss': 0.4, 'learning_rate': 7.117562036522213e-05, 'epoch': 2.39}\n",
            "{'loss': 0.2817, 'learning_rate': 7.102011274355667e-05, 'epoch': 2.39}\n",
            "{'loss': 0.5997, 'learning_rate': 7.086468159053751e-05, 'epoch': 2.4}\n",
            "{'loss': 0.1762, 'learning_rate': 7.070932731629769e-05, 'epoch': 2.4}\n",
            "{'loss': 0.202, 'learning_rate': 7.05540503307674e-05, 'epoch': 2.4}\n",
            "{'loss': 0.3448, 'learning_rate': 7.03988510436729e-05, 'epoch': 2.4}\n",
            "{'loss': 0.165, 'learning_rate': 7.024372986453547e-05, 'epoch': 2.4}\n",
            "{'loss': 0.4215, 'learning_rate': 7.008868720267021e-05, 'epoch': 2.41}\n",
            "{'loss': 0.1848, 'learning_rate': 6.99337234671851e-05, 'epoch': 2.41}\n",
            "{'loss': 0.3503, 'learning_rate': 6.977883906697979e-05, 'epoch': 2.41}\n",
            "{'loss': 0.1299, 'learning_rate': 6.96240344107447e-05, 'epoch': 2.41}\n",
            "{'loss': 0.2269, 'learning_rate': 6.946930990695974e-05, 'epoch': 2.42}\n",
            "{'loss': 0.3681, 'learning_rate': 6.93146659638933e-05, 'epoch': 2.42}\n",
            "{'loss': 0.2066, 'learning_rate': 6.916010298960137e-05, 'epoch': 2.42}\n",
            "{'loss': 0.3065, 'learning_rate': 6.900562139192603e-05, 'epoch': 2.42}\n",
            "{'loss': 0.2344, 'learning_rate': 6.885122157849485e-05, 'epoch': 2.42}\n",
            "{'loss': 0.4605, 'learning_rate': 6.869690395671946e-05, 'epoch': 2.43}\n",
            "{'loss': 0.314, 'learning_rate': 6.85426689337947e-05, 'epoch': 2.43}\n",
            "{'loss': 0.3754, 'learning_rate': 6.838851691669746e-05, 'epoch': 2.43}\n",
            "{'loss': 0.4406, 'learning_rate': 6.823444831218551e-05, 'epoch': 2.43}\n",
            "{'loss': 0.2292, 'learning_rate': 6.808046352679663e-05, 'epoch': 2.43}\n",
            "{'loss': 0.3078, 'learning_rate': 6.792656296684732e-05, 'epoch': 2.44}\n",
            "{'loss': 0.2797, 'learning_rate': 6.777274703843197e-05, 'epoch': 2.44}\n",
            "{'loss': 0.473, 'learning_rate': 6.761901614742151e-05, 'epoch': 2.44}\n",
            "{'loss': 0.182, 'learning_rate': 6.746537069946261e-05, 'epoch': 2.44}\n",
            "{'loss': 0.3658, 'learning_rate': 6.731181109997639e-05, 'epoch': 2.44}\n",
            "{'loss': 0.1628, 'learning_rate': 6.715833775415747e-05, 'epoch': 2.45}\n",
            "{'loss': 0.2731, 'learning_rate': 6.700495106697295e-05, 'epoch': 2.45}\n",
            "{'loss': 0.2982, 'learning_rate': 6.685165144316112e-05, 'epoch': 2.45}\n",
            "{'loss': 0.2886, 'learning_rate': 6.66984392872307e-05, 'epoch': 2.45}\n",
            "{'loss': 0.2938, 'learning_rate': 6.654531500345943e-05, 'epoch': 2.45}\n",
            "{'loss': 0.2653, 'learning_rate': 6.639227899589336e-05, 'epoch': 2.46}\n",
            "{'loss': 0.3003, 'learning_rate': 6.623933166834548e-05, 'epoch': 2.46}\n",
            "{'loss': 0.4138, 'learning_rate': 6.608647342439489e-05, 'epoch': 2.46}\n",
            "{'loss': 0.2448, 'learning_rate': 6.59337046673855e-05, 'epoch': 2.46}\n",
            "{'loss': 0.234, 'learning_rate': 6.578102580042518e-05, 'epoch': 2.46}\n",
            "{'loss': 0.2068, 'learning_rate': 6.562843722638463e-05, 'epoch': 2.47}\n",
            "{'loss': 0.2348, 'learning_rate': 6.547593934789619e-05, 'epoch': 2.47}\n",
            "{'loss': 0.1706, 'learning_rate': 6.532353256735301e-05, 'epoch': 2.47}\n",
            "{'loss': 0.2011, 'learning_rate': 6.517121728690774e-05, 'epoch': 2.47}\n",
            "{'loss': 0.2011, 'learning_rate': 6.50189939084717e-05, 'epoch': 2.47}\n",
            "{'loss': 0.2997, 'learning_rate': 6.486686283371364e-05, 'epoch': 2.48}\n",
            "{'loss': 0.2047, 'learning_rate': 6.471482446405878e-05, 'epoch': 2.48}\n",
            "{'loss': 0.3808, 'learning_rate': 6.456287920068767e-05, 'epoch': 2.48}\n",
            "{'loss': 0.3143, 'learning_rate': 6.441102744453528e-05, 'epoch': 2.48}\n",
            "{'loss': 0.2425, 'learning_rate': 6.425926959628977e-05, 'epoch': 2.49}\n",
            "{'loss': 0.2143, 'learning_rate': 6.41076060563915e-05, 'epoch': 2.49}\n",
            "{'loss': 0.21, 'learning_rate': 6.395603722503205e-05, 'epoch': 2.49}\n",
            "{'loss': 0.1642, 'learning_rate': 6.380456350215301e-05, 'epoch': 2.49}\n",
            "{'loss': 0.1945, 'learning_rate': 6.365318528744508e-05, 'epoch': 2.49}\n",
            "{'loss': 0.2409, 'learning_rate': 6.350190298034688e-05, 'epoch': 2.5}\n",
            "{'loss': 0.2872, 'learning_rate': 6.335071698004403e-05, 'epoch': 2.5}\n",
            "{'loss': 0.3899, 'learning_rate': 6.319962768546798e-05, 'epoch': 2.5}\n",
            "{'loss': 0.116, 'learning_rate': 6.304863549529499e-05, 'epoch': 2.5}\n",
            "{'loss': 0.2313, 'learning_rate': 6.289774080794516e-05, 'epoch': 2.5}\n",
            "{'loss': 0.2065, 'learning_rate': 6.274694402158123e-05, 'epoch': 2.51}\n",
            "{'loss': 0.3275, 'learning_rate': 6.25962455341077e-05, 'epoch': 2.51}\n",
            "{'loss': 0.2322, 'learning_rate': 6.244564574316958e-05, 'epoch': 2.51}\n",
            "{'loss': 0.2541, 'learning_rate': 6.229514504615158e-05, 'epoch': 2.51}\n",
            " 62% 1215/1944 [1:33:47<55:41,  4.58s/it][2024-01-21 13:30:06,903] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 13:30:07,334] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 13:30:07,335] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 0/973 [00:00<?, ?it/s]\u001b[A[2024-01-21 13:30:08,029] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 2/973 [00:00<05:36,  2.88it/s]\u001b[A[2024-01-21 13:30:08,708] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 3/973 [00:01<07:50,  2.06it/s]\u001b[A[2024-01-21 13:30:09,401] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 4/973 [00:02<09:05,  1.78it/s]\u001b[A[2024-01-21 13:30:10,089] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 5/973 [00:02<09:46,  1.65it/s]\u001b[A[2024-01-21 13:30:10,764] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 6/973 [00:03<10:08,  1.59it/s]\u001b[A[2024-01-21 13:30:11,449] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 7/973 [00:04<10:24,  1.55it/s]\u001b[A[2024-01-21 13:30:12,137] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 8/973 [00:04<10:36,  1.52it/s]\u001b[A[2024-01-21 13:30:12,822] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 9/973 [00:05<10:43,  1.50it/s]\u001b[A[2024-01-21 13:30:13,512] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 10/973 [00:06<10:49,  1.48it/s]\u001b[A[2024-01-21 13:30:14,192] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 11/973 [00:06<10:50,  1.48it/s]\u001b[A[2024-01-21 13:30:14,874] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 12/973 [00:07<10:51,  1.47it/s]\u001b[A[2024-01-21 13:30:15,559] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 13/973 [00:08<10:52,  1.47it/s]\u001b[A[2024-01-21 13:30:16,243] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 14/973 [00:08<10:53,  1.47it/s]\u001b[A[2024-01-21 13:30:16,927] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 15/973 [00:09<10:53,  1.47it/s]\u001b[A[2024-01-21 13:30:17,614] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 16/973 [00:10<10:54,  1.46it/s]\u001b[A[2024-01-21 13:30:18,298] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 17/973 [00:10<10:53,  1.46it/s]\u001b[A[2024-01-21 13:30:18,983] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 18/973 [00:11<10:53,  1.46it/s]\u001b[A[2024-01-21 13:30:19,672] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 19/973 [00:12<10:53,  1.46it/s]\u001b[A[2024-01-21 13:30:20,361] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.5593509078025818, 'eval_runtime': 13.7211, 'eval_samples_per_second': 1.458, 'eval_steps_per_second': 1.458, 'epoch': 2.51}\n",
            " 62% 1215/1944 [1:34:01<55:41,  4.58s/it]\n",
            "  2% 20/973 [00:13<10:54,  1.46it/s]\u001b[A\n",
            "{'loss': 0.4203, 'learning_rate': 6.214474384017678e-05, 'epoch': 2.51}\n",
            "{'loss': 0.2869, 'learning_rate': 6.19944425221059e-05, 'epoch': 2.52}\n",
            "{'loss': 0.2723, 'learning_rate': 6.184424148853598e-05, 'epoch': 2.52}\n",
            "{'loss': 0.6488, 'learning_rate': 6.16941411357995e-05, 'epoch': 2.52}\n",
            "{'loss': 0.1417, 'learning_rate': 6.154414185996318e-05, 'epoch': 2.52}\n",
            "{'loss': 0.1698, 'learning_rate': 6.139424405682715e-05, 'epoch': 2.52}\n",
            "{'loss': 0.1907, 'learning_rate': 6.124444812192367e-05, 'epoch': 2.53}\n",
            "{'loss': 0.26, 'learning_rate': 6.109475445051634e-05, 'epoch': 2.53}\n",
            "{'loss': 0.2677, 'learning_rate': 6.094516343759878e-05, 'epoch': 2.53}\n",
            "{'loss': 0.2701, 'learning_rate': 6.0795675477893844e-05, 'epoch': 2.53}\n",
            "{'loss': 0.3379, 'learning_rate': 6.064629096585237e-05, 'epoch': 2.53}\n",
            "{'loss': 0.2417, 'learning_rate': 6.049701029565227e-05, 'epoch': 2.54}\n",
            "{'loss': 0.1911, 'learning_rate': 6.034783386119749e-05, 'epoch': 2.54}\n",
            "{'loss': 0.2647, 'learning_rate': 6.0198762056116834e-05, 'epoch': 2.54}\n",
            "{'loss': 0.2013, 'learning_rate': 6.0049795273763124e-05, 'epoch': 2.54}\n",
            "{'loss': 0.2506, 'learning_rate': 5.990093390721197e-05, 'epoch': 2.54}\n",
            "{'loss': 0.2887, 'learning_rate': 5.975217834926094e-05, 'epoch': 2.55}\n",
            "{'loss': 0.3601, 'learning_rate': 5.960352899242825e-05, 'epoch': 2.55}\n",
            "{'loss': 0.4009, 'learning_rate': 5.9454986228952044e-05, 'epoch': 2.55}\n",
            "{'loss': 0.2638, 'learning_rate': 5.930655045078908e-05, 'epoch': 2.55}\n",
            "{'loss': 0.3681, 'learning_rate': 5.915822204961389e-05, 'epoch': 2.55}\n",
            "{'loss': 0.1858, 'learning_rate': 5.901000141681765e-05, 'epoch': 2.56}\n",
            "{'loss': 0.2026, 'learning_rate': 5.886188894350713e-05, 'epoch': 2.56}\n",
            "{'loss': 0.349, 'learning_rate': 5.871388502050379e-05, 'epoch': 2.56}\n",
            "{'loss': 0.2006, 'learning_rate': 5.856599003834255e-05, 'epoch': 2.56}\n",
            "{'loss': 0.1112, 'learning_rate': 5.841820438727099e-05, 'epoch': 2.57}\n",
            "{'loss': 0.3226, 'learning_rate': 5.827052845724808e-05, 'epoch': 2.57}\n",
            "{'loss': 0.2401, 'learning_rate': 5.812296263794335e-05, 'epoch': 2.57}\n",
            "{'loss': 0.2113, 'learning_rate': 5.797550731873578e-05, 'epoch': 2.57}\n",
            "{'loss': 0.3528, 'learning_rate': 5.7828162888712775e-05, 'epoch': 2.57}\n",
            "{'loss': 0.3828, 'learning_rate': 5.7680929736669065e-05, 'epoch': 2.58}\n",
            "{'loss': 0.3604, 'learning_rate': 5.7533808251105834e-05, 'epoch': 2.58}\n",
            "{'loss': 0.5849, 'learning_rate': 5.738679882022959e-05, 'epoch': 2.58}\n",
            "{'loss': 0.159, 'learning_rate': 5.7239901831951224e-05, 'epoch': 2.58}\n",
            "{'loss': 0.193, 'learning_rate': 5.7093117673884766e-05, 'epoch': 2.58}\n",
            "{'loss': 0.1588, 'learning_rate': 5.694644673334667e-05, 'epoch': 2.59}\n",
            "{'loss': 0.2537, 'learning_rate': 5.679988939735461e-05, 'epoch': 2.59}\n",
            "{'loss': 0.2794, 'learning_rate': 5.665344605262648e-05, 'epoch': 2.59}\n",
            "{'loss': 0.165, 'learning_rate': 5.650711708557941e-05, 'epoch': 2.59}\n",
            "{'loss': 0.1466, 'learning_rate': 5.636090288232867e-05, 'epoch': 2.59}\n",
            "{'loss': 0.2379, 'learning_rate': 5.621480382868673e-05, 'epoch': 2.6}\n",
            "{'loss': 0.1968, 'learning_rate': 5.606882031016227e-05, 'epoch': 2.6}\n",
            "{'loss': 0.4882, 'learning_rate': 5.5922952711959085e-05, 'epoch': 2.6}\n",
            "{'loss': 0.4237, 'learning_rate': 5.5777201418975e-05, 'epoch': 2.6}\n",
            "{'loss': 0.5708, 'learning_rate': 5.563156681580106e-05, 'epoch': 2.6}\n",
            "{'loss': 0.3026, 'learning_rate': 5.548604928672038e-05, 'epoch': 2.61}\n",
            "{'loss': 0.2354, 'learning_rate': 5.534064921570712e-05, 'epoch': 2.61}\n",
            "{'loss': 0.2332, 'learning_rate': 5.519536698642558e-05, 'epoch': 2.61}\n",
            "{'loss': 0.3081, 'learning_rate': 5.505020298222898e-05, 'epoch': 2.61}\n",
            "{'loss': 0.2175, 'learning_rate': 5.4905157586158705e-05, 'epoch': 2.61}\n",
            "{'loss': 0.2303, 'learning_rate': 5.476023118094311e-05, 'epoch': 2.62}\n",
            "{'loss': 0.2488, 'learning_rate': 5.461542414899665e-05, 'epoch': 2.62}\n",
            "{'loss': 0.1801, 'learning_rate': 5.4470736872418625e-05, 'epoch': 2.62}\n",
            "{'loss': 0.2259, 'learning_rate': 5.4326169732992514e-05, 'epoch': 2.62}\n",
            "{'loss': 0.2156, 'learning_rate': 5.41817231121847e-05, 'epoch': 2.62}\n",
            "{'loss': 0.1544, 'learning_rate': 5.4037397391143597e-05, 'epoch': 2.63}\n",
            "{'loss': 0.303, 'learning_rate': 5.389319295069861e-05, 'epoch': 2.63}\n",
            "{'loss': 0.4501, 'learning_rate': 5.374911017135904e-05, 'epoch': 2.63}\n",
            "{'loss': 0.28, 'learning_rate': 5.360514943331323e-05, 'epoch': 2.63}\n",
            "{'loss': 0.1691, 'learning_rate': 5.346131111642752e-05, 'epoch': 2.64}\n",
            "{'loss': 0.1343, 'learning_rate': 5.331759560024521e-05, 'epoch': 2.64}\n",
            "{'loss': 0.3562, 'learning_rate': 5.317400326398546e-05, 'epoch': 2.64}\n",
            "{'loss': 0.1287, 'learning_rate': 5.3030534486542535e-05, 'epoch': 2.64}\n",
            "{'loss': 0.2441, 'learning_rate': 5.288718964648462e-05, 'epoch': 2.64}\n",
            "{'loss': 0.2659, 'learning_rate': 5.274396912205284e-05, 'epoch': 2.65}\n",
            "{'loss': 0.0835, 'learning_rate': 5.260087329116039e-05, 'epoch': 2.65}\n",
            "{'loss': 0.2731, 'learning_rate': 5.2457902531391246e-05, 'epoch': 2.65}\n",
            "{'loss': 0.1106, 'learning_rate': 5.2315057219999555e-05, 'epoch': 2.65}\n",
            "{'loss': 0.2489, 'learning_rate': 5.217233773390835e-05, 'epoch': 2.65}\n",
            "{'loss': 0.1801, 'learning_rate': 5.2029744449708706e-05, 'epoch': 2.66}\n",
            "{'loss': 0.1796, 'learning_rate': 5.1887277743658604e-05, 'epoch': 2.66}\n",
            "{'loss': 0.1252, 'learning_rate': 5.1744937991682086e-05, 'epoch': 2.66}\n",
            "{'loss': 0.2314, 'learning_rate': 5.160272556936822e-05, 'epoch': 2.66}\n",
            "{'loss': 0.2001, 'learning_rate': 5.1460640851970054e-05, 'epoch': 2.66}\n",
            "{'loss': 0.1768, 'learning_rate': 5.131868421440372e-05, 'epoch': 2.67}\n",
            "{'loss': 0.3151, 'learning_rate': 5.117685603124728e-05, 'epoch': 2.67}\n",
            "{'loss': 0.1971, 'learning_rate': 5.103515667673992e-05, 'epoch': 2.67}\n",
            "{'loss': 0.1767, 'learning_rate': 5.089358652478092e-05, 'epoch': 2.67}\n",
            "{'loss': 0.424, 'learning_rate': 5.0752145948928566e-05, 'epoch': 2.67}\n",
            "{'loss': 0.2753, 'learning_rate': 5.0610835322399316e-05, 'epoch': 2.68}\n",
            "{'loss': 0.3281, 'learning_rate': 5.0469655018066595e-05, 'epoch': 2.68}\n",
            "{'loss': 0.1829, 'learning_rate': 5.0328605408460095e-05, 'epoch': 2.68}\n",
            "{'loss': 0.2787, 'learning_rate': 5.018768686576455e-05, 'epoch': 2.68}\n",
            "{'loss': 0.5064, 'learning_rate': 5.0046899761818953e-05, 'epoch': 2.68}\n",
            "{'loss': 0.2722, 'learning_rate': 4.990624446811533e-05, 'epoch': 2.69}\n",
            "{'loss': 0.1858, 'learning_rate': 4.9765721355798e-05, 'epoch': 2.69}\n",
            "{'loss': 0.273, 'learning_rate': 4.9625330795662496e-05, 'epoch': 2.69}\n",
            "{'loss': 0.3106, 'learning_rate': 4.948507315815456e-05, 'epoch': 2.69}\n",
            "{'loss': 0.122, 'learning_rate': 4.934494881336924e-05, 'epoch': 2.69}\n",
            "{'loss': 0.1559, 'learning_rate': 4.920495813104975e-05, 'epoch': 2.7}\n",
            "{'loss': 0.3023, 'learning_rate': 4.906510148058673e-05, 'epoch': 2.7}\n",
            "{'loss': 0.2189, 'learning_rate': 4.892537923101712e-05, 'epoch': 2.7}\n",
            "{'loss': 0.2493, 'learning_rate': 4.878579175102324e-05, 'epoch': 2.7}\n",
            "{'loss': 0.2191, 'learning_rate': 4.864633940893171e-05, 'epoch': 2.71}\n",
            "{'loss': 0.2765, 'learning_rate': 4.850702257271265e-05, 'epoch': 2.71}\n",
            "{'loss': 0.2484, 'learning_rate': 4.836784160997858e-05, 'epoch': 2.71}\n",
            "{'loss': 0.3011, 'learning_rate': 4.822879688798354e-05, 'epoch': 2.71}\n",
            "{'loss': 0.2304, 'learning_rate': 4.8089888773622075e-05, 'epoch': 2.71}\n",
            "{'loss': 0.2442, 'learning_rate': 4.7951117633428154e-05, 'epoch': 2.72}\n",
            "{'loss': 0.3047, 'learning_rate': 4.781248383357443e-05, 'epoch': 2.72}\n",
            "{'loss': 0.1125, 'learning_rate': 4.767398773987114e-05, 'epoch': 2.72}\n",
            "{'loss': 0.1739, 'learning_rate': 4.753562971776516e-05, 'epoch': 2.72}\n",
            "{'loss': 0.3205, 'learning_rate': 4.739741013233897e-05, 'epoch': 2.72}\n",
            "{'loss': 0.247, 'learning_rate': 4.7259329348309844e-05, 'epoch': 2.73}\n",
            "{'loss': 0.3015, 'learning_rate': 4.7121387730028766e-05, 'epoch': 2.73}\n",
            "{'loss': 0.2247, 'learning_rate': 4.698358564147951e-05, 'epoch': 2.73}\n",
            "{'loss': 0.2014, 'learning_rate': 4.684592344627773e-05, 'epoch': 2.73}\n",
            "{'loss': 0.1351, 'learning_rate': 4.670840150766982e-05, 'epoch': 2.73}\n",
            "{'loss': 0.1729, 'learning_rate': 4.657102018853218e-05, 'epoch': 2.74}\n",
            "{'loss': 0.2669, 'learning_rate': 4.643377985137013e-05, 'epoch': 2.74}\n",
            "{'loss': 0.5008, 'learning_rate': 4.629668085831705e-05, 'epoch': 2.74}\n",
            "{'loss': 0.3658, 'learning_rate': 4.615972357113323e-05, 'epoch': 2.74}\n",
            "{'loss': 0.1838, 'learning_rate': 4.602290835120512e-05, 'epoch': 2.74}\n",
            "{'loss': 0.1691, 'learning_rate': 4.588623555954431e-05, 'epoch': 2.75}\n",
            "{'loss': 0.242, 'learning_rate': 4.574970555678654e-05, 'epoch': 2.75}\n",
            "{'loss': 0.2811, 'learning_rate': 4.561331870319083e-05, 'epoch': 2.75}\n",
            "{'loss': 0.366, 'learning_rate': 4.547707535863837e-05, 'epoch': 2.75}\n",
            "{'loss': 0.5451, 'learning_rate': 4.534097588263174e-05, 'epoch': 2.75}\n",
            "{'loss': 0.2613, 'learning_rate': 4.5205020634293914e-05, 'epoch': 2.76}\n",
            "{'loss': 0.3347, 'learning_rate': 4.506920997236731e-05, 'epoch': 2.76}\n",
            "{'loss': 0.2176, 'learning_rate': 4.493354425521272e-05, 'epoch': 2.76}\n",
            "{'loss': 0.1052, 'learning_rate': 4.479802384080858e-05, 'epoch': 2.76}\n",
            "{'loss': 0.11, 'learning_rate': 4.4662649086749885e-05, 'epoch': 2.76}\n",
            "{'loss': 0.1969, 'learning_rate': 4.452742035024728e-05, 'epoch': 2.77}\n",
            "{'loss': 0.1476, 'learning_rate': 4.439233798812615e-05, 'epoch': 2.77}\n",
            "{'loss': 0.2112, 'learning_rate': 4.425740235682554e-05, 'epoch': 2.77}\n",
            "{'loss': 0.245, 'learning_rate': 4.4122613812397417e-05, 'epoch': 2.77}\n",
            "{'loss': 0.2669, 'learning_rate': 4.398797271050562e-05, 'epoch': 2.77}\n",
            "{'loss': 0.2676, 'learning_rate': 4.385347940642495e-05, 'epoch': 2.78}\n",
            "{'loss': 0.2224, 'learning_rate': 4.3719134255040095e-05, 'epoch': 2.78}\n",
            "{'loss': 0.4559, 'learning_rate': 4.358493761084498e-05, 'epoch': 2.78}\n",
            "{'loss': 0.0861, 'learning_rate': 4.3450889827941554e-05, 'epoch': 2.78}\n",
            "{'loss': 0.2643, 'learning_rate': 4.331699126003904e-05, 'epoch': 2.79}\n",
            "{'loss': 0.1294, 'learning_rate': 4.3183242260452926e-05, 'epoch': 2.79}\n",
            "{'loss': 0.5038, 'learning_rate': 4.3049643182103925e-05, 'epoch': 2.79}\n",
            "{'loss': 0.2621, 'learning_rate': 4.2916194377517304e-05, 'epoch': 2.79}\n",
            "{'loss': 0.2644, 'learning_rate': 4.278289619882171e-05, 'epoch': 2.79}\n",
            "{'loss': 0.1928, 'learning_rate': 4.264974899774843e-05, 'epoch': 2.8}\n",
            "{'loss': 0.4062, 'learning_rate': 4.251675312563022e-05, 'epoch': 2.8}\n",
            "{'loss': 0.2642, 'learning_rate': 4.238390893340066e-05, 'epoch': 2.8}\n",
            "{'loss': 0.4878, 'learning_rate': 4.225121677159306e-05, 'epoch': 2.8}\n",
            "{'loss': 0.3775, 'learning_rate': 4.2118676990339546e-05, 'epoch': 2.8}\n",
            "{'loss': 0.5628, 'learning_rate': 4.1986289939370216e-05, 'epoch': 2.81}\n",
            "{'loss': 0.3035, 'learning_rate': 4.1854055968012054e-05, 'epoch': 2.81}\n",
            "{'loss': 0.2792, 'learning_rate': 4.172197542518821e-05, 'epoch': 2.81}\n",
            "{'loss': 0.1592, 'learning_rate': 4.159004865941697e-05, 'epoch': 2.81}\n",
            "{'loss': 0.2103, 'learning_rate': 4.145827601881084e-05, 'epoch': 2.81}\n",
            "{'loss': 0.3409, 'learning_rate': 4.132665785107567e-05, 'epoch': 2.82}\n",
            "{'loss': 0.3455, 'learning_rate': 4.1195194503509606e-05, 'epoch': 2.82}\n",
            "{'loss': 0.2639, 'learning_rate': 4.106388632300237e-05, 'epoch': 2.82}\n",
            "{'loss': 0.3902, 'learning_rate': 4.0932733656034226e-05, 'epoch': 2.82}\n",
            "{'loss': 0.3468, 'learning_rate': 4.080173684867512e-05, 'epoch': 2.82}\n",
            "{'loss': 0.2733, 'learning_rate': 4.067089624658362e-05, 'epoch': 2.83}\n",
            "{'loss': 0.2492, 'learning_rate': 4.0540212195006244e-05, 'epoch': 2.83}\n",
            "{'loss': 0.2635, 'learning_rate': 4.040968503877635e-05, 'epoch': 2.83}\n",
            "{'loss': 0.4603, 'learning_rate': 4.027931512231333e-05, 'epoch': 2.83}\n",
            "{'loss': 0.6332, 'learning_rate': 4.014910278962171e-05, 'epoch': 2.83}\n",
            "{'loss': 0.4171, 'learning_rate': 4.001904838429007e-05, 'epoch': 2.84}\n",
            "{'loss': 0.1595, 'learning_rate': 3.988915224949042e-05, 'epoch': 2.84}\n",
            "{'loss': 0.2081, 'learning_rate': 3.975941472797703e-05, 'epoch': 2.84}\n",
            "{'loss': 0.2491, 'learning_rate': 3.9629836162085775e-05, 'epoch': 2.84}\n",
            "{'loss': 0.345, 'learning_rate': 3.9500416893732926e-05, 'epoch': 2.84}\n",
            "{'loss': 0.3887, 'learning_rate': 3.937115726441454e-05, 'epoch': 2.85}\n",
            "{'loss': 0.1129, 'learning_rate': 3.9242057615205394e-05, 'epoch': 2.85}\n",
            "{'loss': 0.2486, 'learning_rate': 3.91131182867582e-05, 'epoch': 2.85}\n",
            "{'loss': 0.2634, 'learning_rate': 3.898433961930248e-05, 'epoch': 2.85}\n",
            "{'loss': 0.4873, 'learning_rate': 3.8855721952643995e-05, 'epoch': 2.86}\n",
            "{'loss': 0.2138, 'learning_rate': 3.872726562616353e-05, 'epoch': 2.86}\n",
            "{'loss': 0.1825, 'learning_rate': 3.859897097881625e-05, 'epoch': 2.86}\n",
            "{'loss': 0.1855, 'learning_rate': 3.847083834913066e-05, 'epoch': 2.86}\n",
            "{'loss': 0.261, 'learning_rate': 3.834286807520777e-05, 'epoch': 2.86}\n",
            "{'loss': 0.2017, 'learning_rate': 3.821506049472015e-05, 'epoch': 2.87}\n",
            "{'loss': 0.2713, 'learning_rate': 3.808741594491108e-05, 'epoch': 2.87}\n",
            "{'loss': 0.2351, 'learning_rate': 3.7959934762593685e-05, 'epoch': 2.87}\n",
            "{'loss': 0.3582, 'learning_rate': 3.783261728415002e-05, 'epoch': 2.87}\n",
            "{'loss': 0.2641, 'learning_rate': 3.770546384553017e-05, 'epoch': 2.87}\n",
            "{'loss': 0.2135, 'learning_rate': 3.757847478225129e-05, 'epoch': 2.88}\n",
            "{'loss': 0.1302, 'learning_rate': 3.7451650429396924e-05, 'epoch': 2.88}\n",
            "{'loss': 0.2135, 'learning_rate': 3.7324991121615914e-05, 'epoch': 2.88}\n",
            "{'loss': 0.1887, 'learning_rate': 3.7198497193121694e-05, 'epoch': 2.88}\n",
            "{'loss': 0.1919, 'learning_rate': 3.707216897769117e-05, 'epoch': 2.88}\n",
            "{'loss': 0.4604, 'learning_rate': 3.6946006808664094e-05, 'epoch': 2.89}\n",
            "{'loss': 0.2249, 'learning_rate': 3.6820011018942055e-05, 'epoch': 2.89}\n",
            "{'loss': 0.1165, 'learning_rate': 3.669418194098762e-05, 'epoch': 2.89}\n",
            "{'loss': 0.3721, 'learning_rate': 3.6568519906823464e-05, 'epoch': 2.89}\n",
            "{'loss': 0.1972, 'learning_rate': 3.644302524803142e-05, 'epoch': 2.89}\n",
            "{'loss': 0.2515, 'learning_rate': 3.6317698295751746e-05, 'epoch': 2.9}\n",
            "{'loss': 0.2355, 'learning_rate': 3.6192539380682156e-05, 'epoch': 2.9}\n",
            "{'loss': 0.4616, 'learning_rate': 3.6067548833077e-05, 'epoch': 2.9}\n",
            "{'loss': 0.2013, 'learning_rate': 3.5942726982746255e-05, 'epoch': 2.9}\n",
            "{'loss': 0.1117, 'learning_rate': 3.581807415905487e-05, 'epoch': 2.9}\n",
            "{'loss': 0.242, 'learning_rate': 3.569359069092175e-05, 'epoch': 2.91}\n",
            "{'loss': 0.0965, 'learning_rate': 3.5569276906818904e-05, 'epoch': 2.91}\n",
            "{'loss': 0.1767, 'learning_rate': 3.544513313477066e-05, 'epoch': 2.91}\n",
            "{'loss': 0.1067, 'learning_rate': 3.5321159702352636e-05, 'epoch': 2.91}\n",
            "{'loss': 0.2419, 'learning_rate': 3.519735693669105e-05, 'epoch': 2.91}\n",
            "{'loss': 0.1391, 'learning_rate': 3.507372516446179e-05, 'epoch': 2.92}\n",
            "{'loss': 0.2171, 'learning_rate': 3.495026471188957e-05, 'epoch': 2.92}\n",
            "{'loss': 0.2706, 'learning_rate': 3.4826975904746915e-05, 'epoch': 2.92}\n",
            "{'loss': 0.1229, 'learning_rate': 3.470385906835357e-05, 'epoch': 2.92}\n",
            "{'loss': 0.2549, 'learning_rate': 3.458091452757546e-05, 'epoch': 2.92}\n",
            "{'loss': 0.1919, 'learning_rate': 3.445814260682386e-05, 'epoch': 2.93}\n",
            "{'loss': 0.1954, 'learning_rate': 3.433554363005464e-05, 'epoch': 2.93}\n",
            "{'loss': 0.1512, 'learning_rate': 3.421311792076714e-05, 'epoch': 2.93}\n",
            "{'loss': 0.2025, 'learning_rate': 3.409086580200369e-05, 'epoch': 2.93}\n",
            "{'loss': 0.4288, 'learning_rate': 3.396878759634848e-05, 'epoch': 2.94}\n",
            "{'loss': 0.2732, 'learning_rate': 3.384688362592687e-05, 'epoch': 2.94}\n",
            "{'loss': 0.3721, 'learning_rate': 3.372515421240434e-05, 'epoch': 2.94}\n",
            "{'loss': 0.2727, 'learning_rate': 3.360359967698589e-05, 'epoch': 2.94}\n",
            "{'loss': 0.2048, 'learning_rate': 3.3482220340415004e-05, 'epoch': 2.94}\n",
            "{'loss': 0.3823, 'learning_rate': 3.336101652297293e-05, 'epoch': 2.95}\n",
            "{'loss': 0.1922, 'learning_rate': 3.323998854447776e-05, 'epoch': 2.95}\n",
            "{'loss': 0.2042, 'learning_rate': 3.311913672428354e-05, 'epoch': 2.95}\n",
            "{'loss': 0.2934, 'learning_rate': 3.2998461381279554e-05, 'epoch': 2.95}\n",
            "{'loss': 0.3016, 'learning_rate': 3.287796283388942e-05, 'epoch': 2.95}\n",
            "{'loss': 0.1774, 'learning_rate': 3.2757641400070214e-05, 'epoch': 2.96}\n",
            "{'loss': 0.1643, 'learning_rate': 3.2637497397311747e-05, 'epoch': 2.96}\n",
            "{'loss': 0.2235, 'learning_rate': 3.25175311426355e-05, 'epoch': 2.96}\n",
            "{'loss': 0.397, 'learning_rate': 3.239774295259407e-05, 'epoch': 2.96}\n",
            "{'loss': 0.2498, 'learning_rate': 3.2278133143270116e-05, 'epoch': 2.96}\n",
            "{'loss': 0.2736, 'learning_rate': 3.21587020302757e-05, 'epoch': 2.97}\n",
            "{'loss': 0.1969, 'learning_rate': 3.203944992875123e-05, 'epoch': 2.97}\n",
            "{'loss': 0.1645, 'learning_rate': 3.1920377153364847e-05, 'epoch': 2.97}\n",
            "{'loss': 0.3354, 'learning_rate': 3.180148401831151e-05, 'epoch': 2.97}\n",
            "{'loss': 0.3297, 'learning_rate': 3.168277083731214e-05, 'epoch': 2.97}\n",
            "{'loss': 0.1167, 'learning_rate': 3.156423792361285e-05, 'epoch': 2.98}\n",
            "{'loss': 0.3505, 'learning_rate': 3.144588558998399e-05, 'epoch': 2.98}\n",
            "{'loss': 0.3037, 'learning_rate': 3.132771414871953e-05, 'epoch': 2.98}\n",
            "{'loss': 0.1772, 'learning_rate': 3.120972391163608e-05, 'epoch': 2.98}\n",
            "{'loss': 0.19, 'learning_rate': 3.109191519007213e-05, 'epoch': 2.98}\n",
            "{'loss': 0.1229, 'learning_rate': 3.097428829488712e-05, 'epoch': 2.99}\n",
            "{'loss': 0.2283, 'learning_rate': 3.085684353646081e-05, 'epoch': 2.99}\n",
            "{'loss': 0.2312, 'learning_rate': 3.0739581224692336e-05, 'epoch': 2.99}\n",
            "{'loss': 0.2629, 'learning_rate': 3.0622501668999385e-05, 'epoch': 2.99}\n",
            " 75% 1449/1944 [1:51:51<37:49,  4.58s/it][2024-01-21 13:48:10,801] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "{'loss': 0.0846, 'learning_rate': 3.0505605178317476e-05, 'epoch': 3.0}\n",
            "{'loss': 0.3048, 'learning_rate': 3.038889206109895e-05, 'epoch': 3.0}\n",
            "{'loss': 0.2821, 'learning_rate': 3.027236262531242e-05, 'epoch': 3.01}\n",
            "{'loss': 0.1409, 'learning_rate': 3.0156017178441755e-05, 'epoch': 3.01}\n",
            "{'loss': 0.2041, 'learning_rate': 3.003985602748537e-05, 'epoch': 3.01}\n",
            "{'loss': 0.1111, 'learning_rate': 2.9923879478955308e-05, 'epoch': 3.01}\n",
            "{'loss': 0.138, 'learning_rate': 2.9808087838876587e-05, 'epoch': 3.01}\n",
            "{'loss': 0.3151, 'learning_rate': 2.969248141278629e-05, 'epoch': 3.02}\n",
            "{'loss': 0.1567, 'learning_rate': 2.9577060505732746e-05, 'epoch': 3.02}\n",
            " 75% 1458/1944 [1:52:32<37:11,  4.59s/it][2024-01-21 13:48:52,073] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 13:48:52,489] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 13:48:52,490] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 0/973 [00:00<?, ?it/s]\u001b[A[2024-01-21 13:48:53,192] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 2/973 [00:00<05:40,  2.85it/s]\u001b[A[2024-01-21 13:48:53,864] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 3/973 [00:01<07:50,  2.06it/s]\u001b[A[2024-01-21 13:48:54,555] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 4/973 [00:02<09:04,  1.78it/s]\u001b[A[2024-01-21 13:48:55,240] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 5/973 [00:02<09:45,  1.65it/s]\u001b[A[2024-01-21 13:48:55,922] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 6/973 [00:03<10:09,  1.59it/s]\u001b[A[2024-01-21 13:48:56,612] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 7/973 [00:04<10:27,  1.54it/s]\u001b[A[2024-01-21 13:48:57,302] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 8/973 [00:04<10:39,  1.51it/s]\u001b[A[2024-01-21 13:48:57,989] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 9/973 [00:05<10:45,  1.49it/s]\u001b[A[2024-01-21 13:48:58,679] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 10/973 [00:06<10:51,  1.48it/s]\u001b[A[2024-01-21 13:48:59,364] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 11/973 [00:06<10:53,  1.47it/s]\u001b[A[2024-01-21 13:49:00,046] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 12/973 [00:07<10:53,  1.47it/s]\u001b[A[2024-01-21 13:49:00,725] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 13/973 [00:08<10:52,  1.47it/s]\u001b[A[2024-01-21 13:49:01,409] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 14/973 [00:08<10:53,  1.47it/s]\u001b[A[2024-01-21 13:49:02,098] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 15/973 [00:09<10:54,  1.46it/s]\u001b[A[2024-01-21 13:49:02,788] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 16/973 [00:10<10:55,  1.46it/s]\u001b[A[2024-01-21 13:49:03,481] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 17/973 [00:10<10:57,  1.45it/s]\u001b[A[2024-01-21 13:49:04,165] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 18/973 [00:11<10:55,  1.46it/s]\u001b[A[2024-01-21 13:49:04,847] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 19/973 [00:12<10:53,  1.46it/s]\u001b[A[2024-01-21 13:49:05,523] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.5646761059761047, 'eval_runtime': 13.7137, 'eval_samples_per_second': 1.458, 'eval_steps_per_second': 1.458, 'epoch': 3.02}\n",
            " 75% 1458/1944 [1:52:46<37:11,  4.59s/it]\n",
            "  2% 20/973 [00:13<10:50,  1.46it/s]\u001b[A\n",
            "{'loss': 0.157, 'learning_rate': 2.9461825422274847e-05, 'epoch': 3.02}\n",
            "{'loss': 0.1896, 'learning_rate': 2.9346776466481006e-05, 'epoch': 3.02}\n",
            "{'loss': 0.2582, 'learning_rate': 2.9231913941928636e-05, 'epoch': 3.02}\n",
            "{'loss': 0.0803, 'learning_rate': 2.9117238151703164e-05, 'epoch': 3.03}\n",
            "{'loss': 0.2114, 'learning_rate': 2.9002749398397322e-05, 'epoch': 3.03}\n",
            "{'loss': 0.1306, 'learning_rate': 2.8888447984110235e-05, 'epoch': 3.03}\n",
            "{'loss': 0.179, 'learning_rate': 2.8774334210446775e-05, 'epoch': 3.03}\n",
            "{'loss': 0.3315, 'learning_rate': 2.8660408378516655e-05, 'epoch': 3.03}\n",
            "{'loss': 0.1599, 'learning_rate': 2.8546670788933684e-05, 'epoch': 3.04}\n",
            "{'loss': 0.2503, 'learning_rate': 2.8433121741814994e-05, 'epoch': 3.04}\n",
            "{'loss': 0.1257, 'learning_rate': 2.83197615367801e-05, 'epoch': 3.04}\n",
            "{'loss': 0.2828, 'learning_rate': 2.8206590472950334e-05, 'epoch': 3.04}\n",
            "{'loss': 0.0496, 'learning_rate': 2.8093608848947906e-05, 'epoch': 3.05}\n",
            "{'loss': 0.5512, 'learning_rate': 2.7980816962895195e-05, 'epoch': 3.05}\n",
            "{'loss': 0.1778, 'learning_rate': 2.7868215112413808e-05, 'epoch': 3.05}\n",
            "{'loss': 0.2088, 'learning_rate': 2.7755803594624042e-05, 'epoch': 3.05}\n",
            "{'loss': 0.1758, 'learning_rate': 2.764358270614388e-05, 'epoch': 3.05}\n",
            "{'loss': 0.3789, 'learning_rate': 2.753155274308835e-05, 'epoch': 3.06}\n",
            "{'loss': 0.2798, 'learning_rate': 2.7419714001068687e-05, 'epoch': 3.06}\n",
            "{'loss': 0.2097, 'learning_rate': 2.7308066775191466e-05, 'epoch': 3.06}\n",
            "{'loss': 0.346, 'learning_rate': 2.7196611360058012e-05, 'epoch': 3.06}\n",
            "{'loss': 0.2354, 'learning_rate': 2.708534804976349e-05, 'epoch': 3.06}\n",
            "{'loss': 0.1384, 'learning_rate': 2.697427713789621e-05, 'epoch': 3.07}\n",
            "{'loss': 0.2177, 'learning_rate': 2.6863398917536665e-05, 'epoch': 3.07}\n",
            "{'loss': 0.2302, 'learning_rate': 2.6752713681257037e-05, 'epoch': 3.07}\n",
            "{'loss': 0.1835, 'learning_rate': 2.664222172112022e-05, 'epoch': 3.07}\n",
            "{'loss': 0.0993, 'learning_rate': 2.6531923328679143e-05, 'epoch': 3.07}\n",
            "{'loss': 0.1745, 'learning_rate': 2.6421818794975994e-05, 'epoch': 3.08}\n",
            "{'loss': 0.211, 'learning_rate': 2.6311908410541308e-05, 'epoch': 3.08}\n",
            "{'loss': 0.2341, 'learning_rate': 2.620219246539347e-05, 'epoch': 3.08}\n",
            "{'loss': 0.1417, 'learning_rate': 2.6092671249037714e-05, 'epoch': 3.08}\n",
            "{'loss': 0.3102, 'learning_rate': 2.5983345050465514e-05, 'epoch': 3.08}\n",
            "{'loss': 0.0763, 'learning_rate': 2.5874214158153664e-05, 'epoch': 3.09}\n",
            "{'loss': 0.1518, 'learning_rate': 2.576527886006367e-05, 'epoch': 3.09}\n",
            "{'loss': 0.4692, 'learning_rate': 2.5656539443640913e-05, 'epoch': 3.09}\n",
            "{'loss': 0.163, 'learning_rate': 2.5547996195813928e-05, 'epoch': 3.09}\n",
            "{'loss': 0.1617, 'learning_rate': 2.5439649402993614e-05, 'epoch': 3.09}\n",
            "{'loss': 0.1686, 'learning_rate': 2.533149935107242e-05, 'epoch': 3.1}\n",
            "{'loss': 0.2013, 'learning_rate': 2.5223546325423742e-05, 'epoch': 3.1}\n",
            "{'loss': 0.34, 'learning_rate': 2.511579061090107e-05, 'epoch': 3.1}\n",
            "{'loss': 0.4469, 'learning_rate': 2.5008232491837236e-05, 'epoch': 3.1}\n",
            "{'loss': 0.2808, 'learning_rate': 2.4900872252043728e-05, 'epoch': 3.1}\n",
            "{'loss': 0.1628, 'learning_rate': 2.479371017480977e-05, 'epoch': 3.11}\n",
            "{'loss': 0.4163, 'learning_rate': 2.468674654290184e-05, 'epoch': 3.11}\n",
            "{'loss': 0.0701, 'learning_rate': 2.457998163856271e-05, 'epoch': 3.11}\n",
            "{'loss': 0.3602, 'learning_rate': 2.447341574351081e-05, 'epoch': 3.11}\n",
            "{'loss': 0.1898, 'learning_rate': 2.436704913893938e-05, 'epoch': 3.12}\n",
            "{'loss': 0.202, 'learning_rate': 2.426088210551588e-05, 'epoch': 3.12}\n",
            "{'loss': 0.0297, 'learning_rate': 2.41549149233811e-05, 'epoch': 3.12}\n",
            "{'loss': 0.2161, 'learning_rate': 2.4049147872148547e-05, 'epoch': 3.12}\n",
            "{'loss': 0.2214, 'learning_rate': 2.394358123090362e-05, 'epoch': 3.12}\n",
            "{'loss': 0.2825, 'learning_rate': 2.3838215278202848e-05, 'epoch': 3.13}\n",
            "{'loss': 0.1293, 'learning_rate': 2.373305029207328e-05, 'epoch': 3.13}\n",
            "{'loss': 0.2854, 'learning_rate': 2.3628086550011642e-05, 'epoch': 3.13}\n",
            "{'loss': 0.1815, 'learning_rate': 2.3523324328983688e-05, 'epoch': 3.13}\n",
            "{'loss': 0.2673, 'learning_rate': 2.3418763905423335e-05, 'epoch': 3.13}\n",
            "{'loss': 0.1854, 'learning_rate': 2.3314405555232098e-05, 'epoch': 3.14}\n",
            "{'loss': 0.2164, 'learning_rate': 2.3210249553778253e-05, 'epoch': 3.14}\n",
            "{'loss': 0.2254, 'learning_rate': 2.3106296175896148e-05, 'epoch': 3.14}\n",
            "{'loss': 0.1494, 'learning_rate': 2.3002545695885503e-05, 'epoch': 3.14}\n",
            "{'loss': 0.3191, 'learning_rate': 2.2898998387510573e-05, 'epoch': 3.14}\n",
            "{'loss': 0.259, 'learning_rate': 2.279565452399959e-05, 'epoch': 3.15}\n",
            "{'loss': 0.2223, 'learning_rate': 2.2692514378043918e-05, 'epoch': 3.15}\n",
            "{'loss': 0.2967, 'learning_rate': 2.2589578221797425e-05, 'epoch': 3.15}\n",
            "{'loss': 0.1695, 'learning_rate': 2.248684632687562e-05, 'epoch': 3.15}\n",
            "{'loss': 0.0719, 'learning_rate': 2.2384318964355123e-05, 'epoch': 3.15}\n",
            "{'loss': 0.203, 'learning_rate': 2.228199640477283e-05, 'epoch': 3.16}\n",
            "{'loss': 0.1594, 'learning_rate': 2.217987891812521e-05, 'epoch': 3.16}\n",
            "{'loss': 0.1549, 'learning_rate': 2.2077966773867642e-05, 'epoch': 3.16}\n",
            "{'loss': 0.1134, 'learning_rate': 2.1976260240913628e-05, 'epoch': 3.16}\n",
            "{'loss': 0.0962, 'learning_rate': 2.1874759587634163e-05, 'epoch': 3.16}\n",
            "{'loss': 0.2092, 'learning_rate': 2.177346508185698e-05, 'epoch': 3.17}\n",
            "{'loss': 0.1333, 'learning_rate': 2.1672376990865895e-05, 'epoch': 3.17}\n",
            "{'loss': 0.1987, 'learning_rate': 2.1571495581399957e-05, 'epoch': 3.17}\n",
            "{'loss': 0.2108, 'learning_rate': 2.147082111965294e-05, 'epoch': 3.17}\n",
            "{'loss': 0.2816, 'learning_rate': 2.137035387127253e-05, 'epoch': 3.17}\n",
            "{'loss': 0.2252, 'learning_rate': 2.127009410135965e-05, 'epoch': 3.18}\n",
            "{'loss': 0.2516, 'learning_rate': 2.1170042074467746e-05, 'epoch': 3.18}\n",
            "{'loss': 0.0938, 'learning_rate': 2.107019805460203e-05, 'epoch': 3.18}\n",
            "{'loss': 0.1662, 'learning_rate': 2.0970562305218966e-05, 'epoch': 3.18}\n",
            "{'loss': 0.2514, 'learning_rate': 2.087113508922539e-05, 'epoch': 3.18}\n",
            "{'loss': 0.1485, 'learning_rate': 2.0771916668977932e-05, 'epoch': 3.19}\n",
            "{'loss': 0.203, 'learning_rate': 2.0672907306282186e-05, 'epoch': 3.19}\n",
            "{'loss': 0.323, 'learning_rate': 2.0574107262392216e-05, 'epoch': 3.19}\n",
            "{'loss': 0.285, 'learning_rate': 2.0475516798009663e-05, 'epoch': 3.19}\n",
            "{'loss': 0.2075, 'learning_rate': 2.037713617328323e-05, 'epoch': 3.2}\n",
            "{'loss': 0.1183, 'learning_rate': 2.0278965647807912e-05, 'epoch': 3.2}\n",
            "{'loss': 0.1032, 'learning_rate': 2.0181005480624305e-05, 'epoch': 3.2}\n",
            "{'loss': 0.2589, 'learning_rate': 2.0083255930217893e-05, 'epoch': 3.2}\n",
            "{'loss': 0.2974, 'learning_rate': 1.9985717254518477e-05, 'epoch': 3.2}\n",
            "{'loss': 0.0902, 'learning_rate': 1.988838971089939e-05, 'epoch': 3.21}\n",
            "{'loss': 0.3306, 'learning_rate': 1.9791273556176915e-05, 'epoch': 3.21}\n",
            "{'loss': 0.0909, 'learning_rate': 1.969436904660943e-05, 'epoch': 3.21}\n",
            "{'loss': 0.267, 'learning_rate': 1.959767643789694e-05, 'epoch': 3.21}\n",
            "{'loss': 0.141, 'learning_rate': 1.95011959851803e-05, 'epoch': 3.21}\n",
            "{'loss': 0.1945, 'learning_rate': 1.940492794304053e-05, 'epoch': 3.22}\n",
            "{'loss': 0.2045, 'learning_rate': 1.9308872565498214e-05, 'epoch': 3.22}\n",
            "{'loss': 0.2139, 'learning_rate': 1.9213030106012698e-05, 'epoch': 3.22}\n",
            "{'loss': 0.1827, 'learning_rate': 1.9117400817481568e-05, 'epoch': 3.22}\n",
            "{'loss': 0.1869, 'learning_rate': 1.9021984952239923e-05, 'epoch': 3.22}\n",
            "{'loss': 0.1611, 'learning_rate': 1.8926782762059704e-05, 'epoch': 3.23}\n",
            "{'loss': 0.1929, 'learning_rate': 1.883179449814896e-05, 'epoch': 3.23}\n",
            "{'loss': 0.46, 'learning_rate': 1.8737020411151353e-05, 'epoch': 3.23}\n",
            "{'loss': 0.1679, 'learning_rate': 1.8642460751145362e-05, 'epoch': 3.23}\n",
            "{'loss': 0.178, 'learning_rate': 1.854811576764366e-05, 'epoch': 3.23}\n",
            "{'loss': 0.1044, 'learning_rate': 1.845398570959247e-05, 'epoch': 3.24}\n",
            "{'loss': 0.2278, 'learning_rate': 1.8360070825370857e-05, 'epoch': 3.24}\n",
            "{'loss': 0.2453, 'learning_rate': 1.8266371362790146e-05, 'epoch': 3.24}\n",
            "{'loss': 0.2196, 'learning_rate': 1.8172887569093246e-05, 'epoch': 3.24}\n",
            "{'loss': 0.2493, 'learning_rate': 1.807961969095394e-05, 'epoch': 3.24}\n",
            "{'loss': 0.1739, 'learning_rate': 1.7986567974476353e-05, 'epoch': 3.25}\n",
            "{'loss': 0.1108, 'learning_rate': 1.789373266519413e-05, 'epoch': 3.25}\n",
            "{'loss': 0.1466, 'learning_rate': 1.780111400806993e-05, 'epoch': 3.25}\n",
            "{'loss': 0.1049, 'learning_rate': 1.7708712247494785e-05, 'epoch': 3.25}\n",
            "{'loss': 0.1686, 'learning_rate': 1.761652762728735e-05, 'epoch': 3.25}\n",
            "{'loss': 0.2391, 'learning_rate': 1.7524560390693312e-05, 'epoch': 3.26}\n",
            "{'loss': 0.2344, 'learning_rate': 1.7432810780384777e-05, 'epoch': 3.26}\n",
            "{'loss': 0.0993, 'learning_rate': 1.73412790384596e-05, 'epoch': 3.26}\n",
            "{'loss': 0.0723, 'learning_rate': 1.724996540644076e-05, 'epoch': 3.26}\n",
            "{'loss': 0.1606, 'learning_rate': 1.7158870125275726e-05, 'epoch': 3.27}\n",
            "{'loss': 0.1867, 'learning_rate': 1.7067993435335728e-05, 'epoch': 3.27}\n",
            "{'loss': 0.2279, 'learning_rate': 1.697733557641529e-05, 'epoch': 3.27}\n",
            "{'loss': 0.1378, 'learning_rate': 1.6886896787731478e-05, 'epoch': 3.27}\n",
            "{'loss': 0.2196, 'learning_rate': 1.6796677307923346e-05, 'epoch': 3.27}\n",
            "{'loss': 0.2368, 'learning_rate': 1.670667737505116e-05, 'epoch': 3.28}\n",
            "{'loss': 0.1002, 'learning_rate': 1.6616897226595962e-05, 'epoch': 3.28}\n",
            "{'loss': 0.1258, 'learning_rate': 1.6527337099458827e-05, 'epoch': 3.28}\n",
            "{'loss': 0.2127, 'learning_rate': 1.6437997229960266e-05, 'epoch': 3.28}\n",
            "{'loss': 0.1188, 'learning_rate': 1.634887785383963e-05, 'epoch': 3.28}\n",
            "{'loss': 0.4286, 'learning_rate': 1.6259979206254362e-05, 'epoch': 3.29}\n",
            "{'loss': 0.1879, 'learning_rate': 1.6171301521779558e-05, 'epoch': 3.29}\n",
            "{'loss': 0.2102, 'learning_rate': 1.6082845034407255e-05, 'epoch': 3.29}\n",
            "{'loss': 0.3169, 'learning_rate': 1.599460997754584e-05, 'epoch': 3.29}\n",
            "{'loss': 0.084, 'learning_rate': 1.5906596584019317e-05, 'epoch': 3.29}\n",
            "{'loss': 0.1368, 'learning_rate': 1.58188050860669e-05, 'epoch': 3.3}\n",
            "{'loss': 0.1764, 'learning_rate': 1.573123571534224e-05, 'epoch': 3.3}\n",
            "{'loss': 0.1849, 'learning_rate': 1.564388870291289e-05, 'epoch': 3.3}\n",
            "{'loss': 0.185, 'learning_rate': 1.5556764279259663e-05, 'epoch': 3.3}\n",
            "{'loss': 0.3031, 'learning_rate': 1.5469862674275982e-05, 'epoch': 3.3}\n",
            "{'loss': 0.1541, 'learning_rate': 1.538318411726739e-05, 'epoch': 3.31}\n",
            "{'loss': 0.2184, 'learning_rate': 1.529672883695087e-05, 'epoch': 3.31}\n",
            "{'loss': 0.0876, 'learning_rate': 1.5210497061454232e-05, 'epoch': 3.31}\n",
            "{'loss': 0.1885, 'learning_rate': 1.5124489018315502e-05, 'epoch': 3.31}\n",
            "{'loss': 0.1395, 'learning_rate': 1.5038704934482395e-05, 'epoch': 3.31}\n",
            "{'loss': 0.1459, 'learning_rate': 1.4953145036311644e-05, 'epoch': 3.32}\n",
            "{'loss': 0.2636, 'learning_rate': 1.4867809549568434e-05, 'epoch': 3.32}\n",
            "{'loss': 0.3739, 'learning_rate': 1.4782698699425823e-05, 'epoch': 3.32}\n",
            "{'loss': 0.2429, 'learning_rate': 1.4697812710464054e-05, 'epoch': 3.32}\n",
            "{'loss': 0.229, 'learning_rate': 1.4613151806670111e-05, 'epoch': 3.32}\n",
            "{'loss': 0.1639, 'learning_rate': 1.452871621143701e-05, 'epoch': 3.33}\n",
            "{'loss': 0.5408, 'learning_rate': 1.4444506147563285e-05, 'epoch': 3.33}\n",
            "{'loss': 0.2382, 'learning_rate': 1.4360521837252305e-05, 'epoch': 3.33}\n",
            "{'loss': 0.223, 'learning_rate': 1.4276763502111789e-05, 'epoch': 3.33}\n",
            "{'loss': 0.1468, 'learning_rate': 1.4193231363153192e-05, 'epoch': 3.34}\n",
            "{'loss': 0.1558, 'learning_rate': 1.4109925640791077e-05, 'epoch': 3.34}\n",
            "{'loss': 0.2189, 'learning_rate': 1.4026846554842598e-05, 'epoch': 3.34}\n",
            "{'loss': 0.0691, 'learning_rate': 1.3943994324526832e-05, 'epoch': 3.34}\n",
            "{'loss': 0.0686, 'learning_rate': 1.3861369168464322e-05, 'epoch': 3.34}\n",
            "{'loss': 0.2012, 'learning_rate': 1.3778971304676403e-05, 'epoch': 3.35}\n",
            "{'loss': 0.3382, 'learning_rate': 1.3696800950584688e-05, 'epoch': 3.35}\n",
            "{'loss': 0.1111, 'learning_rate': 1.3614858323010382e-05, 'epoch': 3.35}\n",
            "{'loss': 0.1419, 'learning_rate': 1.3533143638173884e-05, 'epoch': 3.35}\n",
            "{'loss': 0.6363, 'learning_rate': 1.3451657111694094e-05, 'epoch': 3.35}\n",
            "{'loss': 0.1657, 'learning_rate': 1.337039895858786e-05, 'epoch': 3.36}\n",
            "{'loss': 0.1844, 'learning_rate': 1.328936939326948e-05, 'epoch': 3.36}\n",
            "{'loss': 0.2081, 'learning_rate': 1.3208568629549967e-05, 'epoch': 3.36}\n",
            "{'loss': 0.1985, 'learning_rate': 1.3127996880636717e-05, 'epoch': 3.36}\n",
            "{'loss': 0.2211, 'learning_rate': 1.3047654359132787e-05, 'epoch': 3.36}\n",
            "{'loss': 0.2124, 'learning_rate': 1.2967541277036387e-05, 'epoch': 3.37}\n",
            "{'loss': 0.3616, 'learning_rate': 1.2887657845740252e-05, 'epoch': 3.37}\n",
            "{'loss': 0.2825, 'learning_rate': 1.2808004276031205e-05, 'epoch': 3.37}\n",
            "{'loss': 0.3695, 'learning_rate': 1.2728580778089538e-05, 'epoch': 3.37}\n",
            "{'loss': 0.2497, 'learning_rate': 1.2649387561488424e-05, 'epoch': 3.37}\n",
            "{'loss': 0.2382, 'learning_rate': 1.2570424835193439e-05, 'epoch': 3.38}\n",
            "{'loss': 0.3906, 'learning_rate': 1.2491692807561906e-05, 'epoch': 3.38}\n",
            "{'loss': 0.3666, 'learning_rate': 1.2413191686342451e-05, 'epoch': 3.38}\n",
            "{'loss': 0.2345, 'learning_rate': 1.2334921678674416e-05, 'epoch': 3.38}\n",
            "{'loss': 0.195, 'learning_rate': 1.2256882991087294e-05, 'epoch': 3.38}\n",
            "{'loss': 0.3215, 'learning_rate': 1.2179075829500231e-05, 'epoch': 3.39}\n",
            "{'loss': 0.262, 'learning_rate': 1.2101500399221366e-05, 'epoch': 3.39}\n",
            "{'loss': 0.341, 'learning_rate': 1.2024156904947458e-05, 'epoch': 3.39}\n",
            "{'loss': 0.1665, 'learning_rate': 1.1947045550763236e-05, 'epoch': 3.39}\n",
            "{'loss': 0.1494, 'learning_rate': 1.1870166540140882e-05, 'epoch': 3.39}\n",
            "{'loss': 0.1779, 'learning_rate': 1.179352007593948e-05, 'epoch': 3.4}\n",
            "{'loss': 0.2872, 'learning_rate': 1.1717106360404518e-05, 'epoch': 3.4}\n",
            "{'loss': 0.1565, 'learning_rate': 1.164092559516734e-05, 'epoch': 3.4}\n",
            "{'loss': 0.1945, 'learning_rate': 1.1564977981244595e-05, 'epoch': 3.4}\n",
            "{'loss': 0.2593, 'learning_rate': 1.1489263719037757e-05, 'epoch': 3.4}\n",
            "{'loss': 0.0939, 'learning_rate': 1.1413783008332479e-05, 'epoch': 3.41}\n",
            "{'loss': 0.19, 'learning_rate': 1.133853604829822e-05, 'epoch': 3.41}\n",
            "{'loss': 0.2232, 'learning_rate': 1.1263523037487623e-05, 'epoch': 3.41}\n",
            "{'loss': 0.1296, 'learning_rate': 1.1188744173836018e-05, 'epoch': 3.41}\n",
            "{'loss': 0.1271, 'learning_rate': 1.1114199654660872e-05, 'epoch': 3.42}\n",
            "{'loss': 0.2309, 'learning_rate': 1.1039889676661319e-05, 'epoch': 3.42}\n",
            "{'loss': 0.1884, 'learning_rate': 1.096581443591761e-05, 'epoch': 3.42}\n",
            "{'loss': 0.1279, 'learning_rate': 1.0891974127890581e-05, 'epoch': 3.42}\n",
            "{'loss': 0.0897, 'learning_rate': 1.0818368947421209e-05, 'epoch': 3.42}\n",
            "{'loss': 0.1611, 'learning_rate': 1.0744999088729946e-05, 'epoch': 3.43}\n",
            "{'loss': 0.0552, 'learning_rate': 1.0671864745416394e-05, 'epoch': 3.43}\n",
            "{'loss': 0.2617, 'learning_rate': 1.0598966110458675e-05, 'epoch': 3.43}\n",
            "{'loss': 0.0496, 'learning_rate': 1.0526303376212976e-05, 'epoch': 3.43}\n",
            "{'loss': 0.2989, 'learning_rate': 1.0453876734412949e-05, 'epoch': 3.43}\n",
            "{'loss': 0.0969, 'learning_rate': 1.0381686376169342e-05, 'epoch': 3.44}\n",
            "{'loss': 0.1726, 'learning_rate': 1.0309732491969392e-05, 'epoch': 3.44}\n",
            "{'loss': 0.1681, 'learning_rate': 1.0238015271676382e-05, 'epoch': 3.44}\n",
            "{'loss': 0.1282, 'learning_rate': 1.0166534904529113e-05, 'epoch': 3.44}\n",
            "{'loss': 0.0698, 'learning_rate': 1.0095291579141353e-05, 'epoch': 3.44}\n",
            "{'loss': 0.202, 'learning_rate': 1.002428548350145e-05, 'epoch': 3.45}\n",
            "{'loss': 0.1108, 'learning_rate': 9.953516804971774e-06, 'epoch': 3.45}\n",
            "{'loss': 0.1459, 'learning_rate': 9.88298573028823e-06, 'epoch': 3.45}\n",
            "{'loss': 0.0819, 'learning_rate': 9.812692445559701e-06, 'epoch': 3.45}\n",
            "{'loss': 0.1497, 'learning_rate': 9.742637136267696e-06, 'epoch': 3.45}\n",
            "{'loss': 0.4019, 'learning_rate': 9.672819987265747e-06, 'epoch': 3.46}\n",
            "{'loss': 0.1715, 'learning_rate': 9.603241182778955e-06, 'epoch': 3.46}\n",
            "{'loss': 0.1359, 'learning_rate': 9.533900906403549e-06, 'epoch': 3.46}\n",
            "{'loss': 0.2189, 'learning_rate': 9.464799341106267e-06, 'epoch': 3.46}\n",
            "{'loss': 0.1526, 'learning_rate': 9.39593666922406e-06, 'epoch': 3.46}\n",
            "{'loss': 0.2354, 'learning_rate': 9.327313072463462e-06, 'epoch': 3.47}\n",
            "{'loss': 0.1503, 'learning_rate': 9.258928731900196e-06, 'epoch': 3.47}\n",
            "{'loss': 0.1336, 'learning_rate': 9.190783827978621e-06, 'epoch': 3.47}\n",
            "{'loss': 0.1549, 'learning_rate': 9.122878540511338e-06, 'epoch': 3.47}\n",
            "{'loss': 0.2536, 'learning_rate': 9.055213048678656e-06, 'epoch': 3.47}\n",
            "{'loss': 0.1944, 'learning_rate': 8.987787531028168e-06, 'epoch': 3.48}\n",
            "{'loss': 0.1876, 'learning_rate': 8.920602165474245e-06, 'epoch': 3.48}\n",
            "{'loss': 0.1701, 'learning_rate': 8.853657129297521e-06, 'epoch': 3.48}\n",
            "{'loss': 0.0742, 'learning_rate': 8.786952599144526e-06, 'epoch': 3.48}\n",
            "{'loss': 0.3497, 'learning_rate': 8.72048875102719e-06, 'epoch': 3.49}\n",
            "{'loss': 0.1783, 'learning_rate': 8.654265760322322e-06, 'epoch': 3.49}\n",
            "{'loss': 0.2089, 'learning_rate': 8.58828380177118e-06, 'epoch': 3.49}\n",
            "{'loss': 0.1371, 'learning_rate': 8.522543049479048e-06, 'epoch': 3.49}\n",
            "{'loss': 0.2197, 'learning_rate': 8.457043676914723e-06, 'epoch': 3.49}\n",
            "{'loss': 0.1039, 'learning_rate': 8.391785856910096e-06, 'epoch': 3.5}\n",
            "{'loss': 0.0617, 'learning_rate': 8.326769761659658e-06, 'epoch': 3.5}\n",
            "{'loss': 0.259, 'learning_rate': 8.26199556272007e-06, 'epoch': 3.5}\n",
            "{'loss': 0.1922, 'learning_rate': 8.1974634310097e-06, 'epoch': 3.5}\n",
            "{'loss': 0.3463, 'learning_rate': 8.133173536808202e-06, 'epoch': 3.5}\n",
            "{'loss': 0.2075, 'learning_rate': 8.069126049756037e-06, 'epoch': 3.51}\n",
            "{'loss': 0.1146, 'learning_rate': 8.005321138853994e-06, 'epoch': 3.51}\n",
            "{'loss': 0.1506, 'learning_rate': 7.941758972462832e-06, 'epoch': 3.51}\n",
            "{'loss': 0.0796, 'learning_rate': 7.878439718302754e-06, 'epoch': 3.51}\n",
            "{'loss': 0.1877, 'learning_rate': 7.815363543453002e-06, 'epoch': 3.51}\n",
            "{'loss': 0.2327, 'learning_rate': 7.752530614351427e-06, 'epoch': 3.52}\n",
            "{'loss': 0.1801, 'learning_rate': 7.689941096793995e-06, 'epoch': 3.52}\n",
            " 88% 1701/1944 [2:11:23<18:32,  4.58s/it][2024-01-21 14:07:42,874] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 14:07:43,292] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "[2024-01-21 14:07:43,293] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 0/973 [00:00<?, ?it/s]\u001b[A[2024-01-21 14:07:43,996] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 2/973 [00:00<05:41,  2.85it/s]\u001b[A[2024-01-21 14:07:44,667] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 3/973 [00:01<07:50,  2.06it/s]\u001b[A[2024-01-21 14:07:45,363] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  0% 4/973 [00:02<09:05,  1.78it/s]\u001b[A[2024-01-21 14:07:46,051] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 5/973 [00:02<09:47,  1.65it/s]\u001b[A[2024-01-21 14:07:46,730] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 6/973 [00:03<10:09,  1.59it/s]\u001b[A[2024-01-21 14:07:47,421] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 7/973 [00:04<10:28,  1.54it/s]\u001b[A[2024-01-21 14:07:48,110] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 8/973 [00:04<10:39,  1.51it/s]\u001b[A[2024-01-21 14:07:48,797] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 9/973 [00:05<10:45,  1.49it/s]\u001b[A[2024-01-21 14:07:49,488] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 10/973 [00:06<10:51,  1.48it/s]\u001b[A[2024-01-21 14:07:50,179] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 11/973 [00:06<10:54,  1.47it/s]\u001b[A[2024-01-21 14:07:50,862] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 12/973 [00:07<10:54,  1.47it/s]\u001b[A[2024-01-21 14:07:51,546] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 13/973 [00:08<10:54,  1.47it/s]\u001b[A[2024-01-21 14:07:52,221] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  1% 14/973 [00:08<10:52,  1.47it/s]\u001b[A[2024-01-21 14:07:52,908] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 15/973 [00:09<10:53,  1.47it/s]\u001b[A[2024-01-21 14:07:53,597] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 16/973 [00:10<10:54,  1.46it/s]\u001b[A[2024-01-21 14:07:54,280] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 17/973 [00:10<10:53,  1.46it/s]\u001b[A[2024-01-21 14:07:54,964] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 18/973 [00:11<10:53,  1.46it/s]\u001b[A[2024-01-21 14:07:55,643] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "  2% 19/973 [00:12<10:50,  1.47it/s]\u001b[A[2024-01-21 14:07:56,329] [INFO] [axolotl.utils.samplers.multipack._len_est:178] [PID:8731] [RANK:0] packing_efficiency_estimate: 0.76 total_num_tokens per device: 1532799\u001b[39m\n",
            "\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.5971428155899048, 'eval_runtime': 13.7187, 'eval_samples_per_second': 1.458, 'eval_steps_per_second': 1.458, 'epoch': 3.52}\n",
            " 88% 1701/1944 [2:11:37<18:32,  4.58s/it]\n",
            "  2% 20/973 [00:13<10:51,  1.46it/s]\u001b[A\n",
            "{'loss': 0.4122, 'learning_rate': 7.6275951559344196e-06, 'epoch': 3.52}\n",
            "{'loss': 0.3765, 'learning_rate': 7.565492956283693e-06, 'epoch': 3.52}\n",
            "{'loss': 0.178, 'learning_rate': 7.503634661709613e-06, 'epoch': 3.52}\n",
            "{'loss': 0.2562, 'learning_rate': 7.442020435436437e-06, 'epoch': 3.53}\n",
            "{'loss': 0.4214, 'learning_rate': 7.380650440044401e-06, 'epoch': 3.53}\n",
            "{'loss': 0.3259, 'learning_rate': 7.319524837469239e-06, 'epoch': 3.53}\n",
            "{'loss': 0.131, 'learning_rate': 7.258643789001873e-06, 'epoch': 3.53}\n",
            "{'loss': 0.4894, 'learning_rate': 7.198007455287914e-06, 'epoch': 3.53}\n",
            "{'loss': 0.0932, 'learning_rate': 7.13761599632724e-06, 'epoch': 3.54}\n",
            "{'loss': 0.1258, 'learning_rate': 7.077469571473549e-06, 'epoch': 3.54}\n",
            "{'loss': 0.1752, 'learning_rate': 7.017568339434022e-06, 'epoch': 3.54}\n",
            "{'loss': 0.1386, 'learning_rate': 6.957912458268834e-06, 'epoch': 3.54}\n",
            "{'loss': 0.3963, 'learning_rate': 6.8985020853907566e-06, 'epoch': 3.54}\n",
            "{'loss': 0.1586, 'learning_rate': 6.839337377564781e-06, 'epoch': 3.55}\n",
            "{'loss': 0.2495, 'learning_rate': 6.780418490907581e-06, 'epoch': 3.55}\n",
            "{'loss': 0.2014, 'learning_rate': 6.721745580887273e-06, 'epoch': 3.55}\n",
            "{'loss': 0.1513, 'learning_rate': 6.663318802322871e-06, 'epoch': 3.55}\n",
            "{'loss': 0.1457, 'learning_rate': 6.605138309383951e-06, 'epoch': 3.55}\n",
            "{'loss': 0.1908, 'learning_rate': 6.547204255590211e-06, 'epoch': 3.56}\n",
            "{'loss': 0.1279, 'learning_rate': 6.489516793811057e-06, 'epoch': 3.56}\n",
            "{'loss': 0.0887, 'learning_rate': 6.432076076265247e-06, 'epoch': 3.56}\n",
            "{'loss': 0.3132, 'learning_rate': 6.374882254520464e-06, 'epoch': 3.56}\n",
            "{'loss': 0.2066, 'learning_rate': 6.3179354794928865e-06, 'epoch': 3.57}\n",
            "{'loss': 0.1598, 'learning_rate': 6.261235901446816e-06, 'epoch': 3.57}\n",
            "{'loss': 0.2125, 'learning_rate': 6.204783669994285e-06, 'epoch': 3.57}\n",
            "{'loss': 0.2506, 'learning_rate': 6.148578934094673e-06, 'epoch': 3.57}\n",
            "{'loss': 0.2164, 'learning_rate': 6.092621842054314e-06, 'epoch': 3.57}\n",
            "{'loss': 0.105, 'learning_rate': 6.036912541526019e-06, 'epoch': 3.58}\n",
            "{'loss': 0.2078, 'learning_rate': 5.981451179508812e-06, 'epoch': 3.58}\n",
            "{'loss': 0.2789, 'learning_rate': 5.9262379023474755e-06, 'epoch': 3.58}\n",
            "{'loss': 0.0728, 'learning_rate': 5.871272855732191e-06, 'epoch': 3.58}\n",
            "{'loss': 0.1906, 'learning_rate': 5.8165561846981184e-06, 'epoch': 3.58}\n",
            "{'loss': 0.233, 'learning_rate': 5.7620880336250124e-06, 'epoch': 3.59}\n",
            "{'loss': 0.2143, 'learning_rate': 5.707868546236916e-06, 'epoch': 3.59}\n",
            "{'loss': 0.4083, 'learning_rate': 5.653897865601687e-06, 'epoch': 3.59}\n",
            "{'loss': 0.1516, 'learning_rate': 5.6001761341306966e-06, 'epoch': 3.59}\n",
            "{'loss': 0.1907, 'learning_rate': 5.546703493578365e-06, 'epoch': 3.59}\n",
            "{'loss': 0.4709, 'learning_rate': 5.493480085041902e-06, 'epoch': 3.6}\n",
            "{'loss': 0.1966, 'learning_rate': 5.440506048960836e-06, 'epoch': 3.6}\n",
            "{'loss': 0.1389, 'learning_rate': 5.3877815251166865e-06, 'epoch': 3.6}\n",
            "{'loss': 0.3039, 'learning_rate': 5.335306652632621e-06, 'epoch': 3.6}\n",
            "{'loss': 0.1598, 'learning_rate': 5.283081569972992e-06, 'epoch': 3.6}\n",
            "{'loss': 0.1687, 'learning_rate': 5.23110641494311e-06, 'epoch': 3.61}\n",
            "{'loss': 0.1059, 'learning_rate': 5.179381324688748e-06, 'epoch': 3.61}\n",
            "{'loss': 0.1286, 'learning_rate': 5.1279064356958835e-06, 'epoch': 3.61}\n",
            "{'loss': 0.1293, 'learning_rate': 5.076681883790247e-06, 'epoch': 3.61}\n",
            "{'loss': 0.2647, 'learning_rate': 5.025707804137058e-06, 'epoch': 3.61}\n",
            "{'loss': 0.2523, 'learning_rate': 4.974984331240584e-06, 'epoch': 3.62}\n",
            "{'loss': 0.2867, 'learning_rate': 4.924511598943826e-06, 'epoch': 3.62}\n",
            "{'loss': 0.1036, 'learning_rate': 4.874289740428206e-06, 'epoch': 3.62}\n",
            "{'loss': 0.1287, 'learning_rate': 4.824318888213086e-06, 'epoch': 3.62}\n",
            "{'loss': 0.1247, 'learning_rate': 4.774599174155581e-06, 'epoch': 3.62}\n",
            "{'loss': 0.1917, 'learning_rate': 4.725130729450078e-06, 'epoch': 3.63}\n",
            "{'loss': 0.1647, 'learning_rate': 4.6759136846280085e-06, 'epoch': 3.63}\n",
            "{'loss': 0.1855, 'learning_rate': 4.626948169557344e-06, 'epoch': 3.63}\n",
            "{'loss': 0.3425, 'learning_rate': 4.5782343134424425e-06, 'epoch': 3.63}\n",
            "{'loss': 0.1557, 'learning_rate': 4.529772244823571e-06, 'epoch': 3.64}\n",
            "{'loss': 0.1926, 'learning_rate': 4.481562091576608e-06, 'epoch': 3.64}\n",
            "{'loss': 0.285, 'learning_rate': 4.433603980912737e-06, 'epoch': 3.64}\n",
            "{'loss': 0.2205, 'learning_rate': 4.385898039378033e-06, 'epoch': 3.64}\n",
            "{'loss': 0.2688, 'learning_rate': 4.338444392853225e-06, 'epoch': 3.64}\n",
            "{'loss': 0.1063, 'learning_rate': 4.2912431665532825e-06, 'epoch': 3.65}\n",
            "{'loss': 0.2511, 'learning_rate': 4.244294485027156e-06, 'epoch': 3.65}\n",
            "{'loss': 0.1561, 'learning_rate': 4.19759847215736e-06, 'epoch': 3.65}\n",
            "{'loss': 0.2117, 'learning_rate': 4.151155251159744e-06, 'epoch': 3.65}\n",
            "{'loss': 0.1663, 'learning_rate': 4.1049649445831e-06, 'epoch': 3.65}\n",
            "{'loss': 0.2053, 'learning_rate': 4.059027674308846e-06, 'epoch': 3.66}\n",
            "{'loss': 0.1854, 'learning_rate': 4.013343561550776e-06, 'epoch': 3.66}\n",
            "{'loss': 0.2243, 'learning_rate': 3.967912726854595e-06, 'epoch': 3.66}\n",
            "{'loss': 0.1263, 'learning_rate': 3.9227352900977455e-06, 'epoch': 3.66}\n",
            "{'loss': 0.1372, 'learning_rate': 3.877811370489026e-06, 'epoch': 3.66}\n",
            "{'loss': 0.0977, 'learning_rate': 3.833141086568281e-06, 'epoch': 3.67}\n",
            "{'loss': 0.188, 'learning_rate': 3.7887245562061136e-06, 'epoch': 3.67}\n",
            "{'loss': 0.1667, 'learning_rate': 3.7445618966034936e-06, 'epoch': 3.67}\n",
            "{'loss': 0.1915, 'learning_rate': 3.7006532242915506e-06, 'epoch': 3.67}\n",
            "{'loss': 0.1525, 'learning_rate': 3.6569986551312276e-06, 'epoch': 3.67}\n",
            "{'loss': 0.2565, 'learning_rate': 3.613598304312971e-06, 'epoch': 3.68}\n",
            "{'loss': 0.1583, 'learning_rate': 3.5704522863563848e-06, 'epoch': 3.68}\n",
            "{'loss': 0.1716, 'learning_rate': 3.527560715110023e-06, 'epoch': 3.68}\n",
            "{'loss': 0.1394, 'learning_rate': 3.4849237037509976e-06, 'epoch': 3.68}\n",
            "{'loss': 0.7067, 'learning_rate': 3.4425413647847347e-06, 'epoch': 3.68}\n",
            "{'loss': 0.225, 'learning_rate': 3.400413810044689e-06, 'epoch': 3.69}\n",
            "{'loss': 0.148, 'learning_rate': 3.358541150691952e-06, 'epoch': 3.69}\n",
            "{'loss': 0.3111, 'learning_rate': 3.3169234972150853e-06, 'epoch': 3.69}\n",
            "{'loss': 0.5292, 'learning_rate': 3.275560959429758e-06, 'epoch': 3.69}\n",
            "{'loss': 0.1994, 'learning_rate': 3.234453646478486e-06, 'epoch': 3.69}\n",
            "{'loss': 0.2766, 'learning_rate': 3.1936016668302703e-06, 'epoch': 3.7}\n",
            "{'loss': 0.1633, 'learning_rate': 3.1530051282804286e-06, 'epoch': 3.7}\n",
            "{'loss': 0.1837, 'learning_rate': 3.1126641379502385e-06, 'epoch': 3.7}\n",
            "{'loss': 0.1982, 'learning_rate': 3.072578802286641e-06, 'epoch': 3.7}\n",
            "{'loss': 0.1809, 'learning_rate': 3.0327492270620373e-06, 'epoch': 3.71}\n",
            "{'loss': 0.229, 'learning_rate': 2.993175517373903e-06, 'epoch': 3.71}\n",
            "{'loss': 0.1275, 'learning_rate': 2.9538577776445974e-06, 'epoch': 3.71}\n",
            "{'loss': 0.079, 'learning_rate': 2.9147961116210433e-06, 'epoch': 3.71}\n",
            "{'loss': 0.0854, 'learning_rate': 2.8759906223744916e-06, 'epoch': 3.71}\n",
            "{'loss': 0.1706, 'learning_rate': 2.83744141230019e-06, 'epoch': 3.72}\n",
            "{'loss': 0.1302, 'learning_rate': 2.7991485831171613e-06, 'epoch': 3.72}\n",
            "{'loss': 0.2725, 'learning_rate': 2.7611122358679463e-06, 'epoch': 3.72}\n",
            "{'loss': 0.2324, 'learning_rate': 2.723332470918272e-06, 'epoch': 3.72}\n",
            "{'loss': 0.1605, 'learning_rate': 2.6858093879568614e-06, 'epoch': 3.72}\n",
            "{'loss': 0.3604, 'learning_rate': 2.6485430859951032e-06, 'epoch': 3.73}\n",
            "{'loss': 0.1225, 'learning_rate': 2.6115336633668387e-06, 'epoch': 3.73}\n",
            "{'loss': 0.1366, 'learning_rate': 2.574781217728095e-06, 'epoch': 3.73}\n",
            "{'loss': 0.1999, 'learning_rate': 2.5382858460568317e-06, 'epoch': 3.73}\n",
            "{'loss': 0.3134, 'learning_rate': 2.5020476446526164e-06, 'epoch': 3.73}\n",
            "{'loss': 0.0106, 'learning_rate': 2.466066709136483e-06, 'epoch': 3.74}\n",
            "{'loss': 0.1213, 'learning_rate': 2.4303431344505968e-06, 'epoch': 3.74}\n",
            "{'loss': 0.2261, 'learning_rate': 2.3948770148580435e-06, 'epoch': 3.74}\n",
            "{'loss': 0.1326, 'learning_rate': 2.3596684439425643e-06, 'epoch': 3.74}\n",
            "{'loss': 0.2199, 'learning_rate': 2.324717514608288e-06, 'epoch': 3.74}\n",
            "{'loss': 0.0978, 'learning_rate': 2.2900243190795422e-06, 'epoch': 3.75}\n",
            "{'loss': 0.2219, 'learning_rate': 2.2555889489005665e-06, 'epoch': 3.75}\n",
            "{'loss': 0.3578, 'learning_rate': 2.2214114949352883e-06, 'epoch': 3.75}\n",
            "{'loss': 0.161, 'learning_rate': 2.187492047367057e-06, 'epoch': 3.75}\n",
            "{'loss': 0.1253, 'learning_rate': 2.1538306956984224e-06, 'epoch': 3.75}\n",
            "{'loss': 0.1766, 'learning_rate': 2.1204275287509455e-06, 'epoch': 3.76}\n",
            "{'loss': 0.2496, 'learning_rate': 2.087282634664878e-06, 'epoch': 3.76}\n",
            "{'loss': 0.1235, 'learning_rate': 2.054396100899003e-06, 'epoch': 3.76}\n",
            "{'loss': 0.1618, 'learning_rate': 2.0217680142303295e-06, 'epoch': 3.76}\n",
            "{'loss': 0.2841, 'learning_rate': 1.989398460753944e-06, 'epoch': 3.76}\n",
            "{'loss': 0.1796, 'learning_rate': 1.957287525882734e-06, 'epoch': 3.77}\n",
            "{'loss': 0.1336, 'learning_rate': 1.9254352943472e-06, 'epoch': 3.77}\n",
            "{'loss': 0.128, 'learning_rate': 1.8938418501951549e-06, 'epoch': 3.77}\n",
            "{'loss': 0.1725, 'learning_rate': 1.862507276791603e-06, 'epoch': 3.77}\n",
            "{'loss': 0.2536, 'learning_rate': 1.8314316568184498e-06, 'epoch': 3.77}\n",
            "{'loss': 0.2108, 'learning_rate': 1.8006150722743142e-06, 'epoch': 3.78}\n",
            "{'loss': 0.2886, 'learning_rate': 1.7700576044742956e-06, 'epoch': 3.78}\n",
            "{'loss': 0.4754, 'learning_rate': 1.739759334049762e-06, 'epoch': 3.78}\n",
            "{'loss': 0.3101, 'learning_rate': 1.7097203409481511e-06, 'epoch': 3.78}\n",
            "{'loss': 0.201, 'learning_rate': 1.6799407044327587e-06, 'epoch': 3.79}\n",
            "{'loss': 0.3555, 'learning_rate': 1.6504205030825282e-06, 'epoch': 3.79}\n",
            "{'loss': 0.1052, 'learning_rate': 1.621159814791795e-06, 'epoch': 3.79}\n",
            "{'loss': 0.3892, 'learning_rate': 1.5921587167701534e-06, 'epoch': 3.79}\n",
            "{'loss': 0.168, 'learning_rate': 1.5634172855422346e-06, 'epoch': 3.79}\n",
            "{'loss': 0.2008, 'learning_rate': 1.534935596947451e-06, 'epoch': 3.8}\n",
            "{'loss': 0.1773, 'learning_rate': 1.5067137261398967e-06, 'epoch': 3.8}\n",
            "{'loss': 0.1697, 'learning_rate': 1.4787517475880252e-06, 'epoch': 3.8}\n",
            "{'loss': 0.3473, 'learning_rate': 1.45104973507455e-06, 'epoch': 3.8}\n",
            "{'loss': 0.3717, 'learning_rate': 1.4236077616962328e-06, 'epoch': 3.8}\n",
            "{'loss': 0.1052, 'learning_rate': 1.3964258998636404e-06, 'epoch': 3.81}\n",
            "{'loss': 0.1641, 'learning_rate': 1.3695042213010213e-06, 'epoch': 3.81}\n",
            "{'loss': 0.2524, 'learning_rate': 1.34284279704604e-06, 'epoch': 3.81}\n",
            "{'loss': 0.1631, 'learning_rate': 1.3164416974496995e-06, 'epoch': 3.81}\n",
            "{'loss': 0.1224, 'learning_rate': 1.290300992176019e-06, 'epoch': 3.81}\n",
            "{'loss': 0.2934, 'learning_rate': 1.2644207502019668e-06, 'epoch': 3.82}\n",
            "{'loss': 0.2085, 'learning_rate': 1.2388010398172167e-06, 'epoch': 3.82}\n",
            "{'loss': 0.1703, 'learning_rate': 1.2134419286239818e-06, 'epoch': 3.82}\n",
            "{'loss': 0.1888, 'learning_rate': 1.1883434835368357e-06, 'epoch': 3.82}\n",
            "{'loss': 0.0671, 'learning_rate': 1.163505770782547e-06, 'epoch': 3.82}\n",
            "{'loss': 0.1729, 'learning_rate': 1.1389288558999011e-06, 'epoch': 3.83}\n",
            "{'loss': 0.3262, 'learning_rate': 1.1146128037394787e-06, 'epoch': 3.83}\n",
            "{'loss': 0.1563, 'learning_rate': 1.0905576784635773e-06, 'epoch': 3.83}\n",
            "{'loss': 0.1453, 'learning_rate': 1.066763543545979e-06, 'epoch': 3.83}\n",
            "{'loss': 0.1803, 'learning_rate': 1.0432304617717824e-06, 'epoch': 3.83}\n",
            "{'loss': 0.1733, 'learning_rate': 1.0199584952372498e-06, 'epoch': 3.84}\n",
            "{'loss': 0.2156, 'learning_rate': 9.969477053496602e-07, 'epoch': 3.84}\n",
            "{'loss': 0.237, 'learning_rate': 9.741981528271105e-07, 'epoch': 3.84}\n",
            "{'loss': 0.2213, 'learning_rate': 9.517098976984052e-07, 'epoch': 3.84}\n",
            "{'loss': 0.1728, 'learning_rate': 9.294829993028554e-07, 'epoch': 3.84}\n",
            "{'loss': 0.0792, 'learning_rate': 9.075175162901128e-07, 'epoch': 3.85}\n",
            "{'loss': 0.1991, 'learning_rate': 8.858135066200591e-07, 'epoch': 3.85}\n",
            "{'loss': 0.0868, 'learning_rate': 8.643710275626271e-07, 'epoch': 3.85}\n",
            "{'loss': 0.1881, 'learning_rate': 8.431901356976801e-07, 'epoch': 3.85}\n",
            "{'loss': 0.3312, 'learning_rate': 8.222708869147888e-07, 'epoch': 3.86}\n",
            "{'loss': 0.2289, 'learning_rate': 8.016133364131428e-07, 'epoch': 3.86}\n",
            "{'loss': 0.2337, 'learning_rate': 7.812175387014398e-07, 'epoch': 3.86}\n",
            "{'loss': 0.1687, 'learning_rate': 7.610835475976296e-07, 'epoch': 3.86}\n",
            "{'loss': 0.1735, 'learning_rate': 7.41211416228893e-07, 'epoch': 3.86}\n",
            "{'loss': 0.086, 'learning_rate': 7.216011970314074e-07, 'epoch': 3.87}\n",
            "{'loss': 0.1751, 'learning_rate': 7.02252941750281e-07, 'epoch': 3.87}\n",
            "{'loss': 0.1028, 'learning_rate': 6.831667014393528e-07, 'epoch': 3.87}\n",
            "{'loss': 0.2261, 'learning_rate': 6.643425264611036e-07, 'epoch': 3.87}\n",
            "{'loss': 0.1836, 'learning_rate': 6.457804664865119e-07, 'epoch': 3.87}\n",
            "{'loss': 0.1618, 'learning_rate': 6.274805704948983e-07, 'epoch': 3.88}\n",
            "{'loss': 0.1941, 'learning_rate': 6.094428867738478e-07, 'epoch': 3.88}\n",
            "{'loss': 0.1458, 'learning_rate': 5.916674629190211e-07, 'epoch': 3.88}\n",
            "{'loss': 0.1543, 'learning_rate': 5.741543458340881e-07, 'epoch': 3.88}\n",
            "{'loss': 0.2711, 'learning_rate': 5.569035817305501e-07, 'epoch': 3.88}\n",
            "{'loss': 0.1855, 'learning_rate': 5.3991521612764e-07, 'epoch': 3.89}\n",
            "{'loss': 0.4129, 'learning_rate': 5.231892938522331e-07, 'epoch': 3.89}\n",
            "{'loss': 0.0968, 'learning_rate': 5.067258590386703e-07, 'epoch': 3.89}\n",
            "{'loss': 0.2309, 'learning_rate': 4.905249551287128e-07, 'epoch': 3.89}\n",
            "{'loss': 0.1497, 'learning_rate': 4.7458662487132045e-07, 'epoch': 3.89}\n",
            "{'loss': 0.1434, 'learning_rate': 4.589109103226852e-07, 'epoch': 3.9}\n",
            "{'loss': 0.2189, 'learning_rate': 4.434978528459643e-07, 'epoch': 3.9}\n",
            "{'loss': 0.2415, 'learning_rate': 4.2834749311131406e-07, 'epoch': 3.9}\n",
            "{'loss': 0.3304, 'learning_rate': 4.134598710956672e-07, 'epoch': 3.9}\n",
            "{'loss': 0.3384, 'learning_rate': 3.9883502608268894e-07, 'epoch': 3.9}\n",
            "{'loss': 0.0951, 'learning_rate': 3.84472996662677e-07, 'epoch': 3.91}\n",
            "{'loss': 0.1584, 'learning_rate': 3.703738207324281e-07, 'epoch': 3.91}\n",
            "{'loss': 0.2923, 'learning_rate': 3.5653753549514946e-07, 'epoch': 3.91}\n",
            "{'loss': 0.2055, 'learning_rate': 3.429641774603587e-07, 'epoch': 3.91}\n",
            "{'loss': 0.1497, 'learning_rate': 3.296537824438284e-07, 'epoch': 3.91}\n",
            "{'loss': 0.5013, 'learning_rate': 3.166063855674084e-07, 'epoch': 3.92}\n",
            "{'loss': 0.1996, 'learning_rate': 3.038220212590037e-07, 'epoch': 3.92}\n",
            "{'loss': 0.1218, 'learning_rate': 2.9130072325247447e-07, 'epoch': 3.92}\n",
            "{'loss': 0.506, 'learning_rate': 2.790425245875139e-07, 'epoch': 3.92}\n",
            "{'loss': 0.3276, 'learning_rate': 2.6704745760957053e-07, 'epoch': 3.92}\n",
            "{'loss': 0.1391, 'learning_rate': 2.5531555396980376e-07, 'epoch': 3.93}\n",
            "{'loss': 0.1379, 'learning_rate': 2.438468446249509e-07, 'epoch': 3.93}\n",
            "{'loss': 0.2873, 'learning_rate': 2.32641359837249e-07, 'epoch': 3.93}\n",
            "{'loss': 0.1494, 'learning_rate': 2.2169912917440194e-07, 'epoch': 3.93}\n",
            "{'loss': 0.0593, 'learning_rate': 2.110201815094359e-07, 'epoch': 3.94}\n",
            "{'loss': 0.2859, 'learning_rate': 2.0060454502069948e-07, 'epoch': 3.94}\n",
            "{'loss': 0.2148, 'learning_rate': 1.9045224719170805e-07, 'epoch': 3.94}\n",
            "{'loss': 0.2671, 'learning_rate': 1.8056331481113297e-07, 'epoch': 3.94}\n",
            "{'loss': 0.0962, 'learning_rate': 1.7093777397269027e-07, 'epoch': 3.94}\n",
            "{'loss': 0.1799, 'learning_rate': 1.6157565007510754e-07, 'epoch': 3.95}\n",
            "{'loss': 0.0754, 'learning_rate': 1.5247696782204612e-07, 'epoch': 3.95}\n",
            "{'loss': 0.1804, 'learning_rate': 1.4364175122199008e-07, 'epoch': 3.95}\n",
            "{'loss': 0.2146, 'learning_rate': 1.3507002358826847e-07, 'epoch': 3.95}\n",
            "{'loss': 0.3884, 'learning_rate': 1.267618075389221e-07, 'epoch': 3.95}\n",
            "{'loss': 0.1787, 'learning_rate': 1.187171249966701e-07, 'epoch': 3.96}\n",
            "{'loss': 0.0873, 'learning_rate': 1.1093599718885461e-07, 'epoch': 3.96}\n",
            "{'loss': 0.2102, 'learning_rate': 1.0341844464738515e-07, 'epoch': 3.96}\n",
            "{'loss': 0.2159, 'learning_rate': 9.6164487208672e-08, 'epoch': 3.96}\n",
            "{'loss': 0.4059, 'learning_rate': 8.917414401359291e-08, 'epoch': 3.96}\n",
            "{'loss': 0.2709, 'learning_rate': 8.244743350741546e-08, 'epoch': 3.97}\n",
            "{'loss': 0.2089, 'learning_rate': 7.598437343978582e-08, 'epoch': 3.97}\n",
            "{'loss': 0.1363, 'learning_rate': 6.978498086465113e-08, 'epoch': 3.97}\n",
            "{'loss': 0.1834, 'learning_rate': 6.384927214021508e-08, 'epoch': 3.97}\n",
            "{'loss': 0.1923, 'learning_rate': 5.817726292892678e-08, 'epoch': 3.97}\n",
            "{'loss': 0.1827, 'learning_rate': 5.276896819738086e-08, 'epoch': 3.98}\n",
            "{'loss': 0.264, 'learning_rate': 4.7624402216361887e-08, 'epoch': 3.98}\n",
            "{'loss': 0.2089, 'learning_rate': 4.2743578560711095e-08, 'epoch': 3.98}\n",
            "{'loss': 0.1412, 'learning_rate': 3.812651010937085e-08, 'epoch': 3.98}\n",
            "{'loss': 0.1693, 'learning_rate': 3.3773209045318e-08, 'epoch': 3.98}\n",
            "{'loss': 0.1282, 'learning_rate': 2.9683686855497274e-08, 'epoch': 3.99}\n",
            "{'loss': 0.1907, 'learning_rate': 2.5857954330854584e-08, 'epoch': 3.99}\n",
            "{'loss': 0.1254, 'learning_rate': 2.229602156628152e-08, 'epoch': 3.99}\n",
            "{'loss': 0.1489, 'learning_rate': 1.8997897960582044e-08, 'epoch': 3.99}\n",
            "{'train_runtime': 8955.1075, 'train_samples_per_second': 0.431, 'train_steps_per_second': 0.217, 'train_loss': 0.31293830859106553, 'epoch': 3.99}\n",
            " 99% 1932/1944 [2:29:13<00:55,  4.63s/it]\n",
            "[2024-01-21 14:25:32,865] [INFO] [axolotl.train.log:61] [PID:8731] [RANK:0] Training Completed!!! Saving pre-trained model to ./qlora-out\u001b[39m\n",
            "adapter_model.bin: 100% 101M/101M [00:02<00:00, 36.4MB/s] \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss ▇▂▁▁▁▄▅█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime ▁███████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second █▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second █▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate ███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss ▃▄▃▄█▄▄▅▁▅▅▄▃▃▃▃▄▅▂▄▄▂▃▃▃▃▃▂▃▃▅▃▃▁▂▂▃▁▂▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                      eval/loss 0.59714\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   eval/runtime 13.7187\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        eval/samples_per_second 1.458\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          eval/steps_per_second 1.458\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    train/epoch 3.99\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:              train/global_step 1932\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/learning_rate 0.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     train/loss 0.1489\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/total_flos 5.031751467191501e+16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               train/train_loss 0.31294\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train/train_runtime 8955.1075\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/train_samples_per_second 0.431\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   train/train_steps_per_second 0.217\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdifferent-sound-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/bastien-pouessel/axolotl-pytiny/runs/0e3121ub\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240121_115618-0e3121ub/logs\u001b[0m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://gist.githubusercontent.com/mlabonne/a3542b0519708b8871d0703c938bba9f/raw/60abc5afc07f9d843bc23d56f4e0b7ab072c4a62/merge_peft.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heqGOqCBPrhD",
        "outputId": "a962d1c3-de29-46ec-af7c-c91ca03e7b20"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-21 14:25:53--  https://gist.githubusercontent.com/mlabonne/a3542b0519708b8871d0703c938bba9f/raw/60abc5afc07f9d843bc23d56f4e0b7ab072c4a62/merge_peft.py\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1502 (1.5K) [text/plain]\n",
            "Saving to: ‘merge_peft.py.1’\n",
            "\n",
            "\rmerge_peft.py.1       0%[                    ]       0  --.-KB/s               \rmerge_peft.py.1     100%[===================>]   1.47K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-21 14:25:53 (28.8 MB/s) - ‘merge_peft.py.1’ saved [1502/1502]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python merge_peft.py --base_model=TinyLlama/TinyLlama-1.1B-Chat-v1.0 --peft_model=./qlora-out --hub_id=Pytiny"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMoAyy1Md4Z7",
        "outputId": "6f78ded7-8823-4582-d979-12501fe1f687"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/5] Loading base model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
            "[2/5] Loading adapter: ./qlora-out\n",
            "[3/5] Merge base model and adapter\n",
            "[4/5] Saving model and tokenizer in Pytiny\n",
            "[5/5] Uploading to Hugging Face Hub: Pytiny\n",
            "model.safetensors: 100% 2.20G/2.20G [00:44<00:00, 49.3MB/s]\n",
            "Merged model uploaded to Hugging Face Hub!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EckZazjOajPc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}